{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convloution (합성곱)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://opentutorials.org/module/5268/29788)\n",
    "\n",
    "특정한 패턴의 특징이 어디서 나타나는지 확인\n",
    "\n",
    "conv 필터를 가지고 특징맵을 만들어 본다.\n",
    "\n",
    "- 특징맵 (feature map)\n",
    "\n",
    "<img src=\"./img/c2.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컨볼루션 필터의 이해\n",
    "  1. 필터는 **3차원 형태로 된 가중치**의 모음\n",
    "  1. 필터는 앞선 레이어에서 생성된 **특징맵 전체**를 본다.\n",
    "  1. **필터의 수만큼 특징맵**을 만들어 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_data in module tensorflow.python.keras.datasets.mnist:\n",
      "\n",
      "load_data(path='mnist.npz')\n",
      "    Loads the MNIST dataset.\n",
      "    \n",
      "    This is a dataset of 60,000 28x28 grayscale images of the 10 digits,\n",
      "    along with a test set of 10,000 images.\n",
      "    More info can be found at the\n",
      "    [MNIST homepage](http://yann.lecun.com/exdb/mnist/).\n",
      "    \n",
      "    Args:\n",
      "      path: path where to cache the dataset locally\n",
      "        (relative to `~/.keras/datasets`).\n",
      "    \n",
      "    Returns:\n",
      "      Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
      "    \n",
      "    **x_train**: uint8 NumPy array of grayscale image data with shapes\n",
      "      `(60000, 28, 28)`, containing the training data. Pixel values range\n",
      "      from 0 to 255.\n",
      "    \n",
      "    **y_train**: uint8 NumPy array of digit labels (integers in range 0-9)\n",
      "      with shape `(60000,)` for the training data.\n",
      "    \n",
      "    **x_test**: uint8 NumPy array of grayscale image data with shapes\n",
      "      (10000, 28, 28), containing the test data. Pixel values range\n",
      "      from 0 to 255.\n",
      "    \n",
      "    **y_test**: uint8 NumPy array of digit labels (integers in range 0-9)\n",
      "      with shape `(10000,)` for the test data.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```python\n",
      "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
      "    assert x_train.shape == (60000, 28, 28)\n",
      "    assert x_test.shape == (10000, 28, 28)\n",
      "    assert y_train.shape == (60000,)\n",
      "    assert y_test.shape == (10000,)\n",
      "    ```\n",
      "    \n",
      "    License:\n",
      "      Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset,\n",
      "      which is a derivative work from original NIST datasets.\n",
      "      MNIST dataset is made available under the terms of the\n",
      "      [Creative Commons Attribution-Share Alike 3.0 license.](\n",
      "      https://creativecommons.org/licenses/by-sa/3.0/)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.datasets.mnist.load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 영상 클론 코딩\n",
    "\n",
    "# 1.과거의 데이터를 준비\n",
    "(독립, 종속), _ = tf.keras.datasets.mnist.load_data()\n",
    "독립 = 독립.reshape(60000, 28, 28, 1) # conv 는 3차원을 입력으로 받는다.\n",
    "                                    # (6만장, 28 by 28 1장)\n",
    "                                    # (28 ,28, 3) = 28 by 28 3차원\n",
    "종속 = pd.get_dummies(종속)\n",
    "print(독립.shpae, 종속.shape)\n",
    "\n",
    "# 2. 모델의 구조를 만듭니다.\n",
    "X = tf.keras.layers.Input(shape=[28, 28, 1]) # conv2d 는 3차원을 입력으로 받는다.\n",
    "## 컨볼루젼 레이터 추가    (필터셋 몇개, 필터셋 사이즈)\n",
    "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation='swish')(X) # 3개의 새 특징맵 = 3채널의 특징맵\n",
    "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation='swish')(X) # 6개의 새 특징맵 = 6채널의 특징맵\n",
    "H = tf.keras.layers.Flatten()(H) # 표로 만든다.\n",
    "H = tf.keras.layers.Dense(84, acrivation='swish')(H)\n",
    "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.complie(loss='categorical_corssentropy', merics='accuracy')\n",
    "\n",
    "# 3. 데이터로 모델을 학습(FIT)합니다.\n",
    "model.fit(독립, 종속, epochs=10)\n",
    "\n",
    "# 4. 모델을 이용합니다.\n",
    "print(\"Predictions : \", model.predict(독립[0:5]))\n",
    "\n",
    "\n",
    "https://youtu.be/5eYHZ7wC3Qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필터의 이해\n",
    "\n",
    "1. 필터셋읜 **3차원 형태로 된 가충치**의 모음\n",
    "2. 필터셋  하나는 앞선 레이어의 결과인 **\"특징맵\" 전체를 본다.** (입력되는 특징맵 전체)\n",
    "3. 필터셋의 개수 만큼 특징 맵을 만든다.\n",
    "\n",
    "- ex) 필터셋 3개 라고 하면, 가로선 필터, 세로선 필터, 대각선 필터 3개를 사용함.\n",
    "- 각 필터들은 3차원 (흑백이라도 3차원으로 설정. (5,5,1) 이런식으로)\n",
    "\n",
    "```python\n",
    "Conv2D(3, kernel_size=5, activation='swish')\n",
    "Conv2D(6, kernel_size=5, activation='swish')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 필터 모형 \n",
    "\n",
    "[F1][F2][F3].........[F1][F2][F3][F4][F5][F6]   \n",
    "\n",
    "F1 : [(5,5,?)] # 개별 필터셋 하나가 3차원이다. 즉, 5,5 사이즈 필터가 여러 채널 존재  \n",
    "F2 : [(5,5,?)] # 이때 ? 는 앞선 특징맵 전체의 필터 수와 같은 수가 들어간다.   \n",
    "F3 : [(5,5,?)]  \n",
    "\n",
    "- 흑백 이미지 (28, 28, 1) 이 입력되면, (5, 5, 1) / 전체 필터셋은 (5, 5, ?)\n",
    "- 컬러 이미지 (32, 32, 3) 이 입력되면, (5, 5, 3) / 전체 필터셋은 (3, 5, 5, ?)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Conv2D(3, kernel_size=5, activation='swish')\n",
    "Conv2D(6, kernel_size=5, activation='swish')\n",
    "```\n",
    "\n",
    "<img src=\"./img/c5.png\" width=70% height=70%>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Conv2D(3, kernel_size=5, activation='swish')\n",
    "```\n",
    "- 숫자 4 (28, 28, 1)\n",
    "- F1, F2, F3 : (5, 5, 1) 3개의 필터셋를 만든다. (컨볼루션 필터)\n",
    "- 이 필터를 통해 3장의 특징맵을 만든다. : M1, M2, M3\n",
    "\n",
    "```python\n",
    "Conv2D(6, kernel_size=5, activation='swish')\n",
    "```\n",
    "- 앞서 만들어진 특징맵 3개를 : (24, 24, 3)\n",
    "- F1, F2, F3, F4, F5, F6 : (5 by 5 , 3) 6개의 필터셋를 만든다. (차원을 맞춤) (컨볼루션 필터)\n",
    "- 이때, F1-1 은 M1, F1-2 는 M2, F1-3은 M3 를 본다. \n",
    "- 이는 하나의 필터셋은 앞선 레이어의 특징맵 전체를 한번씩 모두 보는 것이다.\n",
    "- 이 과정을 반복해 새로운 특징맵 M1 ~ M6 까지가 만들어 진다. (20, 20, 6)\n",
    "- 필터셋이 6개인 6체널인 특징맵이 만들어 졌다.\n",
    "\n",
    "컨볼루션 필터 : 이미지들이 0~9 중 어느 숫자인지 판단하기 위해 가장 좋은 특징맵 6개를 찾아라\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고 사항\n",
    "\n",
    "<img src=\"./img/c3.png\" width=70% height=70%>\n",
    "\n",
    "<img src=\"./img/c4.png\" width=70% height=70%>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "(60000, 28, 28, 1) (60000, 10)\n",
      "(10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# 이미지를 3차원으로 reshape\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) # 계산하기 싫은 부분은 -1로 넣어주면 자동 계산이 된다. \n",
    "# reshape 은 60000 단위가 같아야 함. 이를 -1로 하면, 알아서 60000으로 생각함\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 원핫인코딩\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 24, 24, 3)         78        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 6)         456       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 84)                201684    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 203,068\n",
      "Trainable params: 203,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델준비\n",
    "\n",
    "X = tf.keras.Input(shape=[28, 28, 1])\n",
    "\n",
    "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation=\"swish\")(X) # 3채널의 특징맵\n",
    "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation=\"swish\")(H) # 6채널의 특징맵\n",
    "\n",
    "H = tf.keras.layers.Flatten()(H) # 표로 만든다.\n",
    "H = tf.keras.layers.Dense(84, activation=\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과표 해석\n",
    "```python\n",
    "\n",
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
    "_________________________________________________________________\n",
    "conv2d (Conv2D)              (None, 24, 24, 3)         78        \n",
    "# 커널 사이즈가 5 이므로 (5,5) 필터를 통과해 사이즈가 (24, 24, 3) 로 줄었다.\n",
    "# (24, 24, 3) 의 이미지가 6만장\n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 20, 20, 6)         456       \n",
    "# (5, 5) 필터를 통과해 사이즈가 (20, 20, 6) 로 줄었다.\n",
    "# (20, 20) 의 표이므로, 400개의 숫자가 들어있다. 더불어 6채널 이므로, 2400개 숫자가 들어있다.\n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 2400)              0         \n",
    "# 위 표를 한줄로 편다. (2400개의 입력을 받아서...)\n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 84)                201684    \n",
    "# 84개의 특징을 뽑아 낸다.                   2400 + 1(bias) * 84 = 201684\n",
    "# 수식이 84개라는 의미\n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 10)                850       \n",
    "# 최종적으로 10개의 특징을 뽑아 낸다.\n",
    "# 10개의 수식 (1개의 수식을 위해서 84개의 가중치, 1개의 bias가 필요)\n",
    "=================================================================\n",
    "Total params: 203,068\n",
    "# 컴퓨터가 찾은 가중치의 갯수 : 203,068\n",
    "Trainable params: 203,068\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "```\n",
    "\n",
    "- 작은 수의 파라미터 + 다회 학습 (에포크) 이라면, GPU 를 사용해도 속도가 빨라지지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201684"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2401*84\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "480/480 [==============================] - 3s 5ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.1998 - val_accuracy: 0.9809\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1995 - val_accuracy: 0.9762\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.3136 - val_accuracy: 0.9739\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 3s 5ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.2623 - val_accuracy: 0.9793\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.2671 - val_accuracy: 0.9812\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.2712 - val_accuracy: 0.9813\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.2445 - val_accuracy: 0.9810\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.2382 - val_accuracy: 0.9803\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.2670 - val_accuracy: 0.9795\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.3306 - val_accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c6573bedf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3055 - accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30545511841773987, 0.9799000024795532]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 경사하강법 추가\n",
    "\n",
    "loss가 가장 작은 global minimum 을 찾음을 증명 할 수 없다.  \n",
    "우리가 찾는 것은 local minimum 이다. (결과가 매번 달라지는 이유). 이 weight 들도 충분이 쓸만 하기 때문에, 최적의 수준의 모델을 사용한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolusion 연산\n",
    "\n",
    "https://youtu.be/VHQbRI2Xvl0\n",
    "\n",
    "\n",
    "<img src=\"./img/c6.png\" width=70% height=70%>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필터를 통한 연산을 하고 나면, 결과의 사이즈가 작아지는 이유도 알 수 있다.\n",
    "- 수식은 퍼셉트론의 수식 모양과 같다.\n",
    "- 퍼셉트론에서는 최적의 특징을 추출, 컨볼루션에서는 최적의 특징맵을 추출\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제 계산 연습\n",
    "\n",
    "<img src=\"./img/c7.png\" width=70% height=70%>\n",
    "\n",
    "- 숫자 4 이미지와, 가로선이 있는 필터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫번째 칸의 계산  \n",
    "\n",
    "|0|0|0|\n",
    "|:-:|:-:|:-:|\n",
    "|0|1|0|\n",
    "|0|1|0|\n",
    "\n",
    "|-1|-1|-1|\n",
    "|:-:|:-:|:-:|\n",
    "|2|2|2|\n",
    "|-1|-1|-1|\n",
    "\n",
    "- 0 + 0 + 0 + 0 + 2 + 0 + 0 + -1 + 0 = 1\n",
    "\n",
    "---\n",
    "위 계산을 반복해서 채우면  \n",
    "(6 , 6)\n",
    "|1|1|0|1|1|1|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|0|0|0|0|0|0|\n",
    "|-1|-2|-3|-2|-2|-1|\n",
    "|3|5|6|4|4|2|\n",
    "|-2|-3|-3|-2|-2|-1|\n",
    "|0|0|0|1|1|1|\n",
    "\n",
    "<img src=\"./img/c8.png\" width=30% height=30%>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 모델에서는 자의적으로 가로선 필터를 만들었지만, 컨볼루션 레이어를 만들어 컴퓨터가 적절한 필터를 만들어 낸다. (핵심)\n",
    "\n",
    "- 딥러닝은 이해가 깊어질수록 이해하기 어렵다!\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxPooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과표 해석 (2)\n",
    "```python\n",
    "\n",
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
    "_________________________________________________________________\n",
    "conv2d (Conv2D)              (None, 24, 24, 3)         78        \n",
    "# 커널 사이즈가 5 이므로 (5,5) 필터를 통과해 사이즈가 (24, 24, 3) 로 줄었다.\n",
    "# (24, 24, 3) 의 이미지가 6만장\n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 20, 20, 6)         456       \n",
    "# (5, 5) 필터를 통과해 사이즈가 (20, 20, 6) 로 줄었다.\n",
    "# (20, 20) 의 표이므로, 400개의 숫자가 들어있다. 더불어 6채널 이므로, 2400개 숫자가 들어있다.\n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 2400)              0         \n",
    "# 위 표를 한줄로 편다. (2400개의 입력을 받아서...)\n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 84)                201684    \n",
    "# 84개의 특징을 뽑아 낸다.                   2400 + 1(bias) * 84 = 201684\n",
    "# 수식이 84개라는 의미\n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 10)                850       \n",
    "# 최종적으로 10개의 특징을 뽑아 낸다.\n",
    "# 내가 가진 종속변수의 값이 10 (0 ~ 9 까지 이므로 10이다.)\n",
    "# 10개의 수식 (1개의 수식을 위해서 84개의 가중치, 1개의 bias가 필요)\n",
    "=================================================================\n",
    "Total params: 203,068\n",
    "# 컴퓨터가 찾은 가중치의 갯수 : 203,068\n",
    "Trainable params: 203,068\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "```\n",
    "\n",
    "- Conv 를 통해 출력된 특징맵의 갯수가 증가하면 (20, 20, 6),\n",
    "- flatten 이후 입력으로 사용할 칼럼수가 증가하고 (2400),\n",
    "- 이는 컴퓨터가 찾아야 하는 가중치의 증가를 의미한다. (201684)\n",
    "\n",
    "**그래서 도입된 방법이 Pooling 이다.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델준비\n",
    "X = tf.keras.Input(shape=[28, 28, 1])\n",
    "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation=\"swish\")(X) # 3채널의 특징맵\n",
    "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation=\"swish\")(H) # 6채널의 특징맵\n",
    "H = tf.keras.layers.Flatten()(H) # 표로 만든다.\n",
    "H = tf.keras.layers.Dense(84, activation=\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과표 계산 \n",
    "\n",
    "- 넣을 사진의 사이즈 (28, 28, 1)\n",
    "- Conv 를 통해 < Conv2D(3, kernel_size=5, > 는 (5, 5, 1) 이 3장이라는 것을 안다.\n",
    "\n",
    "```python\n",
    "\n",
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
    "_________________________________________________________________\n",
    "conv2d (Conv2D)              (None, 24, 24, 3)         78        \n",
    "# 입력 : (5, 5, 1)\n",
    "# (5 * 5) + 1(b) * 3 = (25 + 1) * 3 = 78 \n",
    "# 3채널이 되었으므로, 다음 conv 로는 3채널이 넘어감\n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 20, 20, 6)         456       \n",
    "# 입력 : (5, 5, 3)\n",
    "# (5 * 5 * 3) + 1(b) * 6 = (75 + 1) * 6 = 456 \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 2400)              0         \n",
    "# (20 * 20 * 6) = 2400\n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 84)                201684    \n",
    "# (2400 + 1) * 84 = 201684\n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 10)                850       \n",
    "# (84 + 1) * 10 = 850\n",
    "=================================================================\n",
    "Total params: 203,068\n",
    "# 컴퓨터가 찾은 가중치의 갯수 : 203,068\n",
    "Trainable params: 203,068\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling 을 적용한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델준비\n",
    "X = tf.keras.Input(shape=[28, 28, 1])\n",
    "\n",
    "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation=\"swish\")(X) \n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation=\"swish\")(H) \n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H = tf.keras.layers.Flatten()(H)\n",
    "H = tf.keras.layers.Dense(84, activation=\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 해석\n",
    "\n",
    "```python\n",
    "Model: \"model_3\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 24, 24, 3)         78        \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 12, 12, 3)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_7 (Conv2D)            (None, 8, 8, 6)           456       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 6)           0         \n",
    "# pooling을 하고 나면, (4, 4) 이미지 6장을 사용한다.\n",
    "_________________________________________________________________\n",
    "flatten_3 (Flatten)          (None, 96)                0         \n",
    "# (4 * 4 * 6) = 96\n",
    "_________________________________________________________________\n",
    "dense_6 (Dense)              (None, 84)                8148      \n",
    "# 84개의 수식, 96개의 가중치, 1개의 바이오스\n",
    "# (96 + 1) * 84 = 8148\n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 10)                850       \n",
    "# (84 + 1) * 10 = 850\n",
    "=================================================================\n",
    "Total params: 9,532\n",
    "Trainable params: 9,532\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```\n",
    "- Maxpooling 을 사용하면 특징맵의 사이즈가 줄어들어, 컴퓨터가 찾아야 하는 가중치의 수가 줄어든다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpooling\n",
    "\n",
    "(6, 6) 사이즈의 특징맵을, 그 절반인 (3, 3) 사이즈로 줄인다. \n",
    "\n",
    "<img src=\"./img/c9.png\" width=70% height=70%>\n",
    "\n",
    "- (2, 2) 영역에서 가장 큰 수만 남긴다.\n",
    "\n",
    "- conv로 찾은 특징들은 수치로 나타난다. 큰 수일수록 특징이 많음을 의미\n",
    "\n",
    "- 큰수만 남기는 이유 : 특징맵에서 큰 수 = 필터로 찾으려는 특징이 많이 나타난 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 데이터 실습\n",
    "\n",
    "- 컨볼루션 필터가 찾아낸 특징 정보를 유지하면서 사이즈를 줄이기 위한 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,)\n",
      "(10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Maxpooling\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# 일단 y 값을 onehot 인코딩 하지 않고 넘어감 (자동으로 하는 방법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 3)         78        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 12, 12, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 6)           456       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 84)                8148      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 9,532\n",
      "Trainable params: 9,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = tf.keras.Input(shape=[28, 28, 1])\n",
    "\n",
    "H1 = tf.keras.layers.Conv2D(3, kernel_size=5, activation=\"swish\")(X) \n",
    "# kernel_size=3 이 일반적 (3, 3)\n",
    "H1 = tf.keras.layers.MaxPool2D()(H1)\n",
    "# mxapool 은 (2, 2) 가 디폴트 값. 옵션으로 조정 할 수 있음.\n",
    "\n",
    "H2 = tf.keras.layers.Conv2D(6, kernel_size=5, activation=\"swish\")(H1) \n",
    "H2 = tf.keras.layers.MaxPool2D()(H2)\n",
    "\n",
    "H3 = tf.keras.layers.Flatten()(H2)\n",
    "H3 = tf.keras.layers.Dense(84, activation=\"swish\")(H3)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H3)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "# 로스값을 원레 \"categorical_crossentropy\" 을 사용 했는데, 위에서 onehot 인코딩을 안했다면,\n",
    "# \"sparse_categorical_crossentropy\" 을 사용해 준다. (자동 onehot 인코딩)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컨볼루션 레이어를 쓰는 이유는, 필터가 찾고 싶은 특징이 어디에 있는지 알고 싶다.\n",
    "- 따라서 컨볼루션에서 높은 값은 아주 의미 있는 값\n",
    "- conv 와 maxpooling 은 일반적으로 함께 사용한다.\n",
    "- 또, 이미지 사이즈는 줄이되, 필터의 갯수는 늘리면서 학습하는게 좋다고 알려져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "480/480 [==============================] - 5s 9ms/step - loss: 1.8044 - accuracy: 0.8060 - val_loss: 0.2415 - val_accuracy: 0.9286\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.1860 - accuracy: 0.9454 - val_loss: 0.1633 - val_accuracy: 0.9524\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 4s 7ms/step - loss: 0.1186 - accuracy: 0.9644 - val_loss: 0.1106 - val_accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.0917 - accuracy: 0.9711 - val_loss: 0.1032 - val_accuracy: 0.9718\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.0770 - accuracy: 0.9762 - val_loss: 0.1040 - val_accuracy: 0.9709\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.0653 - accuracy: 0.9794 - val_loss: 0.1128 - val_accuracy: 0.9700\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.0575 - accuracy: 0.9822 - val_loss: 0.0885 - val_accuracy: 0.9745\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0920 - val_accuracy: 0.9747\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 3s 7ms/step - loss: 0.0459 - accuracy: 0.9852 - val_loss: 0.0870 - val_accuracy: 0.9776\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 3s 7ms/step - loss: 0.0439 - accuracy: 0.9854 - val_loss: 0.0904 - val_accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c7ffa83040>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0799 - accuracy: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07989798486232758, 0.9789000153541565]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# LeNet\n",
    "\n",
    "<img src=\"./img/c10.png\" width=80% height=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력 이미지 : (32, 32)\n",
    "- Conv 1 : (28, 28) * 6 이니, 사이즈가 4 줄었으니 (5, 5, 6) Conv 를 사용.\n",
    "- Maxpo 1 : (14, 14) * 6 : 사이즈가 절반으로 줄어든다.\n",
    "- Conv 2 : (10, 10) * 16 이니, 사이즈가 4 줄었으니 (5, 5, 16) Conv 를 사용.\n",
    "- Maxpo 2 : (5, 5) * 16 : 사이즈가 절반으로 줄어든다.\n",
    "- hidden 1 : 120개의 노드\n",
    "- hidden 2 : 84개의 노드\n",
    "- output : 10개의 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,)\n",
      "(10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 코드로 구현\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = tf.keras.Input(shape=[28, 28, 1])\n",
    "\n",
    "H1 = tf.keras.layers.Conv2D(6, kernel_size=5, padding=\"same\", activation=\"swish\")(X)\n",
    "# padding=\"same\" 은 conv 결과인 특징맵의 사이즈가 입력 이미지와 동일한 사이즈로 출력된다.\n",
    "# kernel 이 5 이므로, (28,28)을 받으면 (24, 24)로 줄어야 하는데, same 을 통해 (28, 28)이 유지된다.\n",
    "H1 = tf.keras.layers.MaxPool2D()(H1)\n",
    "\n",
    "H2 = tf.keras.layers.Conv2D(16, kernel_size=5, activation=\"swish\")(H1)\n",
    "H2 = tf.keras.layers.MaxPool2D()(H2)\n",
    "\n",
    "H3 = tf.keras.layers.Flatten()(H2)\n",
    "H3 = tf.keras.layers.Dense(120, activation=\"swish\")(H3)\n",
    "H3 = tf.keras.layers.Dense(84, activation=\"swish\")(H3)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H3)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "480/480 [==============================] - 4s 7ms/step - loss: 0.9787 - accuracy: 0.8903 - val_loss: 0.1313 - val_accuracy: 0.9596\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 3s 7ms/step - loss: 0.0937 - accuracy: 0.9732 - val_loss: 0.0784 - val_accuracy: 0.9806\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0632 - accuracy: 0.9820 - val_loss: 0.0914 - val_accuracy: 0.9763\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0495 - accuracy: 0.9854 - val_loss: 0.0612 - val_accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0410 - accuracy: 0.9884 - val_loss: 0.0645 - val_accuracy: 0.9831\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0330 - accuracy: 0.9903 - val_loss: 0.0981 - val_accuracy: 0.9805\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.0777 - val_accuracy: 0.9827\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0854 - val_accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 3s 6ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 0.0816 - val_accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 3s 5ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.1008 - val_accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c7f053c370>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08967630565166473, 0.9818999767303467]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40b396f7bb4524eebe16d5148ef674cb630ecbb9edf31b1d2c1678c5ede47175"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('webai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
