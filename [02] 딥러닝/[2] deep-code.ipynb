{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형수식 (막대기)를 여러개 써서 복잡한 함수를 만들 수 있음을 증명 논문\n",
    "\n",
    "- 원 함수에 근사한 막대기로 이루어진 함수를 만드는 것\n",
    "- 작은 막대기를 여러개 써서 근사한 함수를 만드는 것을 증명\n",
    "#\n",
    "[Multilayer feedforward networks are universal approximators ( 1989 )](https://www.sciencedirect.com/science/article/abs/pii/0893608089900208)\n",
    "- X와 Y사이에 특정 함수가 존재 한다면, Multi Layer는 인공신경망이 어떤 함수든 근사(Approximate)할 수 있다.\n",
    "]\n",
    "\n",
    "아무리 복잡한 함수라도 막대기로 표현할 수 있다.\n",
    "\n",
    "따라서, 딥러닝은 **모방은 천재** 라고 할 수 있다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Keras\n",
    "\n",
    "데이터 준비 (전처리)\n",
    "- 결측치, 이상치 처리\n",
    "- 수치형 : normalization (일반화-데이터 분포가 다르므로) & 범주형 : one-hot encoding\n",
    "- feature extraction & feature engineering\n",
    "- augmentation\n",
    "\n",
    "### 모델구성 방식\n",
    "- Funcional (Model)\n",
    "- Sequentail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Sequential\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(13,)))\n",
    "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.complie(optimizer='adam', loss='mes')\n",
    "model.fit(x_train, y_train, epochs=100)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (구형)\n",
    "\n",
    "X = tf.keras.layers.Input(shape=(13,))\n",
    "H = tf.keras.layers.Dense(5, activation='relu')(X))\n",
    "Y = tf.keras.layers.Dense(1)(H)\n",
    "model = tf.keras.models.Model(X, Y)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(x_train, y_train, epochs=100)\n",
    "\n",
    "# 자유로운 구성을 위해서는 Funcional (Model) 방식이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Neuron (우리 신경의 과정)\n",
    "![img](./img/neuron.jpg)\n",
    "1. 근처 뉴들들에게서 이진 신호를 받고\n",
    "2. 그 신호들을 잘 조합해서\n",
    "3. 일정 기준치가 넘으면 흥분을 하고\n",
    "4. 흥분을 하면 terminal로 신호를 보냄\n",
    "\n",
    "### Perceptron (Neuron의 수학적인 모델링)\n",
    "\n",
    "<img src=\"./img/perceptron.jpg\" width=70% height=70%>\n",
    "\n",
    "### 인공신경망\n",
    "- perceptron 이 모여 Layer를 이루는 것  \n",
    "\n",
    "<img src=\"./img/neuralnet.png\" width=70% height=70%>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Process\n",
    "\n",
    "1. 데이터를 준비한다. (전처리)\n",
    "    - 결측치, 이상치 처리\n",
    "    - normalization & one-hot encoding\n",
    "    - feature extraction & feature engineering\n",
    "    - augmentation  \n",
    "    \n",
    "\n",
    "2. 적절한 모델을 선택한다. (혹은 구성한다.)\n",
    "\n",
    "3. 모델을 학습시킨다.\n",
    "\n",
    "4. 학습된 모델을 평가한다.\n",
    "\n",
    "---\n",
    "### normalization & one-hot encoding\n",
    "\n",
    "- 수치형 - normalization\n",
    "    - minmax normalization\n",
    "    - standardization\n",
    "#\n",
    "- 범주형 - one-hot encoding\n",
    "    - tf.keras.utils.to_categorical\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer?\n",
    " - Nand Gate 를 쌓아 Not gate , And gate , Or gate 를 만듦\n",
    " - Nand Gate 만으로 컴퓨터를 완성할 수 있음\n",
    " - Nand Gate 는 Universal Gate 라고도 불림\n",
    "\n",
    "<img src=\"./img/a1.png\" width=70% height=700%>\n",
    "\n",
    "<img src=\"./img/a2.png\" width=50% height=50%>\n",
    "\n",
    "- Nand gate 들을 연결하면 Not, and, or 다 만들 수 있음\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers\n",
    "\n",
    "- 신경망 모델을 구성하는 기본 빌딩 블럭\n",
    "- 주요 블럭 종류 (링크 가서 찾아보기)\n",
    "\n",
    "    - tf.keras.layers.InputLayer\n",
    "    - [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "    - tf.keras.layers.Activation\n",
    "    - tf.keras.layers.Dropout\n",
    "    - tf.keras.layers.BatchNormalization\n",
    "    - tf.keras.layers.Conv2D, tf.keras.layers.MaxPool2D, tf.keras.layers.Flatten\n",
    "    - tf.keras.layers.SimpleRNN, tf.keras.layers.LSTM, tf.keras.layers.GRU\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression / Logistic Regression\n",
    "- 선형 회귀 / 로지스틱 회귀\n",
    "\n",
    "1. 평균과 분산\n",
    "\n",
    "$$\n",
    "s^2 = {\\sum^n_{i=1}(x_i - \\bar x)^2 \\over n-1}\n",
    "$$\n",
    "\n",
    "- 평균: 자료의 중심값으로 자료를 대표하는 값\n",
    "- 분산: 자료들이 평균을 중심으로 퍼져있는 평균적인 거리\n",
    "- 분산 = 편차제곱합의 평균\n",
    "- 평균 = 편차제곱합이 최소가 되도록 하는 값\n",
    "- 평균과 표준편차는 이상치에 취약하다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모평균 = $m$\n",
    "- 모분산 = $\\sigma^2$\n",
    "- 모표준편차 = $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 표본평균 = $\\bar X$\n",
    "- 표본분산 = $S^2$\n",
    "- 표본표준편차 = $S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = [40, 42, 44, 46, 48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 예제\n",
    "\n",
    "판매량이 40, 42, 44, 46, 48 일때.\n",
    "\n",
    "### - 평균 \n",
    "$$\n",
    "(모평균) : m =  {\\sum^n_{i=1}x_i \\over n}\n",
    "$$\n",
    "$$\n",
    "(표본평균) : \\bar x =  {\\sum^n_{i=1}x_i \\over n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.0\n",
      "44.0\n"
     ]
    }
   ],
   "source": [
    "# 따라서 평균은 \n",
    "y = (40 + 42 + 44 + 46  + 48) / 5\n",
    "\n",
    "print(y)\n",
    "\n",
    "print(np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 분산과 표준편차\n",
    "\n",
    "- 모집단의 분산(모분산) / 모집단의 표준편차(모표준편차)\n",
    "\n",
    "$$\n",
    "(모분산(\\sigma^2)) : v =  {\\sum^n_{i=1}(x_i - \\bar x)^2 \\over n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(모표준편차(\\sigma)) : \\sigma = \\sqrt \\sigma^2 =  \\sqrt{{\\sum^n_{i=1}(x_i - \\bar x)^2 \\over n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 표본의 분산(표본분산) / 표본의 표준편차(표본표준편차)\n",
    "$$\n",
    "(표본분산(s^2)) : v =  {\\sum^n_{i=1}(x_i - \\bar x)^2 \\over n-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(표본표준편차(s)) : s = \\sqrt s^2 =  \\sqrt{{\\sum^n_{i=1}(x_i - \\bar x)^2 \\over n-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Loss (mse : 평균 제곱 오차) => 모분산과 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.0, -2.0, 0.0, 2.0, 4.0]\n",
      "[16.0, 4.0, 0.0, 4.0, 16.0]\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "# 평균 = 44 => np.mean(x)\n",
    "\n",
    "# loss 는 각 값과 평균의 차를 제곱한 값들을 합하고, n으로 나눠준다.\n",
    "\n",
    "# 각 값과 평균값의 차\n",
    "lo = []\n",
    "for i in x:\n",
    "    k = i - np.mean(x)\n",
    "    lo.append(k)\n",
    "\n",
    "# 구한 값의 제곱\n",
    "lo2 = []\n",
    "for i in lo:\n",
    "    k = i ** 2\n",
    "    lo2.append(k)\n",
    "    \n",
    "# 나누기 n\n",
    "lo3 = np.sum(lo2) / len(lo2)\n",
    "\n",
    "print(lo)\n",
    "print(lo2)\n",
    "print(lo3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - RMSE = 분산의 Root = 모표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8284271247461903"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(lo3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀와 로지스틱회귀\n",
    "\n",
    "- 최적의 그래프 찾기\n",
    "    - a. 그래프와 각데이터의 오차구하기\n",
    "    - b. 오차를 모두 더한다.\n",
    "    - c. 오차의 합이 최소가 되게 한다.\n",
    "\n",
    "<img src=\"./img/d1.png\" width=30% height=30%>  \n",
    "\n",
    "만일 위 그래프가 온도/판매량 그래프라 하면,  \n",
    "빨간 점들을 가장 잘 설명하는 직선을 찾아야 한다.  \n",
    "=> 선형 회귀\n",
    "\n",
    "<img src=\"./img/d2.png\" width=40% height=40%> class => sigmoid 함수로 대체\n",
    "\n",
    "만일 위 그래프가 체온/감염여부 라면,  \n",
    "빨간 점들은 정상(0), 감염(1)로 표현한다.  \n",
    "이 0과 1의 관계를 가장 잘 설명하는 곡선을 찾아야 한다.  \n",
    "=> 로지스틱 회귀\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀와 최소제곱추정\n",
    "\n",
    "<img src=\"./img/d3.png\" width=40% height=40%>\n",
    "\n",
    "예측값 직션 y = wx + b 를 추정하고, 각 점과 직선의 차이 만큼이 loss.\n",
    "\n",
    "이 loss 를 제곱하여 더하면 = mse = 분산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3월 29일 = 1시간 39분"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40b396f7bb4524eebe16d5148ef674cb630ecbb9edf31b1d2c1678c5ede47175"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('webai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
