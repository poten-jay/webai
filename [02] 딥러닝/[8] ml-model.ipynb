{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML - Model  추가\n",
    "\n",
    "220405 / CNN(4) / 3:14\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1StIDi_nbt49LL01FzBtxxcvpSSgI9-xy#scrollTo=-l4CViARu4d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAY\\anaconda3\\envs\\webai\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "# 암 진단 데이터 (분류)\n",
    "cancer = datasets.load_breast_cancer()\n",
    "# 보스턴 집값 데이터 (회귀)\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "dfy = pd.DataFrame(cancer.target, columns=[\"Y\"])\n",
    "df_cancer = pd.concat([dfX, dfy], axis=1)\n",
    "\n",
    "dfX = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "dfy = pd.DataFrame(boston.target, columns=[\"Y\"])\n",
    "df_boston = pd.concat([dfX, dfy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.05</td>\n",
       "      <td>18.59</td>\n",
       "      <td>85.09</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.09603</td>\n",
       "      <td>0.05603</td>\n",
       "      <td>0.2035</td>\n",
       "      <td>0.06501</td>\n",
       "      <td>...</td>\n",
       "      <td>24.85</td>\n",
       "      <td>94.22</td>\n",
       "      <td>591.2</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.12580</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>0.08317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.22</td>\n",
       "      <td>24.91</td>\n",
       "      <td>171.50</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.33390</td>\n",
       "      <td>0.18450</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>...</td>\n",
       "      <td>33.62</td>\n",
       "      <td>211.70</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>0.15730</td>\n",
       "      <td>0.6076</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.28670</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>0.10510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.26</td>\n",
       "      <td>18.17</td>\n",
       "      <td>91.22</td>\n",
       "      <td>633.1</td>\n",
       "      <td>0.06576</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.02475</td>\n",
       "      <td>0.01374</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.05586</td>\n",
       "      <td>...</td>\n",
       "      <td>25.26</td>\n",
       "      <td>105.80</td>\n",
       "      <td>819.7</td>\n",
       "      <td>0.09445</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.07530</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>0.07676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.53</td>\n",
       "      <td>19.34</td>\n",
       "      <td>94.25</td>\n",
       "      <td>659.7</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.08817</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.05746</td>\n",
       "      <td>...</td>\n",
       "      <td>28.39</td>\n",
       "      <td>108.10</td>\n",
       "      <td>830.5</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.2471</td>\n",
       "      <td>0.07463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.42</td>\n",
       "      <td>19.77</td>\n",
       "      <td>94.48</td>\n",
       "      <td>642.5</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.1141</td>\n",
       "      <td>0.09388</td>\n",
       "      <td>0.05839</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.06390</td>\n",
       "      <td>...</td>\n",
       "      <td>30.86</td>\n",
       "      <td>109.50</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.3194</td>\n",
       "      <td>0.15650</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        13.05         18.59           85.09      512.0          0.10820   \n",
       "1        25.22         24.91          171.50     1878.0          0.10630   \n",
       "2        14.26         18.17           91.22      633.1          0.06576   \n",
       "3        14.53         19.34           94.25      659.7          0.08388   \n",
       "4        14.42         19.77           94.48      642.5          0.09752   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.1304         0.09603              0.05603         0.2035   \n",
       "1            0.2665         0.33390              0.18450         0.1829   \n",
       "2            0.0522         0.02475              0.01374         0.1635   \n",
       "3            0.0780         0.08817              0.02925         0.1473   \n",
       "4            0.1141         0.09388              0.05839         0.1879   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.06501  ...          24.85            94.22       591.2   \n",
       "1                 0.06782  ...          33.62           211.70      2562.0   \n",
       "2                 0.05586  ...          25.26           105.80       819.7   \n",
       "3                 0.05746  ...          28.39           108.10       830.5   \n",
       "4                 0.06390  ...          30.86           109.50       826.4   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0           0.13430             0.2658           0.2573               0.12580   \n",
       "1           0.15730             0.6076           0.6476               0.28670   \n",
       "2           0.09445             0.2167           0.1565               0.07530   \n",
       "3           0.10890             0.2649           0.3779               0.09594   \n",
       "4           0.14310             0.3026           0.3194               0.15650   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  Y  \n",
       "0          0.3113                  0.08317  1  \n",
       "1          0.2355                  0.10510  0  \n",
       "2          0.2636                  0.07676  1  \n",
       "3          0.2471                  0.07463  1  \n",
       "4          0.2718                  0.09353  0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_cancer = df_cancer.sample(frac=1).reset_index(drop=True)\n",
    "df_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04666</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404</td>\n",
       "      <td>7.107</td>\n",
       "      <td>36.6</td>\n",
       "      <td>7.3090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>354.31</td>\n",
       "      <td>8.61</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01965</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385</td>\n",
       "      <td>6.230</td>\n",
       "      <td>31.5</td>\n",
       "      <td>9.0892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>341.60</td>\n",
       "      <td>12.93</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.55778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.335</td>\n",
       "      <td>98.2</td>\n",
       "      <td>2.1107</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>394.67</td>\n",
       "      <td>16.96</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.174</td>\n",
       "      <td>93.6</td>\n",
       "      <td>1.6119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>388.08</td>\n",
       "      <td>24.16</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.34940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.972</td>\n",
       "      <td>76.7</td>\n",
       "      <td>3.1025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.24</td>\n",
       "      <td>9.97</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.04666  80.0   1.52   0.0  0.404  7.107  36.6  7.3090  2.0  329.0   \n",
       "1  0.01965  80.0   1.76   0.0  0.385  6.230  31.5  9.0892  1.0  241.0   \n",
       "2  0.55778   0.0  21.89   0.0  0.624  6.335  98.2  2.1107  4.0  437.0   \n",
       "3  0.29090   0.0  21.89   0.0  0.624  6.174  93.6  1.6119  4.0  437.0   \n",
       "4  0.34940   0.0   9.90   0.0  0.544  5.972  76.7  3.1025  4.0  304.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT     Y  \n",
       "0     12.6  354.31   8.61  30.3  \n",
       "1     18.2  341.60  12.93  20.1  \n",
       "2     21.2  394.67  16.96  18.1  \n",
       "3     21.2  388.08  24.16  14.0  \n",
       "4     18.4  396.24   9.97  20.3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston = df_boston.sample(frac=1).reset_index(drop=True)\n",
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 지도학습\n",
    "\n",
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9411764705882353\n",
      "[[36  5]\n",
      " [ 2 76]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAY\\anaconda3\\envs\\webai\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# classification\n",
    "\n",
    "X = df_cancer.iloc[:450, :-1] # 독립변수\n",
    "y = df_cancer.iloc[:450, -1:] # 종속변수\n",
    "testx = df_cancer.iloc[450:, :-1] # 테스트 데이터 분리\n",
    "testy = df_cancer.iloc[450:, -1:]\n",
    "\n",
    "knn_model = neighbors.KNeighborsClassifier() # 모델선택\n",
    "knn_model.fit(X, y) # 학습\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = knn_model.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1720664256282625\n",
      "0.7037437524015552\n",
      "5.503572865486046\n",
      "-0.6578484600541195\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "knn_model = neighbors.KNeighborsRegressor()\n",
    "knn_model.fit(X, y)\n",
    "\n",
    "# 학습한 데이터로 평가\n",
    "y_pred = knn_model.predict(X)\n",
    "print(metrics.mean_squared_error(y, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(y, y_pred))\n",
    "\n",
    "# 모르는 데이터로 평가\n",
    "y_pred = knn_model.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1720664256282625  \n",
    "0.7037437524015552  \n",
    "5.503572865486046  \n",
    "-0.6578484600541195 <- R^2 음수라면, 평균보다 못한... 엉망이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Linear / Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9327731092436975\n",
      "[[26  1]\n",
      " [ 7 85]]\n"
     ]
    }
   ],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "logit = linear_model.LogisticRegression(max_iter=5000)\n",
    "logit.fit(X, y)\n",
    "\n",
    "y_pred = logit.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9327731092436975  : 정확도 (93%)  \n",
    "# [[26  1]   [참예측=참,   1     ]  \n",
    "#  [ 7 85]]  [ 7, 거짓예측 = 거짓]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3774255386059195\n",
      "0.37565166960622753\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(X, y)\n",
    "\n",
    "y_pred = linear.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ridge / Lasso / ElasticNet\n",
    "\n",
    "---\n",
    "\n",
    "- Ridge : L2 loss\n",
    "- Lasso : L1 loss\n",
    "- ElasticNet : L1 + L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge\n",
      "3.4551260178628693\n",
      "0.3465939182217851\n",
      "lasso\n",
      "3.5361499192026917\n",
      "0.31558940029904414\n",
      "elastic\n",
      "3.619456173717858\n",
      "0.28296222902760815\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "ridge = linear_model.Ridge(max_iter=1000)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "print(\"ridge\")\n",
    "y_pred = ridge.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))\n",
    "\n",
    "lasso = linear_model.Lasso(max_iter=1000)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "print(\"lasso\")\n",
    "y_pred = lasso.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))\n",
    "\n",
    "elastic = linear_model.ElasticNet(max_iter=1000)\n",
    "elastic.fit(X, y)\n",
    "\n",
    "print(\"elastic\")\n",
    "y_pred = elastic.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge\n",
      "3.4551260178628693\n",
      "0.3465939182217851\n",
      "lasso\n",
      "3.5361499192026917\n",
      "0.31558940029904414\n",
      "elastic\n",
      "3.619456173717858\n",
      "0.28296222902760815\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "ridge = linear_model.Ridge(max_iter=1000)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "print(\"ridge\")\n",
    "y_pred = ridge.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))\n",
    "\n",
    "lasso = linear_model.Lasso(max_iter=1000)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "print(\"lasso\")\n",
    "y_pred = lasso.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))\n",
    "\n",
    "elastic = linear_model.ElasticNet(max_iter=1000)\n",
    "elastic.fit(X, y)\n",
    "\n",
    "print(\"elastic\")\n",
    "y_pred = elastic.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Dicision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n",
      "[[25  2]\n",
      " [12 80]]\n"
     ]
    }
   ],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "y_pred = tree_model.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0204388530891215\n",
      "0.11528719871990001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.6793402719188715, 0.975, 'X[5] <= 6.941\\nsquared_error = 90.294\\nsamples = 450\\nvalue = 23.044'),\n",
       " Text(0.4375311107923866, 0.925, 'X[12] <= 14.4\\nsquared_error = 43.078\\nsamples = 378\\nvalue = 20.201'),\n",
       " Text(0.20779372806425486, 0.875, 'X[7] <= 1.385\\nsquared_error = 27.184\\nsamples = 232\\nvalue = 23.614'),\n",
       " Text(0.13792943439524838, 0.825, 'X[12] <= 10.83\\nsquared_error = 78.146\\nsamples = 5\\nvalue = 45.58'),\n",
       " Text(0.13576960718142547, 0.775, 'squared_error = 0.0\\nsamples = 4\\nvalue = 50.0'),\n",
       " Text(0.14008926160907129, 0.775, 'squared_error = -0.0\\nsamples = 1\\nvalue = 27.9'),\n",
       " Text(0.2776580217332613, 0.825, 'X[5] <= 6.543\\nsquared_error = 15.199\\nsamples = 227\\nvalue = 23.13'),\n",
       " Text(0.14440891603671707, 0.775, 'X[12] <= 9.66\\nsquared_error = 8.406\\nsamples = 175\\nvalue = 21.773'),\n",
       " Text(0.06652436555075594, 0.725, 'X[9] <= 222.5\\nsquared_error = 7.238\\nsamples = 84\\nvalue = 23.102'),\n",
       " Text(0.03914686825053996, 0.675, 'X[7] <= 4.33\\nsquared_error = 14.062\\nsamples = 2\\nvalue = 32.45'),\n",
       " Text(0.036987041036717065, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 36.2'),\n",
       " Text(0.04130669546436285, 0.625, 'squared_error = -0.0\\nsamples = 1\\nvalue = 28.7'),\n",
       " Text(0.09390186285097192, 0.675, 'X[5] <= 6.145\\nsquared_error = 4.888\\nsamples = 82\\nvalue = 22.874'),\n",
       " Text(0.04562634989200864, 0.625, 'X[2] <= 13.375\\nsquared_error = 3.861\\nsamples = 30\\nvalue = 21.407'),\n",
       " Text(0.025377969762419007, 0.575, 'X[2] <= 3.44\\nsquared_error = 2.193\\nsamples = 27\\nvalue = 20.981'),\n",
       " Text(0.008639308855291577, 0.525, 'X[11] <= 379.42\\nsquared_error = 0.91\\nsamples = 4\\nvalue = 19.3'),\n",
       " Text(0.004319654427645789, 0.475, 'X[9] <= 382.0\\nsquared_error = 0.16\\nsamples = 2\\nvalue = 20.2'),\n",
       " Text(0.0021598272138228943, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.6'),\n",
       " Text(0.0064794816414686825, 0.425, 'squared_error = -0.0\\nsamples = 1\\nvalue = 19.8'),\n",
       " Text(0.012958963282937365, 0.475, 'X[4] <= 0.412\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 18.4'),\n",
       " Text(0.01079913606911447, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.6'),\n",
       " Text(0.01511879049676026, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.2'),\n",
       " Text(0.042116630669546434, 0.525, 'X[6] <= 35.75\\nsquared_error = 1.839\\nsamples = 23\\nvalue = 21.274'),\n",
       " Text(0.026997840172786176, 0.475, 'X[0] <= 0.044\\nsquared_error = 1.91\\nsamples = 10\\nvalue = 21.98'),\n",
       " Text(0.019438444924406047, 0.425, 'X[12] <= 7.92\\nsquared_error = 0.576\\nsamples = 3\\nvalue = 20.467'),\n",
       " Text(0.017278617710583154, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.4'),\n",
       " Text(0.02159827213822894, 0.375, 'X[4] <= 0.453\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 21.0'),\n",
       " Text(0.019438444924406047, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.9'),\n",
       " Text(0.023758099352051837, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.1'),\n",
       " Text(0.03455723542116631, 0.425, 'X[4] <= 0.411\\nsquared_error = 1.079\\nsamples = 7\\nvalue = 22.629'),\n",
       " Text(0.03023758099352052, 0.375, 'X[11] <= 396.555\\nsquared_error = 0.247\\nsamples = 3\\nvalue = 21.6'),\n",
       " Text(0.028077753779697623, 0.325, 'X[1] <= 46.25\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 21.95'),\n",
       " Text(0.02591792656587473, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.0'),\n",
       " Text(0.03023758099352052, 0.275, 'squared_error = -0.0\\nsamples = 1\\nvalue = 21.9'),\n",
       " Text(0.032397408207343416, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.9'),\n",
       " Text(0.038876889848812095, 0.375, 'X[5] <= 6.086\\nsquared_error = 0.315\\nsamples = 4\\nvalue = 23.4'),\n",
       " Text(0.0367170626349892, 0.325, 'X[0] <= 0.071\\nsquared_error = 0.06\\nsamples = 3\\nvalue = 23.1'),\n",
       " Text(0.03455723542116631, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.4'),\n",
       " Text(0.038876889848812095, 0.275, 'X[6] <= 18.55\\nsquared_error = 0.022\\nsamples = 2\\nvalue = 22.95'),\n",
       " Text(0.0367170626349892, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.8'),\n",
       " Text(0.04103671706263499, 0.225, 'squared_error = -0.0\\nsamples = 1\\nvalue = 23.1'),\n",
       " Text(0.04103671706263499, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.3'),\n",
       " Text(0.05723542116630669, 0.475, 'X[7] <= 3.841\\nsquared_error = 1.107\\nsamples = 13\\nvalue = 20.731'),\n",
       " Text(0.04967602591792657, 0.425, 'X[12] <= 9.04\\nsquared_error = 0.047\\nsamples = 3\\nvalue = 22.3'),\n",
       " Text(0.047516198704103674, 0.375, 'X[6] <= 54.8\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 22.15'),\n",
       " Text(0.04535637149028078, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.1'),\n",
       " Text(0.04967602591792657, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.2'),\n",
       " Text(0.05183585313174946, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.6'),\n",
       " Text(0.06479481641468683, 0.425, 'X[6] <= 44.35\\nsquared_error = 0.464\\nsamples = 10\\nvalue = 20.26'),\n",
       " Text(0.058315334773218146, 0.375, 'X[6] <= 38.65\\nsquared_error = 0.122\\nsamples = 4\\nvalue = 20.775'),\n",
       " Text(0.05399568034557235, 0.325, 'X[10] <= 19.45\\nsquared_error = 0.022\\nsamples = 2\\nvalue = 20.45'),\n",
       " Text(0.05183585313174946, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.3'),\n",
       " Text(0.056155507559395246, 0.275, 'squared_error = -0.0\\nsamples = 1\\nvalue = 20.6'),\n",
       " Text(0.06263498920086392, 0.325, 'X[8] <= 4.0\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 21.1'),\n",
       " Text(0.06047516198704104, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.2'),\n",
       " Text(0.06479481641468683, 0.275, 'squared_error = -0.0\\nsamples = 1\\nvalue = 21.0'),\n",
       " Text(0.07127429805615551, 0.375, 'X[9] <= 233.5\\nsquared_error = 0.398\\nsamples = 6\\nvalue = 19.917'),\n",
       " Text(0.06911447084233262, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.7'),\n",
       " Text(0.0734341252699784, 0.325, 'X[5] <= 5.938\\nsquared_error = 0.122\\nsamples = 5\\nvalue = 20.16'),\n",
       " Text(0.06911447084233262, 0.275, 'X[6] <= 51.85\\nsquared_error = 0.023\\nsamples = 2\\nvalue = 19.75'),\n",
       " Text(0.06695464362850972, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.6'),\n",
       " Text(0.07127429805615551, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.9'),\n",
       " Text(0.07775377969762419, 0.275, 'X[0] <= 0.197\\nsquared_error = 0.002\\nsamples = 3\\nvalue = 20.433'),\n",
       " Text(0.0755939524838013, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.5'),\n",
       " Text(0.07991360691144708, 0.225, 'squared_error = 0.0\\nsamples = 2\\nvalue = 20.4'),\n",
       " Text(0.06587473002159827, 0.575, 'X[0] <= 2.949\\nsquared_error = 2.596\\nsamples = 3\\nvalue = 25.233'),\n",
       " Text(0.06371490280777538, 0.525, 'X[6] <= 59.2\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 24.1'),\n",
       " Text(0.061555075593952485, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.9'),\n",
       " Text(0.06587473002159827, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 24.3'),\n",
       " Text(0.06803455723542116, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 27.5'),\n",
       " Text(0.1421773758099352, 0.625, 'X[5] <= 6.539\\nsquared_error = 3.521\\nsamples = 52\\nvalue = 23.721'),\n",
       " Text(0.14001754859611232, 0.575, 'X[2] <= 5.48\\nsquared_error = 2.548\\nsamples = 51\\nvalue = 23.863'),\n",
       " Text(0.11609071274298056, 0.525, 'X[4] <= 0.512\\nsquared_error = 0.952\\nsamples = 23\\nvalue = 23.091'),\n",
       " Text(0.10583153347732181, 0.475, 'X[12] <= 6.725\\nsquared_error = 0.708\\nsamples = 21\\nvalue = 23.248'),\n",
       " Text(0.091792656587473, 0.425, 'X[9] <= 324.0\\nsquared_error = 0.611\\nsamples = 9\\nvalue = 23.722'),\n",
       " Text(0.08639308855291576, 0.375, 'X[2] <= 4.895\\nsquared_error = 0.244\\nsamples = 5\\nvalue = 24.3'),\n",
       " Text(0.08423326133909287, 0.325, 'X[9] <= 288.5\\nsquared_error = 0.007\\nsamples = 3\\nvalue = 24.7'),\n",
       " Text(0.08207343412526998, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.8'),\n",
       " Text(0.08639308855291576, 0.275, 'X[11] <= 396.25\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 24.65'),\n",
       " Text(0.08423326133909287, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.6'),\n",
       " Text(0.08855291576673865, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.7'),\n",
       " Text(0.08855291576673865, 0.325, 'squared_error = -0.0\\nsamples = 2\\nvalue = 23.7'),\n",
       " Text(0.09719222462203024, 0.375, 'X[1] <= 75.0\\nsquared_error = 0.13\\nsamples = 4\\nvalue = 23.0'),\n",
       " Text(0.09287257019438445, 0.325, 'X[9] <= 346.5\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 22.7'),\n",
       " Text(0.09071274298056156, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.9'),\n",
       " Text(0.09503239740820735, 0.275, 'squared_error = -0.0\\nsamples = 1\\nvalue = 22.5'),\n",
       " Text(0.10151187904967603, 0.325, 'X[10] <= 17.0\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 23.3'),\n",
       " Text(0.09935205183585313, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.5'),\n",
       " Text(0.10367170626349892, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.1'),\n",
       " Text(0.11987041036717062, 0.425, 'X[12] <= 8.925\\nsquared_error = 0.486\\nsamples = 12\\nvalue = 22.892'),\n",
       " Text(0.11447084233261338, 0.375, 'X[5] <= 6.262\\nsquared_error = 0.402\\nsamples = 10\\nvalue = 22.72'),\n",
       " Text(0.1101511879049676, 0.325, 'X[10] <= 15.65\\nsquared_error = 0.197\\nsamples = 4\\nvalue = 23.375'),\n",
       " Text(0.1079913606911447, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.1'),\n",
       " Text(0.11231101511879049, 0.275, 'X[7] <= 6.359\\nsquared_error = 0.029\\nsamples = 3\\nvalue = 23.133'),\n",
       " Text(0.1101511879049676, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.9'),\n",
       " Text(0.11447084233261338, 0.225, 'X[12] <= 7.0\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 23.25'),\n",
       " Text(0.11231101511879049, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.3'),\n",
       " Text(0.11663066954643629, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.2'),\n",
       " Text(0.11879049676025918, 0.325, 'X[11] <= 392.865\\nsquared_error = 0.061\\nsamples = 6\\nvalue = 22.283'),\n",
       " Text(0.11663066954643629, 0.275, 'squared_error = 0.0\\nsamples = 2\\nvalue = 22.6'),\n",
       " Text(0.12095032397408208, 0.275, 'X[8] <= 4.0\\nsquared_error = 0.017\\nsamples = 4\\nvalue = 22.125'),\n",
       " Text(0.11879049676025918, 0.225, 'squared_error = 0.0\\nsamples = 2\\nvalue = 22.0'),\n",
       " Text(0.12311015118790497, 0.225, 'X[4] <= 0.429\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 22.25'),\n",
       " Text(0.12095032397408208, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.3'),\n",
       " Text(0.12526997840172785, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.2'),\n",
       " Text(0.12526997840172785, 0.375, 'X[10] <= 17.55\\nsquared_error = 0.022\\nsamples = 2\\nvalue = 23.75'),\n",
       " Text(0.12311015118790497, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.6'),\n",
       " Text(0.12742980561555076, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.9'),\n",
       " Text(0.1263498920086393, 0.475, 'X[12] <= 6.215\\nsquared_error = 0.563\\nsamples = 2\\nvalue = 21.45'),\n",
       " Text(0.12419006479481641, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.2'),\n",
       " Text(0.1285097192224622, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.7'),\n",
       " Text(0.16394438444924406, 0.525, 'X[1] <= 31.0\\nsquared_error = 2.968\\nsamples = 28\\nvalue = 24.496'),\n",
       " Text(0.15618250539956804, 0.475, 'X[6] <= 43.7\\nsquared_error = 2.179\\nsamples = 26\\nvalue = 24.246'),\n",
       " Text(0.14713822894168466, 0.425, 'X[12] <= 8.46\\nsquared_error = 1.181\\nsamples = 15\\nvalue = 24.787'),\n",
       " Text(0.1398488120950324, 0.375, 'X[10] <= 18.65\\nsquared_error = 0.441\\nsamples = 13\\nvalue = 24.515'),\n",
       " Text(0.13174946004319654, 0.325, 'X[12] <= 7.015\\nsquared_error = 0.042\\nsamples = 5\\nvalue = 25.04'),\n",
       " Text(0.12958963282937366, 0.275, 'X[0] <= 0.098\\nsquared_error = 0.017\\nsamples = 4\\nvalue = 25.125'),\n",
       " Text(0.12742980561555076, 0.225, 'squared_error = 0.0\\nsamples = 2\\nvalue = 25.0'),\n",
       " Text(0.13174946004319654, 0.225, 'X[2] <= 6.935\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 25.25'),\n",
       " Text(0.12958963282937366, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 25.3'),\n",
       " Text(0.13390928725701945, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 25.2'),\n",
       " Text(0.13390928725701945, 0.275, 'squared_error = -0.0\\nsamples = 1\\nvalue = 24.7'),\n",
       " Text(0.14794816414686826, 0.325, 'X[5] <= 6.363\\nsquared_error = 0.411\\nsamples = 8\\nvalue = 24.188'),\n",
       " Text(0.14254859611231102, 0.275, 'X[2] <= 11.82\\nsquared_error = 0.207\\nsamples = 3\\nvalue = 23.5'),\n",
       " Text(0.14038876889848811, 0.225, 'X[9] <= 296.0\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 23.2'),\n",
       " Text(0.13822894168466524, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.0'),\n",
       " Text(0.14254859611231102, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.4'),\n",
       " Text(0.1447084233261339, 0.225, 'squared_error = -0.0\\nsamples = 1\\nvalue = 24.1'),\n",
       " Text(0.15334773218142547, 0.275, 'X[0] <= 0.166\\nsquared_error = 0.08\\nsamples = 5\\nvalue = 24.6'),\n",
       " Text(0.1490280777537797, 0.225, 'X[4] <= 0.422\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 24.3'),\n",
       " Text(0.1468682505399568, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.2'),\n",
       " Text(0.1511879049676026, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.4'),\n",
       " Text(0.15766738660907129, 0.225, 'X[6] <= 27.4\\nsquared_error = 0.027\\nsamples = 3\\nvalue = 24.8'),\n",
       " Text(0.15550755939524838, 0.175, 'X[4] <= 0.462\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 24.7'),\n",
       " Text(0.15334773218142547, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.8'),\n",
       " Text(0.15766738660907129, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.6'),\n",
       " Text(0.15982721382289417, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 25.0'),\n",
       " Text(0.15442764578833693, 0.375, 'X[6] <= 37.35\\nsquared_error = 2.403\\nsamples = 2\\nvalue = 26.55'),\n",
       " Text(0.15226781857451405, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.1'),\n",
       " Text(0.15658747300215983, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 25.0'),\n",
       " Text(0.1652267818574514, 0.425, 'X[11] <= 351.615\\nsquared_error = 2.599\\nsamples = 11\\nvalue = 23.509'),\n",
       " Text(0.1630669546436285, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 27.0'),\n",
       " Text(0.1673866090712743, 0.375, 'X[5] <= 6.331\\nsquared_error = 1.518\\nsamples = 10\\nvalue = 23.16'),\n",
       " Text(0.16090712742980562, 0.325, 'X[9] <= 351.0\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 21.5'),\n",
       " Text(0.1587473002159827, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.6'),\n",
       " Text(0.1630669546436285, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.4'),\n",
       " Text(0.17386609071274298, 0.325, 'X[0] <= 0.078\\nsquared_error = 1.034\\nsamples = 8\\nvalue = 23.575'),\n",
       " Text(0.1673866090712743, 0.275, 'X[0] <= 0.035\\nsquared_error = 0.423\\nsamples = 2\\nvalue = 22.25'),\n",
       " Text(0.1652267818574514, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.6'),\n",
       " Text(0.1695464362850972, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.9'),\n",
       " Text(0.18034557235421167, 0.275, 'X[12] <= 7.56\\nsquared_error = 0.458\\nsamples = 6\\nvalue = 24.017'),\n",
       " Text(0.17386609071274298, 0.225, 'X[6] <= 53.3\\nsquared_error = 0.087\\nsamples = 3\\nvalue = 23.4'),\n",
       " Text(0.1717062634989201, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.8'),\n",
       " Text(0.17602591792656588, 0.175, 'X[6] <= 77.15\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 23.2'),\n",
       " Text(0.17386609071274298, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.1'),\n",
       " Text(0.17818574514038876, 0.125, 'squared_error = -0.0\\nsamples = 1\\nvalue = 23.3'),\n",
       " Text(0.18682505399568033, 0.225, 'X[10] <= 19.65\\nsquared_error = 0.069\\nsamples = 3\\nvalue = 24.633'),\n",
       " Text(0.18466522678185746, 0.175, 'X[10] <= 18.85\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 24.45'),\n",
       " Text(0.18250539956803455, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.4'),\n",
       " Text(0.18682505399568033, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.5'),\n",
       " Text(0.18898488120950324, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 25.0'),\n",
       " Text(0.1717062634989201, 0.475, 'X[11] <= 390.255\\nsquared_error = 1.823\\nsamples = 2\\nvalue = 27.75'),\n",
       " Text(0.1695464362850972, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 26.4'),\n",
       " Text(0.17386609071274298, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 29.1'),\n",
       " Text(0.1443372030237581, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.5'),\n",
       " Text(0.22229346652267817, 0.725, 'X[2] <= 2.675\\nsquared_error = 6.346\\nsamples = 91\\nvalue = 20.545'),\n",
       " Text(0.19114470842332612, 0.675, 'X[5] <= 6.191\\nsquared_error = 15.576\\nsamples = 3\\nvalue = 25.367'),\n",
       " Text(0.18898488120950324, 0.625, 'X[5] <= 5.878\\nsquared_error = 2.56\\nsamples = 2\\nvalue = 28.0'),\n",
       " Text(0.18682505399568033, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 26.4'),\n",
       " Text(0.19114470842332612, 0.575, 'squared_error = -0.0\\nsamples = 1\\nvalue = 29.6'),\n",
       " Text(0.19330453563714903, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.1'),\n",
       " Text(0.25344222462203025, 0.675, 'X[5] <= 5.814\\nsquared_error = 5.211\\nsamples = 88\\nvalue = 20.381'),\n",
       " Text(0.21004319654427644, 0.625, 'X[4] <= 0.606\\nsquared_error = 4.962\\nsamples = 21\\nvalue = 18.919'),\n",
       " Text(0.19546436285097193, 0.575, 'X[7] <= 2.639\\nsquared_error = 2.291\\nsamples = 14\\nvalue = 18.071'),\n",
       " Text(0.1900647948164147, 0.525, 'X[2] <= 14.0\\nsquared_error = 0.303\\nsamples = 2\\nvalue = 15.55'),\n",
       " Text(0.1879049676025918, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.1'),\n",
       " Text(0.19222462203023757, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 15.0'),\n",
       " Text(0.20086393088552915, 0.525, 'X[6] <= 75.4\\nsquared_error = 1.386\\nsamples = 12\\nvalue = 18.492'),\n",
       " Text(0.19654427645788336, 0.475, 'X[6] <= 29.75\\nsquared_error = 0.957\\nsamples = 10\\nvalue = 18.81'),\n",
       " Text(0.19438444924406048, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.1'),\n",
       " Text(0.19870410367170627, 0.425, 'X[6] <= 36.7\\nsquared_error = 0.702\\nsamples = 9\\nvalue = 19.0'),\n",
       " Text(0.19114470842332612, 0.375, 'X[0] <= 0.18\\nsquared_error = 0.147\\nsamples = 4\\nvalue = 19.725'),\n",
       " Text(0.18682505399568033, 0.325, 'X[2] <= 5.14\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 19.35'),\n",
       " Text(0.18466522678185746, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.4'),\n",
       " Text(0.18898488120950324, 0.275, 'squared_error = -0.0\\nsamples = 1\\nvalue = 19.3'),\n",
       " Text(0.19546436285097193, 0.325, 'X[2] <= 7.525\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 20.1'),\n",
       " Text(0.19330453563714903, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.0'),\n",
       " Text(0.1976241900647948, 0.275, 'squared_error = -0.0\\nsamples = 1\\nvalue = 20.2'),\n",
       " Text(0.20626349892008639, 0.375, 'X[11] <= 396.005\\nsquared_error = 0.39\\nsamples = 5\\nvalue = 18.42'),\n",
       " Text(0.2041036717062635, 0.325, 'X[10] <= 18.7\\nsquared_error = 0.162\\nsamples = 4\\nvalue = 18.675'),\n",
       " Text(0.2019438444924406, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.3'),\n",
       " Text(0.20626349892008639, 0.275, 'X[10] <= 20.35\\nsquared_error = 0.042\\nsamples = 3\\nvalue = 18.467'),\n",
       " Text(0.2041036717062635, 0.225, 'X[4] <= 0.473\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 18.6'),\n",
       " Text(0.2019438444924406, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.7'),\n",
       " Text(0.20626349892008639, 0.175, 'squared_error = -0.0\\nsamples = 1\\nvalue = 18.5'),\n",
       " Text(0.2084233261339093, 0.225, 'squared_error = -0.0\\nsamples = 1\\nvalue = 18.2'),\n",
       " Text(0.2084233261339093, 0.325, 'squared_error = -0.0\\nsamples = 1\\nvalue = 17.4'),\n",
       " Text(0.20518358531317496, 0.475, 'X[1] <= 11.0\\nsquared_error = 0.49\\nsamples = 2\\nvalue = 16.9'),\n",
       " Text(0.20302375809935205, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.2'),\n",
       " Text(0.20734341252699784, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.6'),\n",
       " Text(0.22462203023758098, 0.575, 'X[3] <= 0.5\\nsquared_error = 5.993\\nsamples = 7\\nvalue = 20.614'),\n",
       " Text(0.2224622030237581, 0.525, 'X[4] <= 0.744\\nsquared_error = 1.5\\nsamples = 6\\nvalue = 21.5'),\n",
       " Text(0.21706263498920086, 0.475, 'X[12] <= 13.665\\nsquared_error = 0.802\\nsamples = 4\\nvalue = 22.15'),\n",
       " Text(0.21274298056155508, 0.425, 'X[7] <= 1.749\\nsquared_error = 0.022\\nsamples = 2\\nvalue = 22.95'),\n",
       " Text(0.21058315334773217, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.1'),\n",
       " Text(0.21490280777537796, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 22.8'),\n",
       " Text(0.22138228941684665, 0.425, 'X[7] <= 1.852\\nsquared_error = 0.302\\nsamples = 2\\nvalue = 21.35'),\n",
       " Text(0.21922246220302377, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.9'),\n",
       " Text(0.22354211663066956, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 20.8'),\n",
       " Text(0.22786177105831534, 0.475, 'X[7] <= 1.848\\nsquared_error = 0.36\\nsamples = 2\\nvalue = 20.2'),\n",
       " Text(0.22570194384449244, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.6'),\n",
       " Text(0.23002159827213822, 0.425, 'squared_error = -0.0\\nsamples = 1\\nvalue = 20.8'),\n",
       " Text(0.2267818574514039, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 15.3'),\n",
       " Text(0.296841252699784, 0.625, 'X[10] <= 18.65\\nsquared_error = 4.41\\nsamples = 67\\nvalue = 20.839'),\n",
       " Text(0.27551295896328293, 0.575, 'X[9] <= 416.5\\nsquared_error = 3.215\\nsamples = 33\\nvalue = 21.721'),\n",
       " Text(0.25944924406047515, 0.525, 'X[12] <= 11.685\\nsquared_error = 2.78\\nsamples = 29\\nvalue = 22.021'),\n",
       " Text(0.24460043196544276, 0.475, 'X[11] <= 395.725\\nsquared_error = 1.706\\nsamples = 16\\nvalue = 22.788'),\n",
       " Text(0.234341252699784, 0.425, 'X[4] <= 0.467\\nsquared_error = 1.013\\nsamples = 12\\nvalue = 23.283'),\n",
       " Text(0.22894168466522677, 0.375, 'X[12] <= 11.28\\nsquared_error = 0.16\\nsamples = 2\\nvalue = 21.8'),\n",
       " Text(0.2267818574514039, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.2'),\n",
       " Text(0.23110151187904968, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.4'),\n",
       " Text(0.23974082073434125, 0.375, 'X[5] <= 6.35\\nsquared_error = 0.656\\nsamples = 10\\nvalue = 23.58'),\n",
       " Text(0.23542116630669546, 0.325, 'X[5] <= 5.918\\nsquared_error = 0.51\\nsamples = 7\\nvalue = 23.914'),\n",
       " Text(0.23326133909287258, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.7'),\n",
       " Text(0.23758099352051837, 0.275, 'X[6] <= 49.85\\nsquared_error = 0.308\\nsamples = 6\\nvalue = 24.117'),\n",
       " Text(0.23542116630669546, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.2'),\n",
       " Text(0.23974082073434125, 0.225, 'X[0] <= 2.612\\nsquared_error = 0.168\\nsamples = 5\\nvalue = 24.3'),\n",
       " Text(0.23758099352051837, 0.175, 'X[7] <= 3.662\\nsquared_error = 0.057\\nsamples = 4\\nvalue = 24.125'),\n",
       " Text(0.23326133909287258, 0.125, 'X[7] <= 2.876\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 23.9'),\n",
       " Text(0.23110151187904968, 0.075, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.8'),\n",
       " Text(0.23542116630669546, 0.075, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.0'),\n",
       " Text(0.24190064794816415, 0.125, 'X[9] <= 292.0\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 24.35'),\n",
       " Text(0.23974082073434125, 0.075, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.4'),\n",
       " Text(0.24406047516198703, 0.075, 'squared_error = -0.0\\nsamples = 1\\nvalue = 24.3'),\n",
       " Text(0.24190064794816415, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 25.0'),\n",
       " Text(0.24406047516198703, 0.325, 'X[7] <= 2.813\\nsquared_error = 0.127\\nsamples = 3\\nvalue = 22.8'),\n",
       " Text(0.24190064794816415, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.3'),\n",
       " Text(0.24622030237580994, 0.275, 'X[7] <= 3.448\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 23.05'),\n",
       " Text(0.24406047516198703, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.0'),\n",
       " Text(0.24838012958963282, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.1'),\n",
       " Text(0.2548596112311015, 0.425, 'X[6] <= 59.5\\nsquared_error = 0.835\\nsamples = 4\\nvalue = 21.3'),\n",
       " Text(0.2505399568034557, 0.375, 'X[2] <= 12.255\\nsquared_error = 0.203\\nsamples = 2\\nvalue = 22.15'),\n",
       " Text(0.24838012958963282, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.6'),\n",
       " Text(0.2526997840172786, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.7'),\n",
       " Text(0.2591792656587473, 0.375, 'X[0] <= 0.196\\nsquared_error = 0.022\\nsamples = 2\\nvalue = 20.45'),\n",
       " Text(0.2570194384449244, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.6'),\n",
       " Text(0.2613390928725702, 0.325, 'squared_error = -0.0\\nsamples = 1\\nvalue = 20.3'),\n",
       " Text(0.27429805615550756, 0.475, 'X[0] <= 0.089\\nsquared_error = 2.488\\nsamples = 13\\nvalue = 21.077'),\n",
       " Text(0.26997840172786175, 0.425, 'X[12] <= 13.185\\nsquared_error = 0.107\\nsamples = 3\\nvalue = 22.9'),\n",
       " Text(0.2678185745140389, 0.375, 'X[9] <= 279.0\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 22.7'),\n",
       " Text(0.265658747300216, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.5'),\n",
       " Text(0.26997840172786175, 0.325, 'squared_error = -0.0\\nsamples = 1\\nvalue = 22.9'),\n",
       " Text(0.27213822894168466, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.3'),\n",
       " Text(0.2786177105831533, 0.425, 'X[11] <= 287.87\\nsquared_error = 1.906\\nsamples = 10\\nvalue = 20.53'),\n",
       " Text(0.27645788336933047, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.8'),\n",
       " Text(0.28077753779697623, 0.375, 'X[5] <= 6.104\\nsquared_error = 0.798\\nsamples = 9\\nvalue = 20.167'),\n",
       " Text(0.27483801295896326, 0.325, 'X[8] <= 3.5\\nsquared_error = 0.577\\nsamples = 7\\nvalue = 19.857'),\n",
       " Text(0.26943844492440605, 0.275, 'X[11] <= 389.995\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 20.9'),\n",
       " Text(0.26727861771058314, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.1'),\n",
       " Text(0.27159827213822896, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.7'),\n",
       " Text(0.28023758099352053, 0.275, 'X[7] <= 6.281\\nsquared_error = 0.182\\nsamples = 5\\nvalue = 19.44'),\n",
       " Text(0.2759179265658747, 0.225, 'X[9] <= 307.5\\nsquared_error = 0.042\\nsamples = 3\\nvalue = 19.133'),\n",
       " Text(0.2737580993520518, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.4'),\n",
       " Text(0.2780777537796976, 0.175, 'X[7] <= 4.308\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 19.0'),\n",
       " Text(0.2759179265658747, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.1'),\n",
       " Text(0.28023758099352053, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.9'),\n",
       " Text(0.2845572354211663, 0.225, 'X[9] <= 271.5\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 19.9'),\n",
       " Text(0.28239740820734344, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.7'),\n",
       " Text(0.2867170626349892, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.1'),\n",
       " Text(0.2867170626349892, 0.325, 'X[6] <= 78.05\\nsquared_error = 0.062\\nsamples = 2\\nvalue = 21.25'),\n",
       " Text(0.2845572354211663, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.0'),\n",
       " Text(0.2888768898488121, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.5'),\n",
       " Text(0.2915766738660907, 0.525, 'X[12] <= 11.245\\nsquared_error = 1.002\\nsamples = 4\\nvalue = 19.55'),\n",
       " Text(0.2894168466522678, 0.475, 'X[5] <= 6.138\\nsquared_error = 0.127\\nsamples = 3\\nvalue = 19.0'),\n",
       " Text(0.28725701943844495, 0.425, 'X[10] <= 17.35\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 19.25'),\n",
       " Text(0.28509719222462204, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.3'),\n",
       " Text(0.2894168466522678, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.2'),\n",
       " Text(0.2915766738660907, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.5'),\n",
       " Text(0.2937365010799136, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 21.2'),\n",
       " Text(0.3181695464362851, 0.575, 'X[6] <= 99.45\\nsquared_error = 4.081\\nsamples = 34\\nvalue = 19.982'),\n",
       " Text(0.3160097192224622, 0.525, 'X[6] <= 44.55\\nsquared_error = 3.266\\nsamples = 33\\nvalue = 20.148'),\n",
       " Text(0.2980561555075594, 0.475, 'X[2] <= 6.67\\nsquared_error = 1.722\\nsamples = 3\\nvalue = 22.867'),\n",
       " Text(0.2958963282937365, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.7'),\n",
       " Text(0.3002159827213823, 0.425, 'X[2] <= 9.095\\nsquared_error = 0.063\\nsamples = 2\\nvalue = 21.95'),\n",
       " Text(0.2980561555075594, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.2'),\n",
       " Text(0.3023758099352052, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.7'),\n",
       " Text(0.333963282937365, 0.475, 'X[2] <= 8.35\\nsquared_error = 2.608\\nsamples = 30\\nvalue = 19.877'),\n",
       " Text(0.3126349892008639, 0.425, 'X[9] <= 341.0\\nsquared_error = 0.941\\nsamples = 11\\nvalue = 18.845'),\n",
       " Text(0.30669546436285094, 0.375, 'X[11] <= 378.79\\nsquared_error = 0.537\\nsamples = 9\\nvalue = 19.178'),\n",
       " Text(0.30129589632829373, 0.325, 'X[0] <= 0.147\\nsquared_error = 0.062\\nsamples = 2\\nvalue = 20.25'),\n",
       " Text(0.2991360691144708, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.0'),\n",
       " Text(0.30345572354211664, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.5'),\n",
       " Text(0.3120950323974082, 0.325, 'X[11] <= 390.235\\nsquared_error = 0.251\\nsamples = 7\\nvalue = 18.871'),\n",
       " Text(0.3077753779697624, 0.275, 'X[6] <= 89.45\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 18.3'),\n",
       " Text(0.30561555075593955, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.2'),\n",
       " Text(0.3099352051835853, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.4'),\n",
       " Text(0.31641468682505397, 0.275, 'X[0] <= 0.032\\nsquared_error = 0.164\\nsamples = 5\\nvalue = 19.1'),\n",
       " Text(0.3142548596112311, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.5'),\n",
       " Text(0.3185745140388769, 0.225, 'X[12] <= 9.77\\nsquared_error = 0.093\\nsamples = 4\\nvalue = 19.25'),\n",
       " Text(0.3142548596112311, 0.175, 'X[2] <= 5.575\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 18.95'),\n",
       " Text(0.3120950323974082, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.0'),\n",
       " Text(0.31641468682505397, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.9'),\n",
       " Text(0.3228941684665227, 0.175, 'X[7] <= 4.622\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 19.55'),\n",
       " Text(0.3207343412526998, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.6'),\n",
       " Text(0.3250539956803456, 0.125, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.5'),\n",
       " Text(0.3185745140388769, 0.375, 'X[12] <= 11.6\\nsquared_error = 0.023\\nsamples = 2\\nvalue = 17.35'),\n",
       " Text(0.31641468682505397, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.5'),\n",
       " Text(0.3207343412526998, 0.325, 'squared_error = -0.0\\nsamples = 1\\nvalue = 17.2'),\n",
       " Text(0.35529157667386607, 0.425, 'X[11] <= 224.3\\nsquared_error = 2.601\\nsamples = 19\\nvalue = 20.474'),\n",
       " Text(0.3466522678185745, 0.375, 'X[4] <= 0.552\\nsquared_error = 1.562\\nsamples = 2\\nvalue = 17.35'),\n",
       " Text(0.3444924406047516, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.6'),\n",
       " Text(0.3488120950323974, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.1'),\n",
       " Text(0.36393088552915764, 0.375, 'X[0] <= 3.843\\nsquared_error = 1.44\\nsamples = 17\\nvalue = 20.841'),\n",
       " Text(0.3531317494600432, 0.325, 'X[11] <= 393.98\\nsquared_error = 1.126\\nsamples = 14\\nvalue = 20.521'),\n",
       " Text(0.3444924406047516, 0.275, 'X[6] <= 94.5\\nsquared_error = 0.94\\nsamples = 10\\nvalue = 20.94'),\n",
       " Text(0.34233261339092874, 0.225, 'X[6] <= 72.1\\nsquared_error = 0.521\\nsamples = 9\\nvalue = 20.711'),\n",
       " Text(0.33369330453563717, 0.175, 'X[4] <= 0.478\\nsquared_error = 0.212\\nsamples = 4\\nvalue = 21.425'),\n",
       " Text(0.32937365010799136, 0.125, 'X[0] <= 0.072\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 21.0'),\n",
       " Text(0.32721382289416845, 0.075, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.2'),\n",
       " Text(0.33153347732181426, 0.075, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.8'),\n",
       " Text(0.33801295896328293, 0.125, 'X[9] <= 286.0\\nsquared_error = 0.022\\nsamples = 2\\nvalue = 21.85'),\n",
       " Text(0.33585313174946, 0.075, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.0'),\n",
       " Text(0.34017278617710583, 0.075, 'squared_error = -0.0\\nsamples = 1\\nvalue = 21.7'),\n",
       " Text(0.3509719222462203, 0.175, 'X[5] <= 6.147\\nsquared_error = 0.034\\nsamples = 5\\nvalue = 20.14'),\n",
       " Text(0.3466522678185745, 0.125, 'X[10] <= 20.0\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 20.35'),\n",
       " Text(0.3444924406047516, 0.075, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.3'),\n",
       " Text(0.3488120950323974, 0.075, 'squared_error = -0.0\\nsamples = 1\\nvalue = 20.4'),\n",
       " Text(0.35529157667386607, 0.125, 'X[6] <= 90.55\\nsquared_error = 0.007\\nsamples = 3\\nvalue = 20.0'),\n",
       " Text(0.3531317494600432, 0.075, 'X[12] <= 12.15\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 20.05'),\n",
       " Text(0.3509719222462203, 0.025, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.0'),\n",
       " Text(0.35529157667386607, 0.025, 'squared_error = -0.0\\nsamples = 1\\nvalue = 20.1'),\n",
       " Text(0.357451403887689, 0.075, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.9'),\n",
       " Text(0.3466522678185745, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.0'),\n",
       " Text(0.3617710583153348, 0.275, 'X[12] <= 12.435\\nsquared_error = 0.057\\nsamples = 4\\nvalue = 19.475'),\n",
       " Text(0.357451403887689, 0.225, 'X[12] <= 12.265\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 19.7'),\n",
       " Text(0.35529157667386607, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.6'),\n",
       " Text(0.3596112311015119, 0.175, 'squared_error = -0.0\\nsamples = 1\\nvalue = 19.8'),\n",
       " Text(0.36609071274298055, 0.225, 'X[10] <= 21.05\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 19.25'),\n",
       " Text(0.36393088552915764, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.3'),\n",
       " Text(0.36825053995680346, 0.175, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.2'),\n",
       " Text(0.3747300215982721, 0.325, 'X[6] <= 87.2\\nsquared_error = 0.202\\nsamples = 3\\nvalue = 22.333'),\n",
       " Text(0.37257019438444927, 0.275, 'X[0] <= 4.732\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 22.65'),\n",
       " Text(0.37041036717062636, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.6'),\n",
       " Text(0.3747300215982721, 0.225, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.7'),\n",
       " Text(0.37688984881209503, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.7'),\n",
       " Text(0.320329373650108, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.5'),\n",
       " Text(0.4109071274298056, 0.775, 'X[9] <= 278.0\\nsquared_error = 10.975\\nsamples = 52\\nvalue = 27.7'),\n",
       " Text(0.3693304535637149, 0.725, 'X[10] <= 17.85\\nsquared_error = 5.085\\nsamples = 19\\nvalue = 30.063'),\n",
       " Text(0.3596112311015119, 0.675, 'X[11] <= 392.84\\nsquared_error = 3.202\\nsamples = 11\\nvalue = 31.436'),\n",
       " Text(0.35529157667386607, 0.625, 'X[5] <= 6.685\\nsquared_error = 0.38\\nsamples = 4\\nvalue = 29.5'),\n",
       " Text(0.3531317494600432, 0.575, 'X[1] <= 30.0\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 28.9'),\n",
       " Text(0.3509719222462203, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.7'),\n",
       " Text(0.35529157667386607, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 29.1'),\n",
       " Text(0.357451403887689, 0.575, 'squared_error = -0.0\\nsamples = 2\\nvalue = 30.1'),\n",
       " Text(0.36393088552915764, 0.625, 'X[10] <= 15.0\\nsquared_error = 1.448\\nsamples = 7\\nvalue = 32.543'),\n",
       " Text(0.3617710583153348, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 35.1'),\n",
       " Text(0.36609071274298055, 0.575, 'X[10] <= 16.6\\nsquared_error = 0.418\\nsamples = 6\\nvalue = 32.117'),\n",
       " Text(0.3617710583153348, 0.525, 'X[1] <= 80.0\\nsquared_error = 0.062\\nsamples = 2\\nvalue = 31.35'),\n",
       " Text(0.3596112311015119, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 31.1'),\n",
       " Text(0.36393088552915764, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 31.6'),\n",
       " Text(0.37041036717062636, 0.525, 'X[6] <= 30.25\\nsquared_error = 0.155\\nsamples = 4\\nvalue = 32.5'),\n",
       " Text(0.36825053995680346, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 33.1'),\n",
       " Text(0.37257019438444927, 0.475, 'X[5] <= 6.806\\nsquared_error = 0.047\\nsamples = 3\\nvalue = 32.3'),\n",
       " Text(0.37041036717062636, 0.425, 'X[3] <= 0.5\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 32.45'),\n",
       " Text(0.36825053995680346, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 32.5'),\n",
       " Text(0.37257019438444927, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 32.4'),\n",
       " Text(0.3747300215982721, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 32.0'),\n",
       " Text(0.37904967602591794, 0.675, 'X[5] <= 6.605\\nsquared_error = 1.517\\nsamples = 8\\nvalue = 28.175'),\n",
       " Text(0.37688984881209503, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 30.8'),\n",
       " Text(0.38120950323974084, 0.625, 'X[11] <= 392.83\\nsquared_error = 0.609\\nsamples = 7\\nvalue = 27.8'),\n",
       " Text(0.37688984881209503, 0.575, 'X[5] <= 6.628\\nsquared_error = 0.72\\nsamples = 3\\nvalue = 27.2'),\n",
       " Text(0.3747300215982721, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.4'),\n",
       " Text(0.37904967602591794, 0.525, 'X[2] <= 5.7\\nsquared_error = 0.0\\nsamples = 2\\nvalue = 26.6'),\n",
       " Text(0.37688984881209503, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 26.6'),\n",
       " Text(0.38120950323974084, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 26.6'),\n",
       " Text(0.3855291576673866, 0.575, 'X[6] <= 25.65\\nsquared_error = 0.052\\nsamples = 4\\nvalue = 28.25'),\n",
       " Text(0.3833693304535637, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 27.9'),\n",
       " Text(0.3876889848812095, 0.525, 'X[6] <= 64.2\\nsquared_error = 0.016\\nsamples = 3\\nvalue = 28.367'),\n",
       " Text(0.3855291576673866, 0.475, 'X[2] <= 3.565\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 28.45'),\n",
       " Text(0.3833693304535637, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.4'),\n",
       " Text(0.3876889848812095, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.5'),\n",
       " Text(0.3898488120950324, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.2'),\n",
       " Text(0.4524838012958963, 0.725, 'X[4] <= 0.529\\nsquared_error = 9.299\\nsamples = 33\\nvalue = 26.339'),\n",
       " Text(0.4265658747300216, 0.675, 'X[4] <= 0.436\\nsquared_error = 8.239\\nsamples = 28\\nvalue = 26.957'),\n",
       " Text(0.408207343412527, 0.625, 'X[6] <= 35.2\\nsquared_error = 3.104\\nsamples = 11\\nvalue = 24.564'),\n",
       " Text(0.4006479481641469, 0.575, 'X[1] <= 46.25\\nsquared_error = 1.618\\nsamples = 5\\nvalue = 26.02'),\n",
       " Text(0.3963282937365011, 0.525, 'X[12] <= 5.59\\nsquared_error = 0.596\\nsamples = 3\\nvalue = 26.933'),\n",
       " Text(0.3941684665226782, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.0'),\n",
       " Text(0.398488120950324, 0.475, 'X[8] <= 4.0\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 26.4'),\n",
       " Text(0.3963282937365011, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 26.6'),\n",
       " Text(0.4006479481641469, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 26.2'),\n",
       " Text(0.40496760259179265, 0.525, 'X[6] <= 26.3\\nsquared_error = 0.023\\nsamples = 2\\nvalue = 24.65'),\n",
       " Text(0.40280777537796975, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.8'),\n",
       " Text(0.40712742980561556, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.5'),\n",
       " Text(0.41576673866090713, 0.575, 'X[12] <= 8.435\\nsquared_error = 1.102\\nsamples = 6\\nvalue = 23.35'),\n",
       " Text(0.4136069114470842, 0.525, 'X[0] <= 0.044\\nsquared_error = 0.287\\nsamples = 4\\nvalue = 24.025'),\n",
       " Text(0.4114470842332613, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.8'),\n",
       " Text(0.41576673866090713, 0.475, 'X[8] <= 5.0\\nsquared_error = 0.116\\nsamples = 3\\nvalue = 23.767'),\n",
       " Text(0.4136069114470842, 0.425, 'X[10] <= 18.65\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 24.0'),\n",
       " Text(0.4114470842332613, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.1'),\n",
       " Text(0.41576673866090713, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.9'),\n",
       " Text(0.41792656587473004, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.3'),\n",
       " Text(0.41792656587473004, 0.525, 'squared_error = 0.0\\nsamples = 2\\nvalue = 22.0'),\n",
       " Text(0.4449244060475162, 0.625, 'X[12] <= 7.05\\nsquared_error = 5.456\\nsamples = 17\\nvalue = 28.506'),\n",
       " Text(0.4298056155507559, 0.575, 'X[9] <= 301.5\\nsquared_error = 1.157\\nsamples = 8\\nvalue = 30.362'),\n",
       " Text(0.4222462203023758, 0.525, 'X[10] <= 16.3\\nsquared_error = 0.287\\nsamples = 3\\nvalue = 29.3'),\n",
       " Text(0.4200863930885529, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.6'),\n",
       " Text(0.4244060475161987, 0.475, 'X[11] <= 391.115\\nsquared_error = 0.062\\nsamples = 2\\nvalue = 29.65'),\n",
       " Text(0.4222462203023758, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 29.4'),\n",
       " Text(0.4265658747300216, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 29.9'),\n",
       " Text(0.4373650107991361, 0.525, 'X[7] <= 4.178\\nsquared_error = 0.596\\nsamples = 5\\nvalue = 31.0'),\n",
       " Text(0.4330453563714903, 0.475, 'X[7] <= 3.582\\nsquared_error = 0.062\\nsamples = 2\\nvalue = 31.75'),\n",
       " Text(0.43088552915766737, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 31.5'),\n",
       " Text(0.4352051835853132, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 32.0'),\n",
       " Text(0.44168466522678185, 0.475, 'X[0] <= 0.097\\nsquared_error = 0.327\\nsamples = 3\\nvalue = 30.5'),\n",
       " Text(0.43952483801295894, 0.425, 'X[12] <= 4.65\\nsquared_error = 0.122\\nsamples = 2\\nvalue = 30.85'),\n",
       " Text(0.4373650107991361, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 31.2'),\n",
       " Text(0.44168466522678185, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 30.5'),\n",
       " Text(0.44384449244060475, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 29.8'),\n",
       " Text(0.46004319654427644, 0.575, 'X[7] <= 3.9\\nsquared_error = 3.489\\nsamples = 9\\nvalue = 26.856'),\n",
       " Text(0.45464362850971923, 0.525, 'X[5] <= 6.727\\nsquared_error = 1.618\\nsamples = 5\\nvalue = 28.12'),\n",
       " Text(0.4503239740820734, 0.475, 'X[12] <= 7.825\\nsquared_error = 0.303\\nsamples = 2\\nvalue = 29.55'),\n",
       " Text(0.4481641468682505, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 30.1'),\n",
       " Text(0.4524838012958963, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 29.0'),\n",
       " Text(0.458963282937365, 0.475, 'X[6] <= 74.5\\nsquared_error = 0.222\\nsamples = 3\\nvalue = 27.167'),\n",
       " Text(0.45680345572354214, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 26.5'),\n",
       " Text(0.4611231101511879, 0.425, 'squared_error = 0.0\\nsamples = 2\\nvalue = 27.5'),\n",
       " Text(0.4654427645788337, 0.525, 'X[8] <= 4.5\\nsquared_error = 1.332\\nsamples = 4\\nvalue = 25.275'),\n",
       " Text(0.4632829373650108, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 27.1'),\n",
       " Text(0.46760259179265656, 0.475, 'X[8] <= 6.5\\nsquared_error = 0.296\\nsamples = 3\\nvalue = 24.667'),\n",
       " Text(0.4654427645788337, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.9'),\n",
       " Text(0.46976241900647947, 0.425, 'X[4] <= 0.48\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 25.05'),\n",
       " Text(0.46760259179265656, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 25.0'),\n",
       " Text(0.4719222462203024, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 25.1'),\n",
       " Text(0.47840172786177104, 0.675, 'X[7] <= 4.164\\nsquared_error = 1.13\\nsamples = 5\\nvalue = 22.88'),\n",
       " Text(0.4762419006479482, 0.625, 'X[5] <= 6.605\\nsquared_error = 0.308\\nsamples = 4\\nvalue = 23.35'),\n",
       " Text(0.4719222462203024, 0.575, 'X[11] <= 396.295\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 23.9'),\n",
       " Text(0.46976241900647947, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.8'),\n",
       " Text(0.4740820734341253, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.0'),\n",
       " Text(0.48056155507559395, 0.575, 'X[5] <= 6.675\\nsquared_error = 0.0\\nsamples = 2\\nvalue = 22.8'),\n",
       " Text(0.47840172786177104, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.8'),\n",
       " Text(0.48272138228941686, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.8'),\n",
       " Text(0.48056155507559395, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.0'),\n",
       " Text(0.6672684935205183, 0.875, 'X[0] <= 5.769\\nsquared_error = 20.408\\nsamples = 146\\nvalue = 14.777'),\n",
       " Text(0.5844019978401728, 0.825, 'X[0] <= 0.615\\nsquared_error = 10.041\\nsamples = 77\\nvalue = 17.552'),\n",
       " Text(0.5231506479481641, 0.775, 'X[7] <= 1.98\\nsquared_error = 7.75\\nsamples = 45\\nvalue = 19.107'),\n",
       " Text(0.4929805615550756, 0.725, 'X[7] <= 1.669\\nsquared_error = 2.517\\nsamples = 9\\nvalue = 16.311'),\n",
       " Text(0.4870410367170626, 0.675, 'X[7] <= 1.64\\nsquared_error = 0.122\\nsamples = 2\\nvalue = 13.65'),\n",
       " Text(0.48488120950323976, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.0'),\n",
       " Text(0.4892008639308855, 0.625, 'squared_error = -0.0\\nsamples = 1\\nvalue = 13.3'),\n",
       " Text(0.49892008639308855, 0.675, 'X[5] <= 5.774\\nsquared_error = 0.599\\nsamples = 7\\nvalue = 17.071'),\n",
       " Text(0.49352051835853133, 0.625, 'X[6] <= 95.8\\nsquared_error = 0.062\\nsamples = 2\\nvalue = 15.95'),\n",
       " Text(0.49136069114470843, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 15.7'),\n",
       " Text(0.4956803455723542, 0.575, 'squared_error = -0.0\\nsamples = 1\\nvalue = 16.2'),\n",
       " Text(0.5043196544276458, 0.625, 'X[7] <= 1.831\\nsquared_error = 0.11\\nsamples = 5\\nvalue = 17.52'),\n",
       " Text(0.5, 0.575, 'X[5] <= 6.291\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 17.9'),\n",
       " Text(0.4978401727861771, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.8'),\n",
       " Text(0.5021598272138229, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.0'),\n",
       " Text(0.5086393088552916, 0.575, 'X[7] <= 1.897\\nsquared_error = 0.016\\nsamples = 3\\nvalue = 17.267'),\n",
       " Text(0.5064794816414687, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.1'),\n",
       " Text(0.5107991360691144, 0.525, 'X[7] <= 1.956\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 17.35'),\n",
       " Text(0.5086393088552916, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.3'),\n",
       " Text(0.5129589632829373, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 17.4'),\n",
       " Text(0.5533207343412527, 0.725, 'X[0] <= 0.17\\nsquared_error = 6.616\\nsamples = 36\\nvalue = 19.806'),\n",
       " Text(0.5318574514038877, 0.675, 'X[5] <= 6.025\\nsquared_error = 5.433\\nsamples = 13\\nvalue = 21.262'),\n",
       " Text(0.5248380129589633, 0.625, 'X[10] <= 17.2\\nsquared_error = 1.761\\nsamples = 11\\nvalue = 20.445'),\n",
       " Text(0.5172786177105831, 0.575, 'X[5] <= 5.681\\nsquared_error = 0.988\\nsamples = 4\\nvalue = 21.65'),\n",
       " Text(0.5151187904967602, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.1'),\n",
       " Text(0.519438444924406, 0.525, 'X[7] <= 5.885\\nsquared_error = 0.382\\nsamples = 3\\nvalue = 21.167'),\n",
       " Text(0.5172786177105831, 0.475, 'X[2] <= 10.88\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 21.6'),\n",
       " Text(0.5151187904967602, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.7'),\n",
       " Text(0.519438444924406, 0.425, 'squared_error = -0.0\\nsamples = 1\\nvalue = 21.5'),\n",
       " Text(0.521598272138229, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.3'),\n",
       " Text(0.5323974082073434, 0.575, 'X[5] <= 5.937\\nsquared_error = 0.9\\nsamples = 7\\nvalue = 19.757'),\n",
       " Text(0.5280777537796977, 0.525, 'X[11] <= 359.005\\nsquared_error = 0.382\\nsamples = 5\\nvalue = 19.28'),\n",
       " Text(0.5259179265658748, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.4'),\n",
       " Text(0.5302375809935205, 0.475, 'X[5] <= 5.865\\nsquared_error = 0.085\\nsamples = 4\\nvalue = 19.0'),\n",
       " Text(0.5280777537796977, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.5'),\n",
       " Text(0.5323974082073434, 0.425, 'X[12] <= 15.505\\nsquared_error = 0.002\\nsamples = 3\\nvalue = 18.833'),\n",
       " Text(0.5302375809935205, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.9'),\n",
       " Text(0.5345572354211663, 0.375, 'X[9] <= 310.0\\nsquared_error = 0.0\\nsamples = 2\\nvalue = 18.8'),\n",
       " Text(0.5323974082073434, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.8'),\n",
       " Text(0.5367170626349892, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.8'),\n",
       " Text(0.5367170626349892, 0.525, 'X[6] <= 90.65\\nsquared_error = 0.202\\nsamples = 2\\nvalue = 20.95'),\n",
       " Text(0.5345572354211663, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 21.4'),\n",
       " Text(0.5388768898488121, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.5'),\n",
       " Text(0.5388768898488121, 0.625, 'X[5] <= 6.118\\nsquared_error = 1.822\\nsamples = 2\\nvalue = 25.75'),\n",
       " Text(0.5367170626349892, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 24.4'),\n",
       " Text(0.541036717062635, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 27.1'),\n",
       " Text(0.5747840172786177, 0.675, 'X[7] <= 5.022\\nsquared_error = 5.408\\nsamples = 23\\nvalue = 18.983'),\n",
       " Text(0.5599352051835853, 0.625, 'X[4] <= 0.514\\nsquared_error = 3.206\\nsamples = 15\\nvalue = 20.087'),\n",
       " Text(0.5496760259179265, 0.575, 'X[5] <= 5.408\\nsquared_error = 1.961\\nsamples = 7\\nvalue = 21.614'),\n",
       " Text(0.5453563714902808, 0.525, 'X[11] <= 396.07\\nsquared_error = 0.123\\nsamples = 2\\nvalue = 19.65'),\n",
       " Text(0.5431965442764579, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.3'),\n",
       " Text(0.5475161987041036, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 20.0'),\n",
       " Text(0.5539956803455723, 0.525, 'X[12] <= 25.505\\nsquared_error = 0.536\\nsamples = 5\\nvalue = 22.4'),\n",
       " Text(0.5518358531317494, 0.475, 'X[5] <= 5.884\\nsquared_error = 0.142\\nsamples = 4\\nvalue = 22.075'),\n",
       " Text(0.5496760259179265, 0.425, 'X[11] <= 390.185\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 22.45'),\n",
       " Text(0.5475161987041036, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.5'),\n",
       " Text(0.5518358531317494, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 22.4'),\n",
       " Text(0.5539956803455723, 0.425, 'squared_error = -0.0\\nsamples = 2\\nvalue = 21.7'),\n",
       " Text(0.5561555075593952, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 23.7'),\n",
       " Text(0.5701943844492441, 0.575, 'X[0] <= 0.291\\nsquared_error = 0.467\\nsamples = 8\\nvalue = 18.75'),\n",
       " Text(0.5647948164146869, 0.525, 'X[10] <= 18.1\\nsquared_error = 0.306\\nsamples = 5\\nvalue = 19.14'),\n",
       " Text(0.5604751619870411, 0.475, 'X[5] <= 6.01\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 18.5'),\n",
       " Text(0.5583153347732182, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.3'),\n",
       " Text(0.562634989200864, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.7'),\n",
       " Text(0.5691144708423326, 0.475, 'X[2] <= 9.23\\nsquared_error = 0.029\\nsamples = 3\\nvalue = 19.567'),\n",
       " Text(0.5669546436285097, 0.425, 'X[11] <= 393.45\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 19.45'),\n",
       " Text(0.5647948164146869, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.4'),\n",
       " Text(0.5691144708423326, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 19.5'),\n",
       " Text(0.5712742980561555, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.8'),\n",
       " Text(0.5755939524838013, 0.525, 'X[10] <= 19.8\\nsquared_error = 0.06\\nsamples = 3\\nvalue = 18.1'),\n",
       " Text(0.5734341252699784, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.8'),\n",
       " Text(0.5777537796976242, 0.475, 'X[12] <= 15.995\\nsquared_error = 0.023\\nsamples = 2\\nvalue = 18.25'),\n",
       " Text(0.5755939524838013, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.4'),\n",
       " Text(0.5799136069114471, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.1'),\n",
       " Text(0.5896328293736501, 0.625, 'X[6] <= 89.65\\nsquared_error = 2.966\\nsamples = 8\\nvalue = 16.912'),\n",
       " Text(0.58207343412527, 0.575, 'X[7] <= 5.889\\nsquared_error = 1.122\\nsamples = 4\\nvalue = 18.35'),\n",
       " Text(0.5799136069114471, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.6'),\n",
       " Text(0.5842332613390929, 0.525, 'X[12] <= 16.65\\nsquared_error = 0.136\\nsamples = 3\\nvalue = 18.933'),\n",
       " Text(0.58207343412527, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 19.4'),\n",
       " Text(0.5863930885529157, 0.475, 'X[5] <= 5.805\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 18.7'),\n",
       " Text(0.5842332613390929, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.5'),\n",
       " Text(0.5885529157667386, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 18.9'),\n",
       " Text(0.5971922246220303, 0.575, 'X[0] <= 0.218\\nsquared_error = 0.677\\nsamples = 4\\nvalue = 15.475'),\n",
       " Text(0.5928725701943844, 0.525, 'X[6] <= 96.7\\nsquared_error = 0.062\\nsamples = 2\\nvalue = 16.25'),\n",
       " Text(0.5907127429805615, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.0'),\n",
       " Text(0.5950323974082073, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.5'),\n",
       " Text(0.6015118790496761, 0.525, 'X[5] <= 5.888\\nsquared_error = 0.09\\nsamples = 2\\nvalue = 14.7'),\n",
       " Text(0.5993520518358532, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.4'),\n",
       " Text(0.603671706263499, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 15.0'),\n",
       " Text(0.6456533477321814, 0.775, 'X[8] <= 14.5\\nsquared_error = 5.085\\nsamples = 32\\nvalue = 15.366'),\n",
       " Text(0.6293196544276458, 0.725, 'X[12] <= 15.965\\nsquared_error = 3.016\\nsamples = 28\\nvalue = 14.964'),\n",
       " Text(0.6144708423326134, 0.675, 'X[12] <= 15.455\\nsquared_error = 1.319\\nsamples = 6\\nvalue = 17.25'),\n",
       " Text(0.6123110151187905, 0.625, 'X[11] <= 190.15\\nsquared_error = 0.474\\nsamples = 5\\nvalue = 16.82'),\n",
       " Text(0.6101511879049676, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 15.6'),\n",
       " Text(0.6144708423326134, 0.575, 'X[12] <= 14.74\\nsquared_error = 0.127\\nsamples = 4\\nvalue = 17.125'),\n",
       " Text(0.6101511879049676, 0.525, 'X[5] <= 5.932\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 17.45'),\n",
       " Text(0.6079913606911447, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.4'),\n",
       " Text(0.6123110151187905, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.5'),\n",
       " Text(0.6187904967602592, 0.525, 'X[6] <= 93.15\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 16.8'),\n",
       " Text(0.6166306695464363, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.6'),\n",
       " Text(0.6209503239740821, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.0'),\n",
       " Text(0.6166306695464363, 0.625, 'squared_error = -0.0\\nsamples = 1\\nvalue = 19.4'),\n",
       " Text(0.6441684665226782, 0.675, 'X[5] <= 4.914\\nsquared_error = 1.665\\nsamples = 22\\nvalue = 14.341'),\n",
       " Text(0.6420086393088553, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 11.8'),\n",
       " Text(0.646328293736501, 0.625, 'X[7] <= 1.633\\nsquared_error = 1.422\\nsamples = 21\\nvalue = 14.462'),\n",
       " Text(0.6328293736501079, 0.575, 'X[7] <= 1.528\\nsquared_error = 1.649\\nsamples = 8\\nvalue = 15.075'),\n",
       " Text(0.6306695464362851, 0.525, 'X[12] <= 26.62\\nsquared_error = 0.673\\nsamples = 7\\nvalue = 14.686'),\n",
       " Text(0.6252699784017278, 0.475, 'X[6] <= 97.45\\nsquared_error = 0.009\\nsamples = 3\\nvalue = 15.533'),\n",
       " Text(0.6231101511879049, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 15.4'),\n",
       " Text(0.6274298056155507, 0.425, 'squared_error = -0.0\\nsamples = 2\\nvalue = 15.6'),\n",
       " Text(0.6360691144708424, 0.475, 'X[7] <= 1.429\\nsquared_error = 0.228\\nsamples = 4\\nvalue = 14.05'),\n",
       " Text(0.6317494600431965, 0.425, 'X[3] <= 0.5\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 13.6'),\n",
       " Text(0.6295896328293736, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.8'),\n",
       " Text(0.6339092872570194, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 13.4'),\n",
       " Text(0.6403887688984882, 0.425, 'X[12] <= 31.97\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 14.5'),\n",
       " Text(0.6382289416846653, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.6'),\n",
       " Text(0.642548596112311, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 14.4'),\n",
       " Text(0.6349892008639308, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 17.8'),\n",
       " Text(0.6598272138228942, 0.575, 'X[0] <= 1.06\\nsquared_error = 0.909\\nsamples = 13\\nvalue = 14.085'),\n",
       " Text(0.6511879049676026, 0.525, 'X[5] <= 5.697\\nsquared_error = 0.405\\nsamples = 6\\nvalue = 14.783'),\n",
       " Text(0.6468682505399568, 0.475, 'X[0] <= 0.861\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 14.1'),\n",
       " Text(0.6447084233261339, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.9'),\n",
       " Text(0.6490280777537797, 0.425, 'squared_error = -0.0\\nsamples = 1\\nvalue = 14.3'),\n",
       " Text(0.6555075593952484, 0.475, 'X[11] <= 394.435\\nsquared_error = 0.237\\nsamples = 4\\nvalue = 15.125'),\n",
       " Text(0.6533477321814255, 0.425, 'X[7] <= 4.427\\nsquared_error = 0.142\\nsamples = 3\\nvalue = 15.333'),\n",
       " Text(0.6511879049676026, 0.375, 'squared_error = 0.0\\nsamples = 2\\nvalue = 15.6'),\n",
       " Text(0.6555075593952484, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.8'),\n",
       " Text(0.6576673866090713, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.5'),\n",
       " Text(0.6684665226781857, 0.525, 'X[11] <= 386.735\\nsquared_error = 0.564\\nsamples = 7\\nvalue = 13.486'),\n",
       " Text(0.6663066954643628, 0.475, 'X[6] <= 95.95\\nsquared_error = 0.087\\nsamples = 6\\nvalue = 13.2'),\n",
       " Text(0.661987041036717, 0.425, 'X[0] <= 1.141\\nsquared_error = 0.037\\nsamples = 4\\nvalue = 13.025'),\n",
       " Text(0.6598272138228942, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 12.7'),\n",
       " Text(0.6641468682505399, 0.375, 'X[7] <= 3.889\\nsquared_error = 0.002\\nsamples = 3\\nvalue = 13.133'),\n",
       " Text(0.661987041036717, 0.325, 'squared_error = 0.0\\nsamples = 2\\nvalue = 13.1'),\n",
       " Text(0.6663066954643628, 0.325, 'squared_error = -0.0\\nsamples = 1\\nvalue = 13.2'),\n",
       " Text(0.6706263498920086, 0.425, 'X[6] <= 97.5\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 13.55'),\n",
       " Text(0.6684665226781857, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.5'),\n",
       " Text(0.6727861771058316, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 13.6'),\n",
       " Text(0.6706263498920086, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 15.2'),\n",
       " Text(0.661987041036717, 0.725, 'X[6] <= 85.2\\nsquared_error = 10.552\\nsamples = 4\\nvalue = 18.175'),\n",
       " Text(0.6598272138228942, 0.675, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.2'),\n",
       " Text(0.6641468682505399, 0.675, 'X[4] <= 0.727\\nsquared_error = 2.847\\nsamples = 3\\nvalue = 16.5'),\n",
       " Text(0.661987041036717, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.3'),\n",
       " Text(0.6663066954643628, 0.625, 'X[5] <= 6.011\\nsquared_error = 0.64\\nsamples = 2\\nvalue = 17.6'),\n",
       " Text(0.6641468682505399, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.8'),\n",
       " Text(0.6684665226781857, 0.575, 'squared_error = -0.0\\nsamples = 1\\nvalue = 18.4'),\n",
       " Text(0.750134989200864, 0.825, 'X[5] <= 6.843\\nsquared_error = 13.799\\nsamples = 69\\nvalue = 11.681'),\n",
       " Text(0.7479751619870411, 0.775, 'X[0] <= 11.369\\nsquared_error = 10.267\\nsamples = 68\\nvalue = 11.449'),\n",
       " Text(0.7146328293736501, 0.725, 'X[12] <= 19.805\\nsquared_error = 6.701\\nsamples = 32\\nvalue = 13.009'),\n",
       " Text(0.699244060475162, 0.675, 'X[4] <= 0.715\\nsquared_error = 2.766\\nsamples = 16\\nvalue = 14.412'),\n",
       " Text(0.6868250539956804, 0.625, 'X[6] <= 78.35\\nsquared_error = 1.0\\nsamples = 9\\nvalue = 13.544'),\n",
       " Text(0.6846652267818575, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 11.7'),\n",
       " Text(0.6889848812095032, 0.575, 'X[5] <= 6.377\\nsquared_error = 0.647\\nsamples = 8\\nvalue = 13.775'),\n",
       " Text(0.6814254859611231, 0.525, 'X[11] <= 395.665\\nsquared_error = 0.237\\nsamples = 4\\nvalue = 14.375'),\n",
       " Text(0.6771058315334774, 0.475, 'X[5] <= 6.03\\nsquared_error = 0.09\\nsamples = 2\\nvalue = 14.8'),\n",
       " Text(0.6749460043196545, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 15.1'),\n",
       " Text(0.6792656587473002, 0.425, 'squared_error = -0.0\\nsamples = 1\\nvalue = 14.5'),\n",
       " Text(0.6857451403887689, 0.475, 'X[4] <= 0.703\\nsquared_error = 0.023\\nsamples = 2\\nvalue = 13.95'),\n",
       " Text(0.683585313174946, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.8'),\n",
       " Text(0.6879049676025918, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.1'),\n",
       " Text(0.6965442764578834, 0.525, 'X[5] <= 6.652\\nsquared_error = 0.337\\nsamples = 4\\nvalue = 13.175'),\n",
       " Text(0.6943844492440605, 0.475, 'X[11] <= 394.44\\nsquared_error = 0.069\\nsamples = 3\\nvalue = 12.867'),\n",
       " Text(0.6922246220302376, 0.425, 'X[7] <= 1.955\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 13.05'),\n",
       " Text(0.6900647948164147, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.1'),\n",
       " Text(0.6943844492440605, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 13.0'),\n",
       " Text(0.6965442764578834, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 12.5'),\n",
       " Text(0.6987041036717062, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.1'),\n",
       " Text(0.7116630669546437, 0.625, 'X[6] <= 96.9\\nsquared_error = 2.822\\nsamples = 7\\nvalue = 15.529'),\n",
       " Text(0.7073434125269978, 0.575, 'X[6] <= 96.5\\nsquared_error = 0.927\\nsamples = 3\\nvalue = 13.9'),\n",
       " Text(0.7051835853131749, 0.525, 'X[6] <= 95.85\\nsquared_error = 0.123\\nsamples = 2\\nvalue = 14.55'),\n",
       " Text(0.703023758099352, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 14.2'),\n",
       " Text(0.7073434125269978, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 14.9'),\n",
       " Text(0.7095032397408207, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 12.6'),\n",
       " Text(0.7159827213822895, 0.575, 'X[5] <= 6.448\\nsquared_error = 0.763\\nsamples = 4\\nvalue = 16.75'),\n",
       " Text(0.7138228941684666, 0.525, 'X[7] <= 2.094\\nsquared_error = 0.207\\nsamples = 3\\nvalue = 17.2'),\n",
       " Text(0.7116630669546437, 0.475, 'X[4] <= 0.729\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 16.9'),\n",
       " Text(0.7095032397408207, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.7'),\n",
       " Text(0.7138228941684666, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.1'),\n",
       " Text(0.7159827213822895, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.8'),\n",
       " Text(0.7181425485961123, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 15.4'),\n",
       " Text(0.7300215982721382, 0.675, 'X[4] <= 0.675\\nsquared_error = 6.698\\nsamples = 16\\nvalue = 11.606'),\n",
       " Text(0.7224622030237581, 0.625, 'X[4] <= 0.606\\nsquared_error = 2.602\\nsamples = 4\\nvalue = 14.425'),\n",
       " Text(0.7203023758099352, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.2'),\n",
       " Text(0.724622030237581, 0.575, 'X[12] <= 29.03\\nsquared_error = 0.047\\nsamples = 3\\nvalue = 13.5'),\n",
       " Text(0.7224622030237581, 0.525, 'X[12] <= 22.265\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 13.35'),\n",
       " Text(0.7203023758099352, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.3'),\n",
       " Text(0.724622030237581, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 13.4'),\n",
       " Text(0.7267818574514039, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.8'),\n",
       " Text(0.7375809935205183, 0.625, 'X[12] <= 25.175\\nsquared_error = 4.532\\nsamples = 12\\nvalue = 10.667'),\n",
       " Text(0.7332613390928726, 0.575, 'X[12] <= 20.115\\nsquared_error = 1.962\\nsamples = 10\\nvalue = 11.42'),\n",
       " Text(0.7311015118790497, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 8.5'),\n",
       " Text(0.7354211663066955, 0.525, 'X[4] <= 0.686\\nsquared_error = 1.127\\nsamples = 9\\nvalue = 11.744'),\n",
       " Text(0.7300215982721382, 0.475, 'X[0] <= 8.353\\nsquared_error = 0.562\\nsamples = 2\\nvalue = 10.25'),\n",
       " Text(0.7278617710583153, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 11.0'),\n",
       " Text(0.7321814254859611, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 9.5'),\n",
       " Text(0.7408207343412527, 0.475, 'X[6] <= 94.7\\nsquared_error = 0.468\\nsamples = 7\\nvalue = 12.171'),\n",
       " Text(0.7365010799136069, 0.425, 'X[7] <= 1.971\\nsquared_error = 0.09\\nsamples = 2\\nvalue = 13.1'),\n",
       " Text(0.734341252699784, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 12.8'),\n",
       " Text(0.7386609071274298, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 13.4'),\n",
       " Text(0.7451403887688985, 0.425, 'X[7] <= 1.557\\nsquared_error = 0.136\\nsamples = 5\\nvalue = 11.8'),\n",
       " Text(0.7429805615550756, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 12.3'),\n",
       " Text(0.7473002159827213, 0.375, 'X[5] <= 5.97\\nsquared_error = 0.092\\nsamples = 4\\nvalue = 11.675'),\n",
       " Text(0.7429805615550756, 0.325, 'X[0] <= 8.669\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 11.4'),\n",
       " Text(0.7408207343412527, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 11.5'),\n",
       " Text(0.7451403887688985, 0.275, 'squared_error = -0.0\\nsamples = 1\\nvalue = 11.3'),\n",
       " Text(0.7516198704103672, 0.325, 'X[7] <= 1.813\\nsquared_error = 0.022\\nsamples = 2\\nvalue = 11.95'),\n",
       " Text(0.7494600431965442, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 12.1'),\n",
       " Text(0.7537796976241901, 0.275, 'squared_error = 0.0\\nsamples = 1\\nvalue = 11.8'),\n",
       " Text(0.7419006479481641, 0.575, 'X[0] <= 10.375\\nsquared_error = 0.36\\nsamples = 2\\nvalue = 6.9'),\n",
       " Text(0.7397408207343412, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 6.3'),\n",
       " Text(0.744060475161987, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 7.5'),\n",
       " Text(0.781317494600432, 0.725, 'X[4] <= 0.675\\nsquared_error = 9.347\\nsamples = 36\\nvalue = 10.061'),\n",
       " Text(0.7634989200863931, 0.675, 'X[11] <= 366.62\\nsquared_error = 7.238\\nsamples = 10\\nvalue = 13.54'),\n",
       " Text(0.7548596112311015, 0.625, 'X[6] <= 96.65\\nsquared_error = 7.828\\nsamples = 5\\nvalue = 15.1'),\n",
       " Text(0.7505399568034558, 0.575, 'X[4] <= 0.627\\nsquared_error = 3.422\\nsamples = 2\\nvalue = 12.05'),\n",
       " Text(0.7483801295896328, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 10.2'),\n",
       " Text(0.7526997840172787, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 13.9'),\n",
       " Text(0.7591792656587473, 0.575, 'X[12] <= 20.65\\nsquared_error = 0.429\\nsamples = 3\\nvalue = 17.133'),\n",
       " Text(0.7570194384449244, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 16.3'),\n",
       " Text(0.7613390928725702, 0.525, 'X[11] <= 31.92\\nsquared_error = 0.122\\nsamples = 2\\nvalue = 17.55'),\n",
       " Text(0.7591792656587473, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.9'),\n",
       " Text(0.7634989200863931, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 17.2'),\n",
       " Text(0.7721382289416847, 0.625, 'X[12] <= 23.515\\nsquared_error = 1.782\\nsamples = 5\\nvalue = 11.98'),\n",
       " Text(0.7678185745140389, 0.575, 'X[5] <= 5.181\\nsquared_error = 0.487\\nsamples = 3\\nvalue = 11.0'),\n",
       " Text(0.765658747300216, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 11.9'),\n",
       " Text(0.7699784017278618, 0.525, 'X[7] <= 1.453\\nsquared_error = 0.123\\nsamples = 2\\nvalue = 10.55'),\n",
       " Text(0.7678185745140389, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 10.2'),\n",
       " Text(0.7721382289416847, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 10.9'),\n",
       " Text(0.7764578833693304, 0.575, 'X[4] <= 0.669\\nsquared_error = 0.123\\nsamples = 2\\nvalue = 13.45'),\n",
       " Text(0.7742980561555075, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.8'),\n",
       " Text(0.7786177105831533, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 13.1'),\n",
       " Text(0.7991360691144709, 0.675, 'X[12] <= 17.2\\nsquared_error = 3.713\\nsamples = 26\\nvalue = 8.723'),\n",
       " Text(0.7829373650107991, 0.625, 'X[7] <= 1.822\\nsquared_error = 0.542\\nsamples = 3\\nvalue = 11.767'),\n",
       " Text(0.7807775377969762, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 12.7'),\n",
       " Text(0.785097192224622, 0.575, 'X[0] <= 25.788\\nsquared_error = 0.16\\nsamples = 2\\nvalue = 11.3'),\n",
       " Text(0.7829373650107991, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 11.7'),\n",
       " Text(0.787257019438445, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 10.9'),\n",
       " Text(0.8153347732181425, 0.625, 'X[7] <= 1.589\\nsquared_error = 2.761\\nsamples = 23\\nvalue = 8.326'),\n",
       " Text(0.796976241900648, 0.575, 'X[5] <= 4.826\\nsquared_error = 3.204\\nsamples = 8\\nvalue = 7.088'),\n",
       " Text(0.7915766738660908, 0.525, 'X[6] <= 95.6\\nsquared_error = 0.722\\nsamples = 2\\nvalue = 9.65'),\n",
       " Text(0.7894168466522679, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 8.8'),\n",
       " Text(0.7937365010799136, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 10.5'),\n",
       " Text(0.8023758099352052, 0.525, 'X[0] <= 23.822\\nsquared_error = 1.112\\nsamples = 6\\nvalue = 6.233'),\n",
       " Text(0.7980561555075594, 0.475, 'X[0] <= 19.704\\nsquared_error = 0.009\\nsamples = 3\\nvalue = 7.267'),\n",
       " Text(0.7958963282937365, 0.425, 'squared_error = 0.0\\nsamples = 2\\nvalue = 7.2'),\n",
       " Text(0.8002159827213823, 0.425, 'squared_error = -0.0\\nsamples = 1\\nvalue = 7.4'),\n",
       " Text(0.806695464362851, 0.475, 'X[0] <= 31.699\\nsquared_error = 0.08\\nsamples = 3\\nvalue = 5.2'),\n",
       " Text(0.8045356371490281, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 5.6'),\n",
       " Text(0.8088552915766739, 0.425, 'squared_error = 0.0\\nsamples = 2\\nvalue = 5.0'),\n",
       " Text(0.8336933045356372, 0.575, 'X[11] <= 107.815\\nsquared_error = 1.27\\nsamples = 15\\nvalue = 8.987'),\n",
       " Text(0.8207343412526998, 0.525, 'X[12] <= 27.75\\nsquared_error = 0.627\\nsamples = 8\\nvalue = 8.3'),\n",
       " Text(0.8153347732181425, 0.475, 'X[12] <= 19.335\\nsquared_error = 0.21\\nsamples = 5\\nvalue = 8.76'),\n",
       " Text(0.8131749460043196, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 9.6'),\n",
       " Text(0.8174946004319654, 0.425, 'X[6] <= 97.7\\nsquared_error = 0.043\\nsamples = 4\\nvalue = 8.55'),\n",
       " Text(0.8131749460043196, 0.375, 'X[7] <= 1.852\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 8.35'),\n",
       " Text(0.8110151187904968, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 8.4'),\n",
       " Text(0.8153347732181425, 0.325, 'squared_error = -0.0\\nsamples = 1\\nvalue = 8.3'),\n",
       " Text(0.8218142548596112, 0.375, 'X[12] <= 23.535\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 8.75'),\n",
       " Text(0.8196544276457883, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 8.8'),\n",
       " Text(0.8239740820734341, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 8.7'),\n",
       " Text(0.826133909287257, 0.475, 'X[6] <= 93.95\\nsquared_error = 0.382\\nsamples = 3\\nvalue = 7.533'),\n",
       " Text(0.8239740820734341, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 8.4'),\n",
       " Text(0.82829373650108, 0.425, 'X[5] <= 5.477\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 7.1'),\n",
       " Text(0.826133909287257, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 7.0'),\n",
       " Text(0.8304535637149028, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 7.2'),\n",
       " Text(0.8466522678185745, 0.525, 'X[0] <= 23.426\\nsquared_error = 0.851\\nsamples = 7\\nvalue = 9.771'),\n",
       " Text(0.8412526997840173, 0.475, 'X[6] <= 96.8\\nsquared_error = 0.165\\nsamples = 4\\nvalue = 10.3'),\n",
       " Text(0.8369330453563715, 0.425, 'X[6] <= 94.5\\nsquared_error = 0.022\\nsamples = 2\\nvalue = 10.65'),\n",
       " Text(0.8347732181425486, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 10.5'),\n",
       " Text(0.8390928725701944, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 10.8'),\n",
       " Text(0.8455723542116631, 0.425, 'X[12] <= 28.15\\nsquared_error = 0.062\\nsamples = 2\\nvalue = 9.95'),\n",
       " Text(0.8434125269978402, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 9.7'),\n",
       " Text(0.847732181425486, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 10.2'),\n",
       " Text(0.8520518358531317, 0.475, 'X[5] <= 5.326\\nsquared_error = 0.896\\nsamples = 3\\nvalue = 9.067'),\n",
       " Text(0.8498920086393088, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 10.4'),\n",
       " Text(0.8542116630669546, 0.425, 'X[5] <= 5.44\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 8.4'),\n",
       " Text(0.8520518358531317, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 8.3'),\n",
       " Text(0.8563714902807775, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 8.5'),\n",
       " Text(0.7522948164146869, 0.775, 'squared_error = 0.0\\nsamples = 1\\nvalue = 27.5'),\n",
       " Text(0.9211494330453563, 0.925, 'X[5] <= 7.437\\nsquared_error = 73.061\\nsamples = 72\\nvalue = 37.967'),\n",
       " Text(0.884685475161987, 0.875, 'X[4] <= 0.659\\nsquared_error = 36.834\\nsamples = 42\\nvalue = 32.874'),\n",
       " Text(0.875067494600432, 0.825, 'X[7] <= 1.886\\nsquared_error = 17.045\\nsamples = 40\\nvalue = 33.882'),\n",
       " Text(0.8623110151187905, 0.775, 'X[0] <= 3.881\\nsquared_error = 18.923\\nsamples = 2\\nvalue = 45.65'),\n",
       " Text(0.8601511879049676, 0.725, 'squared_error = 0.0\\nsamples = 1\\nvalue = 41.3'),\n",
       " Text(0.8644708423326134, 0.725, 'squared_error = 0.0\\nsamples = 1\\nvalue = 50.0'),\n",
       " Text(0.8878239740820735, 0.775, 'X[9] <= 253.0\\nsquared_error = 9.274\\nsamples = 38\\nvalue = 33.263'),\n",
       " Text(0.8687904967602592, 0.725, 'X[0] <= 0.077\\nsquared_error = 2.394\\nsamples = 12\\nvalue = 35.408'),\n",
       " Text(0.8628509719222462, 0.675, 'X[6] <= 58.95\\nsquared_error = 1.702\\nsamples = 10\\nvalue = 34.97'),\n",
       " Text(0.857451403887689, 0.625, 'X[12] <= 3.765\\nsquared_error = 1.218\\nsamples = 7\\nvalue = 35.514'),\n",
       " Text(0.8531317494600432, 0.575, 'X[9] <= 237.0\\nsquared_error = 0.562\\nsamples = 2\\nvalue = 34.15'),\n",
       " Text(0.8509719222462203, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 33.4'),\n",
       " Text(0.8552915766738661, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 34.9'),\n",
       " Text(0.8617710583153347, 0.575, 'X[9] <= 204.5\\nsquared_error = 0.438\\nsamples = 5\\nvalue = 36.06'),\n",
       " Text(0.8596112311015118, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 37.2'),\n",
       " Text(0.8639308855291576, 0.525, 'X[6] <= 39.15\\nsquared_error = 0.142\\nsamples = 4\\nvalue = 35.775'),\n",
       " Text(0.8617710583153347, 0.475, 'squared_error = 0.0\\nsamples = 2\\nvalue = 35.4'),\n",
       " Text(0.8660907127429806, 0.475, 'X[4] <= 0.465\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 36.15'),\n",
       " Text(0.8639308855291576, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 36.2'),\n",
       " Text(0.8682505399568035, 0.425, 'squared_error = -0.0\\nsamples = 1\\nvalue = 36.1'),\n",
       " Text(0.8682505399568035, 0.625, 'X[1] <= 8.75\\nsquared_error = 0.527\\nsamples = 3\\nvalue = 33.7'),\n",
       " Text(0.8660907127429806, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 34.7'),\n",
       " Text(0.8704103671706264, 0.575, 'X[9] <= 219.0\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 33.2'),\n",
       " Text(0.8682505399568035, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 33.0'),\n",
       " Text(0.8725701943844493, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 33.4'),\n",
       " Text(0.8747300215982722, 0.675, 'X[1] <= 40.0\\nsquared_error = 0.09\\nsamples = 2\\nvalue = 37.6'),\n",
       " Text(0.8725701943844493, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 37.9'),\n",
       " Text(0.8768898488120951, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 37.3'),\n",
       " Text(0.9068574514038877, 0.725, 'X[10] <= 17.2\\nsquared_error = 9.346\\nsamples = 26\\nvalue = 32.273'),\n",
       " Text(0.8903887688984882, 0.675, 'X[11] <= 374.63\\nsquared_error = 5.212\\nsamples = 17\\nvalue = 33.488'),\n",
       " Text(0.8833693304535637, 0.625, 'X[9] <= 343.5\\nsquared_error = 0.423\\nsamples = 2\\nvalue = 29.65'),\n",
       " Text(0.8812095032397408, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 30.3'),\n",
       " Text(0.8855291576673866, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 29.0'),\n",
       " Text(0.8974082073434125, 0.625, 'X[0] <= 0.725\\nsquared_error = 3.624\\nsamples = 15\\nvalue = 34.0'),\n",
       " Text(0.8898488120950324, 0.575, 'X[10] <= 15.25\\nsquared_error = 2.417\\nsamples = 13\\nvalue = 34.485'),\n",
       " Text(0.8812095032397408, 0.525, 'X[11] <= 391.345\\nsquared_error = 1.616\\nsamples = 8\\nvalue = 35.312'),\n",
       " Text(0.8747300215982722, 0.475, 'X[11] <= 380.485\\nsquared_error = 0.127\\nsamples = 4\\nvalue = 36.475'),\n",
       " Text(0.8725701943844493, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 37.0'),\n",
       " Text(0.8768898488120951, 0.425, 'X[7] <= 1.912\\nsquared_error = 0.047\\nsamples = 3\\nvalue = 36.3'),\n",
       " Text(0.8747300215982722, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 36.0'),\n",
       " Text(0.8790496760259179, 0.375, 'X[11] <= 389.19\\nsquared_error = 0.002\\nsamples = 2\\nvalue = 36.45'),\n",
       " Text(0.8768898488120951, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 36.5'),\n",
       " Text(0.8812095032397408, 0.325, 'squared_error = -0.0\\nsamples = 1\\nvalue = 36.4'),\n",
       " Text(0.8876889848812095, 0.475, 'X[6] <= 36.2\\nsquared_error = 0.403\\nsamples = 4\\nvalue = 34.15'),\n",
       " Text(0.8855291576673866, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 33.3'),\n",
       " Text(0.8898488120950324, 0.425, 'X[4] <= 0.542\\nsquared_error = 0.216\\nsamples = 3\\nvalue = 34.433'),\n",
       " Text(0.8876889848812095, 0.375, 'X[11] <= 394.55\\nsquared_error = 0.023\\nsamples = 2\\nvalue = 34.75'),\n",
       " Text(0.8855291576673866, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 34.6'),\n",
       " Text(0.8898488120950324, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 34.9'),\n",
       " Text(0.8920086393088553, 0.375, 'squared_error = -0.0\\nsamples = 1\\nvalue = 33.8'),\n",
       " Text(0.8984881209503239, 0.525, 'X[11] <= 395.82\\nsquared_error = 0.846\\nsamples = 5\\nvalue = 33.16'),\n",
       " Text(0.896328293736501, 0.475, 'X[0] <= 0.011\\nsquared_error = 0.112\\nsamples = 4\\nvalue = 32.725'),\n",
       " Text(0.8941684665226782, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 32.2'),\n",
       " Text(0.8984881209503239, 0.425, 'X[5] <= 7.059\\nsquared_error = 0.027\\nsamples = 3\\nvalue = 32.9'),\n",
       " Text(0.896328293736501, 0.375, 'squared_error = 0.0\\nsamples = 1\\nvalue = 33.1'),\n",
       " Text(0.9006479481641468, 0.375, 'X[7] <= 7.346\\nsquared_error = 0.01\\nsamples = 2\\nvalue = 32.8'),\n",
       " Text(0.8984881209503239, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 32.7'),\n",
       " Text(0.9028077753779697, 0.325, 'squared_error = 0.0\\nsamples = 1\\nvalue = 32.9'),\n",
       " Text(0.9006479481641468, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 34.9'),\n",
       " Text(0.9049676025917927, 0.575, 'X[0] <= 0.805\\nsquared_error = 0.023\\nsamples = 2\\nvalue = 30.85'),\n",
       " Text(0.9028077753779697, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 30.7'),\n",
       " Text(0.9071274298056156, 0.525, 'squared_error = -0.0\\nsamples = 1\\nvalue = 31.0'),\n",
       " Text(0.9233261339092873, 0.675, 'X[6] <= 83.1\\nsquared_error = 9.097\\nsamples = 9\\nvalue = 29.978'),\n",
       " Text(0.91792656587473, 0.625, 'X[5] <= 7.121\\nsquared_error = 2.448\\nsamples = 7\\nvalue = 31.357'),\n",
       " Text(0.9136069114470843, 0.575, 'X[4] <= 0.46\\nsquared_error = 0.202\\nsamples = 2\\nvalue = 29.15'),\n",
       " Text(0.9114470842332614, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 29.6'),\n",
       " Text(0.9157667386609071, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 28.7'),\n",
       " Text(0.9222462203023758, 0.575, 'X[8] <= 6.0\\nsquared_error = 0.618\\nsamples = 5\\nvalue = 32.24'),\n",
       " Text(0.9200863930885529, 0.525, 'squared_error = 0.0\\nsamples = 2\\nvalue = 33.2'),\n",
       " Text(0.9244060475161987, 0.525, 'X[7] <= 3.91\\nsquared_error = 0.007\\nsamples = 3\\nvalue = 31.6'),\n",
       " Text(0.9222462203023758, 0.475, 'X[11] <= 374.11\\nsquared_error = 0.003\\nsamples = 2\\nvalue = 31.65'),\n",
       " Text(0.9200863930885529, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 31.6'),\n",
       " Text(0.9244060475161987, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 31.7'),\n",
       " Text(0.9265658747300216, 0.475, 'squared_error = -0.0\\nsamples = 1\\nvalue = 31.5'),\n",
       " Text(0.9287257019438445, 0.625, 'X[5] <= 6.979\\nsquared_error = 2.403\\nsamples = 2\\nvalue = 25.15'),\n",
       " Text(0.9265658747300216, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 26.7'),\n",
       " Text(0.9308855291576674, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 23.6'),\n",
       " Text(0.8943034557235421, 0.825, 'X[12] <= 15.325\\nsquared_error = 5.29\\nsamples = 2\\nvalue = 12.7'),\n",
       " Text(0.8921436285097192, 0.775, 'squared_error = 0.0\\nsamples = 1\\nvalue = 15.0'),\n",
       " Text(0.896463282937365, 0.775, 'squared_error = 0.0\\nsamples = 1\\nvalue = 10.4'),\n",
       " Text(0.9576133909287257, 0.875, 'X[0] <= 2.742\\nsquared_error = 36.628\\nsamples = 30\\nvalue = 45.097'),\n",
       " Text(0.9554535637149028, 0.825, 'X[10] <= 14.8\\nsquared_error = 18.697\\nsamples = 29\\nvalue = 45.897'),\n",
       " Text(0.9395248380129589, 0.775, 'X[5] <= 7.706\\nsquared_error = 8.027\\nsamples = 14\\nvalue = 48.3'),\n",
       " Text(0.9330453563714903, 0.725, 'X[11] <= 381.4\\nsquared_error = 9.462\\nsamples = 4\\nvalue = 44.725'),\n",
       " Text(0.9308855291576674, 0.675, 'squared_error = 0.0\\nsamples = 1\\nvalue = 50.0'),\n",
       " Text(0.9352051835853131, 0.675, 'X[0] <= 0.278\\nsquared_error = 0.249\\nsamples = 3\\nvalue = 42.967'),\n",
       " Text(0.9330453563714903, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 42.3'),\n",
       " Text(0.937365010799136, 0.625, 'X[6] <= 71.0\\nsquared_error = 0.04\\nsamples = 2\\nvalue = 43.3'),\n",
       " Text(0.9352051835853131, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 43.5'),\n",
       " Text(0.9395248380129589, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 43.1'),\n",
       " Text(0.9460043196544277, 0.725, 'X[12] <= 3.755\\nsquared_error = 0.296\\nsamples = 10\\nvalue = 49.73'),\n",
       " Text(0.9438444924406048, 0.675, 'squared_error = 0.0\\nsamples = 6\\nvalue = 50.0'),\n",
       " Text(0.9481641468682506, 0.675, 'X[0] <= 0.549\\nsquared_error = 0.467\\nsamples = 4\\nvalue = 49.325'),\n",
       " Text(0.9460043196544277, 0.625, 'X[4] <= 0.532\\nsquared_error = 0.023\\nsamples = 2\\nvalue = 48.65'),\n",
       " Text(0.9438444924406048, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 48.5'),\n",
       " Text(0.9481641468682506, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 48.8'),\n",
       " Text(0.9503239740820735, 0.625, 'squared_error = -0.0\\nsamples = 2\\nvalue = 50.0'),\n",
       " Text(0.9713822894168467, 0.775, 'X[11] <= 385.48\\nsquared_error = 18.232\\nsamples = 15\\nvalue = 43.653'),\n",
       " Text(0.9611231101511879, 0.725, 'X[0] <= 0.323\\nsquared_error = 3.298\\nsamples = 5\\nvalue = 47.16'),\n",
       " Text(0.9568034557235421, 0.675, 'X[7] <= 3.135\\nsquared_error = 0.616\\nsamples = 3\\nvalue = 45.833'),\n",
       " Text(0.9546436285097192, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 44.8'),\n",
       " Text(0.958963282937365, 0.625, 'X[12] <= 3.465\\nsquared_error = 0.122\\nsamples = 2\\nvalue = 46.35'),\n",
       " Text(0.9568034557235421, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 46.0'),\n",
       " Text(0.9611231101511879, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 46.7'),\n",
       " Text(0.9654427645788337, 0.675, 'X[7] <= 3.273\\nsquared_error = 0.722\\nsamples = 2\\nvalue = 49.15'),\n",
       " Text(0.9632829373650108, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 50.0'),\n",
       " Text(0.9676025917926566, 0.625, 'squared_error = -0.0\\nsamples = 1\\nvalue = 48.3'),\n",
       " Text(0.9816414686825053, 0.725, 'X[0] <= 0.061\\nsquared_error = 16.476\\nsamples = 10\\nvalue = 41.9'),\n",
       " Text(0.9740820734341252, 0.675, 'X[7] <= 3.947\\nsquared_error = 6.569\\nsamples = 3\\nvalue = 46.467'),\n",
       " Text(0.9719222462203023, 0.625, 'squared_error = 0.0\\nsamples = 1\\nvalue = 50.0'),\n",
       " Text(0.9762419006479481, 0.625, 'X[1] <= 55.0\\nsquared_error = 0.49\\nsamples = 2\\nvalue = 44.7'),\n",
       " Text(0.9740820734341252, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 45.4'),\n",
       " Text(0.978401727861771, 0.575, 'squared_error = -0.0\\nsamples = 1\\nvalue = 44.0'),\n",
       " Text(0.9892008639308856, 0.675, 'X[6] <= 44.35\\nsquared_error = 7.954\\nsamples = 7\\nvalue = 39.943'),\n",
       " Text(0.9848812095032398, 0.625, 'X[12] <= 3.555\\nsquared_error = 0.25\\nsamples = 2\\nvalue = 43.3'),\n",
       " Text(0.9827213822894169, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 42.8'),\n",
       " Text(0.9870410367170627, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 43.8'),\n",
       " Text(0.9935205183585313, 0.625, 'X[5] <= 7.728\\nsquared_error = 4.724\\nsamples = 5\\nvalue = 38.6'),\n",
       " Text(0.9913606911447084, 0.575, 'squared_error = 0.0\\nsamples = 1\\nvalue = 35.2'),\n",
       " Text(0.9956803455723542, 0.575, 'X[0] <= 0.479\\nsquared_error = 2.293\\nsamples = 4\\nvalue = 39.45'),\n",
       " Text(0.9935205183585313, 0.525, 'X[11] <= 391.47\\nsquared_error = 0.807\\nsamples = 3\\nvalue = 38.7'),\n",
       " Text(0.9913606911447084, 0.475, 'squared_error = 0.0\\nsamples = 1\\nvalue = 37.6'),\n",
       " Text(0.9956803455723542, 0.475, 'X[7] <= 3.118\\nsquared_error = 0.302\\nsamples = 2\\nvalue = 39.25'),\n",
       " Text(0.9935205183585313, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 39.8'),\n",
       " Text(0.9978401727861771, 0.425, 'squared_error = 0.0\\nsamples = 1\\nvalue = 38.7'),\n",
       " Text(0.9978401727861771, 0.525, 'squared_error = 0.0\\nsamples = 1\\nvalue = 41.7'),\n",
       " Text(0.9597732181425486, 0.825, 'squared_error = -0.0\\nsamples = 1\\nvalue = 21.9')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "model = tree.DecisionTreeRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))\n",
    "\n",
    "tree.plot_tree(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.9166666666666666, 'X[3] <= 0.8\\nsquared_error = 0.667\\nsamples = 150\\nvalue = 1.0'),\n",
       " Text(0.4230769230769231, 0.75, 'squared_error = 0.0\\nsamples = 50\\nvalue = 0.0'),\n",
       " Text(0.5769230769230769, 0.75, 'X[3] <= 1.75\\nsquared_error = 0.25\\nsamples = 100\\nvalue = 1.5'),\n",
       " Text(0.3076923076923077, 0.5833333333333334, 'X[2] <= 4.95\\nsquared_error = 0.084\\nsamples = 54\\nvalue = 1.093'),\n",
       " Text(0.15384615384615385, 0.4166666666666667, 'X[3] <= 1.65\\nsquared_error = 0.02\\nsamples = 48\\nvalue = 1.021'),\n",
       " Text(0.07692307692307693, 0.25, 'squared_error = 0.0\\nsamples = 47\\nvalue = 1.0'),\n",
       " Text(0.23076923076923078, 0.25, 'squared_error = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(0.46153846153846156, 0.4166666666666667, 'X[3] <= 1.55\\nsquared_error = 0.222\\nsamples = 6\\nvalue = 1.667'),\n",
       " Text(0.38461538461538464, 0.25, 'squared_error = 0.0\\nsamples = 3\\nvalue = 2.0'),\n",
       " Text(0.5384615384615384, 0.25, 'X[2] <= 5.45\\nsquared_error = 0.222\\nsamples = 3\\nvalue = 1.333'),\n",
       " Text(0.46153846153846156, 0.08333333333333333, 'squared_error = 0.0\\nsamples = 2\\nvalue = 1.0'),\n",
       " Text(0.6153846153846154, 0.08333333333333333, 'squared_error = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(0.8461538461538461, 0.5833333333333334, 'X[2] <= 4.85\\nsquared_error = 0.021\\nsamples = 46\\nvalue = 1.978'),\n",
       " Text(0.7692307692307693, 0.4166666666666667, 'X[0] <= 5.95\\nsquared_error = 0.222\\nsamples = 3\\nvalue = 1.667'),\n",
       " Text(0.6923076923076923, 0.25, 'squared_error = 0.0\\nsamples = 1\\nvalue = 1.0'),\n",
       " Text(0.8461538461538461, 0.25, 'squared_error = 0.0\\nsamples = 2\\nvalue = 2.0'),\n",
       " Text(0.9230769230769231, 0.4166666666666667, 'squared_error = 0.0\\nsamples = 43\\nvalue = 2.0')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "tree.plot_tree(model.fit(iris.data, iris.target)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Rnadom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9747899159663865\n",
      "[[27  0]\n",
      " [ 3 89]]\n"
     ]
    }
   ],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "forest = ensemble.RandomForestClassifier()\n",
    "forest.fit(X, y)\n",
    "\n",
    "y_pred = forest.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.556039274449674\n",
      "0.3078687051273822\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "forest = ensemble.RandomForestRegressor()\n",
    "forest.fit(X, y)\n",
    "\n",
    "y_pred = forest.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9411764705882353\n",
      "[[26  1]\n",
      " [ 6 86]]\n"
     ]
    }
   ],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "adaboost = ensemble.AdaBoostClassifier()\n",
    "adaboost.fit(X, y)\n",
    "\n",
    "y_pred = adaboost.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.190367096282228\n",
      "0.038920020353554574\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "adaboost = ensemble.AdaBoostRegressor()\n",
    "adaboost.fit(X, y)\n",
    "\n",
    "y_pred = adaboost.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAY\\AppData\\Local\\Temp\\ipykernel_28080\\4148141141.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  alpha = 0.5 * np.log((1 - epsilon) / epsilon)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epsilon = np.arange(0, 1., 0.01)\n",
    "alpha = 0.5 * np.log((1 - epsilon) / epsilon)\n",
    "\n",
    "plt.plot(epsilon, alpha)\n",
    "plt.xlabel('error')\n",
    "plt.ylabel('alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "gradintboost = ensemble.GradientBoostingClassifier()\n",
    "gradintboost.fit(X, y)\n",
    "\n",
    "y_pred = gradintboost.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "gradintboost = ensemble.GradientBoostingRegressor()\n",
    "gradintboost.fit(X, y)\n",
    "\n",
    "y_pred = gradintboost.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.google.com/presentation/d/1IS3qRavO3q-w3ej9fCofw0uFsqMEzIumH-xWYb8RWYc/edit#slide=id.g1027777ea9b_0_938\n",
    "\n",
    "### 앙상블 모델\n",
    " - 모델들의 민주주의\n",
    "\n",
    "### 랜덤 포레스트\n",
    " - 모델 여러개를 가지고, 각각 모덷들이 다른 결과를 낸다.\n",
    " - 이런 결과들을 모아서 하는게 앙상블\n",
    "\n",
    "### 기본 개념\n",
    " - 1인 1표제 (모델들의 민주주의) => 오버피팅 회피하는 획기적인 방법\n",
    " - 모델이 여러개이므로 한 모델이 오버피팅 된다고 해도, 나머지가 방어해줌\n",
    " \n",
    "<img src=\"./img/m1.png\" width=80% height=80%>\n",
    "\n",
    "- 트리1 : 퇴사 7 : 버텨 3\n",
    "- 트리2 : 퇴사 9 : 버텨 1 ... 라면,\n",
    "- 확률들을 더한다. 이때, 어떻게 의사결정을 할것인지가 핵심"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Baggind vs Boosting\n",
    "\n",
    "<img src=\"./img/m2.png\" width=80% height=80%>\n",
    "\n",
    "- 부스팅 기법을 쓴 모델이 정확도가 높다.\n",
    "- AdaBoost\n",
    "- Gradient Boost\n",
    "- XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Bagging 모델\n",
    " - x:data 에서, 각 일부로 x1, x2, x3 만든다. 따라서 데이터들이 다른 모델을 만들어서, 그 결과도 독립적이다. \n",
    " - 각모델의 가중치 등을 줘서 모델을 합쳐서 사용\n",
    "\n",
    "Boosting (오답에 더 집중)\n",
    "- x:data 로 x를 학습하고, 틀린데이터를 가지고 x' 를 학습하고, 또 틀린거로 x'' 를 학습함\n",
    "- 서로 앞에서 만든 모델의 틀린데이터를 학습하므로 정확도를 높인다. (오답에 높은 가중치)\n",
    "- 다만, 앙상블임에도 오버피팅 가능성이 있음\n",
    "- outlier에 취약\n",
    "- 순차학습이므로 속도가 느림 (성능은 좋으나 느림)\n",
    "\n",
    "---\n",
    "\n",
    "AdaBoost\n",
    " - 모델을 생성한 후, 오류 데이터에 가중치 부여\n",
    " - 모델의 오류를 가지고 모델의 Weight 계산\n",
    " \n",
    "Gradient Boost\n",
    " - 모델을 생성한 후, 오류 데이터에 가중치 부여\n",
    " - Gradient Descent를 이용하여 모델의 Weight 계산\n",
    " - 과적합의 가능성이 높음\n",
    "\n",
    "---\n",
    "XGBoost 나 Light BGM 은 속도를 개선시킨 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9243697478991597\n",
      "[[26  1]\n",
      " [ 8 84]]\n"
     ]
    }
   ],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "bagging = ensemble.BaggingClassifier()\n",
    "bagging.fit(X, y)\n",
    "\n",
    "y_pred = bagging.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.045526850732794\n",
      "0.10421133100807867\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "bagging = ensemble.BaggingRegressor()\n",
    "bagging.fit(X, y)\n",
    "\n",
    "y_pred = bagging.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 현재 가장 많이 쓰이는 2개 : XG Boost / Light GBM\n",
    "\n",
    "- 표의 경우, 딥러닝으로 성능이 안나올때, 위 두개를 사용하면 잘 나온다.\n",
    "\n",
    "- 성능을 더 높이고 싶을때\n",
    "    - xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "    - lgb_model = lgb.LGBMRegressor()\n",
    "    - 의 파라미터를 조정할 수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "트리 모델의 앙상블 모델\n",
    "\n",
    "- 트리모델 : 나무모양"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### XG Boost\n",
    "\n",
    "- https://github.com/dmlc/xgboost\n",
    "- https://arxiv.org/pdf/1603.02754.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:32:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9747899159663865\n",
      "[[27  0]\n",
      " [ 3 89]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAY\\anaconda3\\envs\\webai\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0467318225681534\n",
      "0.10367762506192169\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "xgb_model.fit(X, y)\n",
    "\n",
    "y_pred = xgb_model.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xgb.plot_tree(xgb_model, num_trees=0, rankdir='LR')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://free-eunb.tistory.com/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Light GBM\n",
    "\n",
    "- https://github.com/microsoft/LightGBM\n",
    "- https://kicarussays.tistory.com/38\n",
    "- https://papers.nips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_model.fit(X, y)\n",
    "\n",
    "y_pred = lgb_model.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor()\n",
    "lgb_model.fit(X, y)\n",
    "\n",
    "y_pred = lgb_model.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lgb.plot_tree(lgb_model, tree_index=1)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "model1 = neighbors.KNeighborsClassifier()\n",
    "model2 = linear_model.LogisticRegression(max_iter=5000)\n",
    "model3 = tree.DecisionTreeClassifier()\n",
    "\n",
    "voting = ensemble.VotingClassifier(estimators=[('knn', model1), ('lr', model2), ('tree', model3)], voting='soft')\n",
    "voting.fit(X, y)\n",
    "\n",
    "y_pred = voting.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "model1 = neighbors.KNeighborsRegressor()\n",
    "model2 = linear_model.LinearRegression()\n",
    "model3 = tree.DecisionTreeRegressor()\n",
    "\n",
    "voting = ensemble.VotingRegressor(estimators=[('knn', model1), ('lr', model2), ('tree', model3)])\n",
    "voting.fit(X, y)\n",
    "\n",
    "y_pred = voting.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "X = cancer.data[:450, :]\n",
    "y = cancer.target[:450]\n",
    "testx = cancer.data[450:, :]\n",
    "testy = cancer.target[450:]\n",
    "\n",
    "model1 = neighbors.KNeighborsClassifier()\n",
    "model2 = linear_model.LogisticRegression(max_iter=5000)\n",
    "model3 = tree.DecisionTreeClassifier()\n",
    "\n",
    "stack = ensemble.StackingClassifier(estimators=[('knn', model1), ('lr', model2), ('tree', model3)])\n",
    "stack.fit(X, y)\n",
    "\n",
    "y_pred = stack.predict(testx)\n",
    "print(metrics.accuracy_score(testy, y_pred))\n",
    "print(metrics.confusion_matrix(testy, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "X = boston.data[:450, :]\n",
    "y = boston.target[:450]\n",
    "testx = boston.data[450:, :]\n",
    "testy = boston.target[450:]\n",
    "\n",
    "model1 = neighbors.KNeighborsRegressor()\n",
    "model2 = linear_model.LinearRegression()\n",
    "model3 = tree.DecisionTreeRegressor()\n",
    "\n",
    "stack = ensemble.StackingRegressor(estimators=[('knn', model1), ('lr', model2), ('tree', model3)])\n",
    "stack.fit(X, y)\n",
    "\n",
    "y_pred = stack.predict(testx)\n",
    "print(metrics.mean_squared_error(testy, y_pred) ** 0.5)\n",
    "print(metrics.r2_score(testy, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# 비지도 학습\n",
    "\n",
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cluster.KMeans(init=\"k-means++\", n_clusters=2, random_state=0)\n",
    "model.fit(cancer.data)\n",
    "y_pred = model.labels_\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "labels = pd.DataFrame(iris.target)\n",
    "labels.columns=['labels']\n",
    "\n",
    "data = pd.DataFrame(iris.data)\n",
    "data.columns=['Sepal length','Sepal width','Petal length','Petal width']\n",
    "data = pd.concat([data,labels],axis=1)\n",
    "\n",
    "feature = data[ ['Sepal length','Sepal width']]\n",
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# create model and prediction\n",
    "model = KMeans(n_clusters=3,algorithm='auto')\n",
    "model.fit(feature)\n",
    "predict = pd.DataFrame(model.predict(feature))\n",
    "predict.columns=['predict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.concat([feature, predict],axis=1)\n",
    "plt.scatter(r['Sepal length'],r['Sepal width'],c=r['predict'],alpha=0.5)\n",
    "\n",
    "centers = pd.DataFrame(model.cluster_centers_,columns=['Sepal length','Sepal width'])\n",
    "center_x = centers['Sepal length']\n",
    "center_y = centers['Sepal width']\n",
    "plt.scatter(center_x,center_y,s=50,marker='D',c='r')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inertia value를 이용한 적정 군집수 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(feature)\n",
    "    inertias.append(model.inertia_)\n",
    "    \n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 크로스 테이블 체크를 이용한 모델 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(data['labels'], r['predict'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "labels = pd.DataFrame(iris.target)\n",
    "labels.columns=['labels']\n",
    "data = pd.DataFrame(iris.data)\n",
    "data.columns=['Sepal length','Sepal width','Petal length','Petal width']\n",
    "data = pd.concat([data, labels], axis=1)\n",
    "\n",
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(data,method='complete')\n",
    "\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "plt.figure(figsize=(20, 10))\n",
    "dendrogram(mergings,\n",
    "           labels=labels.values,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=8\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "predict = pd.DataFrame(fcluster(mergings, 3, criterion='distance'))\n",
    "predict.columns=['predict']\n",
    "ct = pd.crosstab(predict['predict'],labels['labels'])\n",
    "print(ct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "labels = pd.DataFrame(iris.target)\n",
    "labels.columns=['labels']\n",
    "data = pd.DataFrame(iris.data)\n",
    "data.columns=['Sepal length','Sepal width','Petal length','Petal width']\n",
    "data = pd.concat([data,labels],axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns\n",
    "\n",
    "feature = data[ ['Sepal length','Sepal width','Petal length','Petal width']]\n",
    "feature.head()\n",
    "\n",
    "# create model and prediction\n",
    "model = DBSCAN(min_samples=6)\n",
    "predict = pd.DataFrame(model.fit_predict(feature))\n",
    "predict.columns=['predict']\n",
    "\n",
    "# concatenate labels to df as a new column\n",
    "r = pd.concat([feature,predict],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# scatter plot\n",
    "fig = plt.figure( figsize=(6,6))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "ax.scatter(r['Sepal length'],r['Sepal width'],r['Petal length'],c=r['predict'],alpha=0.5)\n",
    "ax.set_xlabel('Sepal lenth')\n",
    "ax.set_ylabel('Sepal width')\n",
    "ax.set_zlabel('Petal length')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(data['labels'],r['predict'])\n",
    "print (ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "labels = pd.DataFrame(iris.target)\n",
    "labels.columns=['labels']\n",
    "data = pd.DataFrame(iris.data,columns=['Sepal length','Sepal width','Petal length','Petal width'])\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "ax.scatter(data['Sepal length'],data['Sepal width'],data['Petal length'],c=labels['labels'], alpha=0.5)\n",
    "ax.set_xlabel('Sepal lenth')\n",
    "ax.set_ylabel('Sepal width')\n",
    "ax.set_zlabel('Petal length')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scaler: scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a PCA instance: pca\n",
    "pca = PCA()\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler,pca)\n",
    "\n",
    "# Fit the pipeline to 'samples'\n",
    "pipeline.fit(data)\n",
    "\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = PCA(n_components=2)\n",
    "pca_features = model.fit_transform(data)\n",
    "\n",
    "xf = pca_features[:,0]\n",
    "yf = pca_features[:,1]\n",
    "plt.scatter(xf,yf,c=labels['labels'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = PCA(n_components=1)\n",
    "pca_features = model.fit_transform(data)\n",
    "\n",
    "xf = pca_features[:,0]\n",
    "yf = len(xf)*[0]\n",
    "plt.scatter(xf,yf,c=labels['labels']);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = TSNE(learning_rate=100)\n",
    "transformed = model.fit_transform(feature)\n",
    "\n",
    "xs = transformed[:,0]\n",
    "ys = transformed[:,1]\n",
    "plt.scatter(xs,ys,c=labels['labels'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logit_model = linear_model.LogisticRegression(max_iter=10, multi_class='multinomial')\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logit_model = linear_model.RidgeClassifier(max_iter=10)\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "logit_model = tree.DecisionTreeClassifier()\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "logit_model = ensemble.RandomForestClassifier(n_estimators=10)\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "logit_model = ensemble.BaggingClassifier()\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "logit_model = ensemble.GradientBoostingClassifier(n_estimators=10)\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "logit_model = ensemble.AdaBoostClassifier()\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softmax\", random_state=42)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "y_pred = xgb_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(objective=\"multiclass\")\n",
    "lgb_model.fit(x_train, y_train)\n",
    "y_pred = lgb_model.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet 이 설명력이 높은 이유\n",
    "\n",
    "<img src=\"./img/c24.png\" width=80% height=80%>\n",
    "\n",
    "- 최종에 도달할수 있는 가지수가 굉장히 많음\n",
    "- 그 가지 수 들이 모두 앙상블이라고 생각하면됨. (정확도 높아짐)\n",
    "- (boosting 모델 : 잔차를 획기적으로 줄이는 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40b396f7bb4524eebe16d5148ef674cb630ecbb9edf31b1d2c1678c5ede47175"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('webai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
