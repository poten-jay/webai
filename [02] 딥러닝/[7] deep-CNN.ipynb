{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼셉트론의 이해 (추가)\n",
    "\n",
    "<img src=\"./img/c17.jpg\" width=80% height=80%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과거 퍼셉트론 모델에서는 Activation 펑션이 step funtion이 되어야 한다는 고정관념이 있었다.\n",
    "\n",
    "- Activation (활성하 함수)\n",
    "- Sigmodi, tanh, ReLU, Leaky ReLU, Maxout, ELU 등\n",
    "\n",
    "<img src=\"./img/c18.png\" width=80% height=80%>\n",
    "\n",
    "- 하지만 이런 구조에서 문제가 생김.\n",
    "\n",
    "### Vanishing Gradient (기울기 소멸 문제)\n",
    "\n",
    "- loss 값이 낮아지는 방향으로 이동하는 과정에서, activation 을 통해 0~1 사이 값으로 바뀌어서 큰 신호와 작은 신호의 구분히 모호해짐.\n",
    "- 이 상태로 층을 지나갈 수록 뒤로 전해지지 않음. (깊게 학습하지 못함)\n",
    "- 깊게 학습시키지 못하면 정확도가 떨어짐\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG Net\n",
    "\n",
    "- 220405 / CNN[(4)]\n",
    "\n",
    "유명해진 이유 : 2014년 출시 => 너무 쉬워서\n",
    "\n",
    "<img src=\"./img/c19.png\" width=100% height=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (224, 224) 입력 : (3, 3) * 64 Conv\n",
    "- (224, 224) 입력 : (3, 3) * 64 Conv\n",
    "- pool => 1/2\n",
    "- (112, 112) 입력 : (3, 3) * 128 Conv\n",
    "- (112, 112) 입력 : (3, 3) * 128 Conv\n",
    "- pool => 1/2\n",
    "- (56, 56) 입력 : (3, 3) * 256 Conv\n",
    "- (56, 56) 입력 : (3, 3) * 256 Conv\n",
    "- (56, 56) 입력 : (3, 3) * 256 Conv\n",
    "- pool => 1/2\n",
    "- (28, 28) 입력 : (3, 3) * 512 Conv\n",
    "- (28, 28) 입력 : (3, 3) * 512 Conv\n",
    "- (28, 28) 입력 : (3, 3) * 512 Conv\n",
    "- pool => 1/2\n",
    "- Flatten : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/c20.png\" width=50% height=50%>\n",
    "\n",
    "- 3x3  convolution, stride 1 활용\n",
    "- 간단한 구조로 좋은 성과를 내었다.\n",
    "- 파라미터의 개수가 많다\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 사이파 텐 이미지\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 50,423,626\n",
      "Trainable params: 50,423,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 코드 구현\n",
    "\n",
    "X = tf.keras.Input(shape=[32, 32, 3])\n",
    "\n",
    "H = tf.keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"swish\")(X)\n",
    "H = tf.keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"swish\")(H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H1 = tf.keras.layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"swish\")(H)\n",
    "H1 = tf.keras.layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"swish\")(H1)\n",
    "H1 = tf.keras.layers.MaxPool2D()(H1)\n",
    "\n",
    "H2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\", activation=\"swish\")(H1)\n",
    "H2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\", activation=\"swish\")(H2)\n",
    "H2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\", activation=\"swish\")(H2)\n",
    "H2 = tf.keras.layers.MaxPool2D()(H2)\n",
    "\n",
    "H3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\", activation=\"swish\")(H2)\n",
    "H3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\", activation=\"swish\")(H3)\n",
    "H3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\", activation=\"swish\")(H3)\n",
    "H3 = tf.keras.layers.MaxPool2D()(H3)\n",
    "\n",
    "H4 = tf.keras.layers.Flatten()(H3)\n",
    "H4 = tf.keras.layers.Dense(4096, activation=\"swish\")(H4)\n",
    "H4 = tf.keras.layers.Dense(4096, activation=\"swish\")(H4)\n",
    "H4 = tf.keras.layers.Dense(4096, activation=\"swish\")(H4)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H4)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컴퓨터가 학습해야 하는 파라미터 : 5000만개\n",
    "\n",
    "- 느림.\n",
    "\n",
    "- 빠르게 하려면? batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "352/352 [==============================] - 16s 37ms/step - loss: 50.5657 - accuracy: 0.1686 - val_loss: 2.7666 - val_accuracy: 0.1262\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 14s 40ms/step - loss: 29.8182 - accuracy: 0.1684 - val_loss: 2.6950 - val_accuracy: 0.1578\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 13s 37ms/step - loss: 2.4834 - accuracy: 0.3179 - val_loss: 1.4613 - val_accuracy: 0.4638\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 14s 40ms/step - loss: 1.9057 - accuracy: 0.4533 - val_loss: 1.2788 - val_accuracy: 0.5586\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 13s 37ms/step - loss: 1.7177 - accuracy: 0.5250 - val_loss: 1.3597 - val_accuracy: 0.5648\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 14s 39ms/step - loss: 1.8266 - accuracy: 0.5227 - val_loss: 1.1804 - val_accuracy: 0.5934\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 14s 41ms/step - loss: 1.4112 - accuracy: 0.5826 - val_loss: 1.0950 - val_accuracy: 0.6346\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 13s 37ms/step - loss: 1.2215 - accuracy: 0.6371 - val_loss: 1.5443 - val_accuracy: 0.5392\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 14s 39ms/step - loss: 1.0014 - accuracy: 0.6768 - val_loss: 4.4130 - val_accuracy: 0.4442\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 13s 37ms/step - loss: 1.5274 - accuracy: 0.7005 - val_loss: 1.0911 - val_accuracy: 0.6612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x215e530ba30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 50,485,578\n",
      "Trainable params: 50,452,554\n",
      "Non-trainable params: 33,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG 16 코드 구현\n",
    "\n",
    "X = tf.keras.Input(shape=[32, 32, 3])\n",
    "\n",
    "H = tf.keras.layers.Conv2D(64, kernel_size=3, padding=\"same\")(X)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "H = tf.keras.layers.Conv2D(64, kernel_size=3, padding=\"same\")(H)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H1 = tf.keras.layers.Conv2D(128, kernel_size=3, padding=\"same\")(H)\n",
    "H1 = tf.keras.layers.BatchNormalization()(H1)\n",
    "H1 = tf.keras.layers.Activation(\"swish\")(H1)\n",
    "H1 = tf.keras.layers.Conv2D(128, kernel_size=3, padding=\"same\")(H1)\n",
    "H1 = tf.keras.layers.BatchNormalization()(H1)\n",
    "H1 = tf.keras.layers.Activation(\"swish\")(H1)\n",
    "H1 = tf.keras.layers.MaxPool2D()(H1)\n",
    "\n",
    "H2 = tf.keras.layers.Conv2D(256, kernel_size=3, padding=\"same\")(H1)\n",
    "H2 = tf.keras.layers.BatchNormalization()(H2)\n",
    "H2 = tf.keras.layers.Activation(\"swish\")(H2)\n",
    "H2 = tf.keras.layers.Conv2D(256, kernel_size=3, padding=\"same\")(H2)\n",
    "H2 = tf.keras.layers.BatchNormalization()(H2)\n",
    "H2 = tf.keras.layers.Activation(\"swish\")(H2)\n",
    "H2 = tf.keras.layers.Conv2D(256, kernel_size=3, padding=\"same\")(H2)\n",
    "H2 = tf.keras.layers.BatchNormalization()(H2)\n",
    "H2 = tf.keras.layers.Activation(\"swish\")(H2)\n",
    "H2 = tf.keras.layers.MaxPool2D()(H2)\n",
    "\n",
    "H3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\")(H2)\n",
    "H3 = tf.keras.layers.BatchNormalization()(H3)\n",
    "H3 = tf.keras.layers.Activation(\"swish\")(H3)\n",
    "H3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\")(H3)\n",
    "H3 = tf.keras.layers.BatchNormalization()(H3)\n",
    "H3 = tf.keras.layers.Activation(\"swish\")(H3)\n",
    "H3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\")(H3)\n",
    "H3 = tf.keras.layers.BatchNormalization()(H3)\n",
    "H3 = tf.keras.layers.Activation(\"swish\")(H3)\n",
    "H3 = tf.keras.layers.MaxPool2D()(H3)\n",
    "\n",
    "H4 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\")(H3)\n",
    "H4 = tf.keras.layers.BatchNormalization()(H4)\n",
    "H4 = tf.keras.layers.Activation(\"swish\")(H4)\n",
    "H4 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\")(H4)\n",
    "H4 = tf.keras.layers.BatchNormalization()(H4)\n",
    "H4 = tf.keras.layers.Activation(\"swish\")(H4)\n",
    "H4 = tf.keras.layers.Conv2D(512, kernel_size=3, padding=\"same\")(H4)\n",
    "H4 = tf.keras.layers.BatchNormalization()(H4)\n",
    "H4 = tf.keras.layers.Activation(\"swish\")(H4)\n",
    "H4 = tf.keras.layers.MaxPool2D()(H4)\n",
    "\n",
    "H5 = tf.keras.layers.Flatten()(H4)\n",
    "H5 = tf.keras.layers.Dense(4096)(H5)\n",
    "H5 = tf.keras.layers.BatchNormalization()(H5)\n",
    "H5 = tf.keras.layers.Activation(\"swish\")(H5)\n",
    "H5 = tf.keras.layers.Dense(4096)(H5)\n",
    "H5 = tf.keras.layers.BatchNormalization()(H5)\n",
    "H5 = tf.keras.layers.Activation(\"swish\")(H5)\n",
    "H5 = tf.keras.layers.Dense(4096)(H5)\n",
    "H5 = tf.keras.layers.BatchNormalization()(H5)\n",
    "H5 = tf.keras.layers.Activation(\"swish\")(H5)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H5)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "352/352 [==============================] - 35s 92ms/step - loss: 2.4590 - accuracy: 0.1612 - val_loss: 43.8763 - val_accuracy: 0.1758\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 30s 86ms/step - loss: 2.1821 - accuracy: 0.2167 - val_loss: 5.1803 - val_accuracy: 0.2244\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 30s 85ms/step - loss: 2.0760 - accuracy: 0.2792 - val_loss: 2.4165 - val_accuracy: 0.2598\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 30s 86ms/step - loss: 1.8263 - accuracy: 0.3609 - val_loss: 2.7150 - val_accuracy: 0.3482\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 30s 85ms/step - loss: 1.6654 - accuracy: 0.4231 - val_loss: 7.6725 - val_accuracy: 0.3856\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 32s 90ms/step - loss: 1.4800 - accuracy: 0.4788 - val_loss: 1.6121 - val_accuracy: 0.4424\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 33s 94ms/step - loss: 1.2737 - accuracy: 0.5502 - val_loss: 1.1965 - val_accuracy: 0.5706\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 31s 89ms/step - loss: 1.1574 - accuracy: 0.5968 - val_loss: 1.4113 - val_accuracy: 0.5160\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 30s 86ms/step - loss: 0.9843 - accuracy: 0.6493 - val_loss: 0.9892 - val_accuracy: 0.6352\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 30s 86ms/step - loss: 0.8792 - accuracy: 0.6892 - val_loss: 1.4237 - val_accuracy: 0.5480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2160e0c0f10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1142903e-06, 3.1198859e-05, 2.9510664e-04, 2.9702994e-01,\n",
       "        5.9454153e-05, 7.0014381e-01, 2.0540068e-03, 3.5427930e-04,\n",
       "        2.3462793e-05, 7.6503711e-06],\n",
       "       [1.6325252e-05, 9.9346220e-01, 1.7850088e-07, 2.9469055e-07,\n",
       "        8.8182706e-09, 1.5796589e-07, 1.0912457e-05, 3.2672304e-08,\n",
       "        1.0090997e-03, 5.5006980e-03],\n",
       "       [1.0957654e-01, 3.8772571e-01, 1.2236338e-02, 3.0326359e-02,\n",
       "        6.2005469e-03, 6.8072742e-03, 8.2649449e-03, 1.6306980e-02,\n",
       "        5.9012800e-02, 3.6354247e-01],\n",
       "       [2.7486365e-02, 1.2615463e-01, 3.4211485e-03, 9.1938572e-03,\n",
       "        1.0900543e-03, 1.9787923e-03, 7.4839829e-03, 6.4410473e-04,\n",
       "        8.0412763e-01, 1.8419351e-02],\n",
       "       [1.1338221e-05, 2.5790220e-04, 2.5304579e-03, 1.9145703e-02,\n",
       "        3.3837964e-03, 5.3743240e-03, 9.6889305e-01, 1.3629878e-05,\n",
       "        1.8334633e-04, 2.0642785e-04]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [8],\n",
       "       [8],\n",
       "       [0],\n",
       "       [6]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21772d4b580>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 def 만들기\n",
    "\n",
    "def vgg_block(n_filter, X, blocks=2):\n",
    "    H = tf.keras.layers.Conv2D(n_filter, kernel_size=3, padding=\"same\")(X)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    H = tf.keras.layers.Conv2D(n_filter, kernel_size=3, padding=\"same\")(H)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    if blocks == 3:\n",
    "        H = tf.keras.layers.Conv2D(n_filter, kernel_size=3, padding=\"same\")(H)\n",
    "        H = tf.keras.layers.BatchNormalization()(H)\n",
    "        H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 37,757,922\n",
      "Trainable params: 37,731,090\n",
      "Non-trainable params: 26,832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = tf.keras.Input(shape=[32, 32, 3])\n",
    "\n",
    "H = vgg_block(64, X, 2)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H = vgg_block(128, H, 2)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H = vgg_block(256, H, 3)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H = vgg_block(512, H, 3)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H = vgg_block(512, H, 3)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "H = tf.keras.layers.Flatten()(H)\n",
    "H = tf.keras.layers.Dense(4096)(H)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "H = tf.keras.layers.Dense(4096)(H)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "H = tf.keras.layers.Dense(1000)(H)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### GoogLeNet\n",
    "\n",
    "<img src=\"./img/c21.png\" width=100% height=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 중간 중간 병렬 처리가 되어 있는 것이 특징  \n",
    "병렬로 처리된 결과들을 다음에 사용함   \n",
    "\n",
    "- 처음 VGG 와 같이 만들어 져 1등, VGG는 2등을 함\n",
    "- 하지만, 초창기에는 VGG가 더 많이 사용됨\n",
    "- 이후 계속 버젼 업을 하여 inception net 으로 발전함 (개선)\n",
    "\n",
    "기울기 소실 문제를 방지하기 위해 분류기를 중간중간에 더 추가해 놨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet - Inception module (병렬구조)\n",
    "\n",
    "<img src=\"./img/c22.png\" width=80% height=80%>\n",
    "\n",
    "<img src=\"./img/c23.png\" width=80% height=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ResNet\n",
    "\n",
    "- Residual Block\n",
    "\n",
    "<img src=\"./img/c24.png\" width=100% height=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 블럭 하나 하나가, VGG 에서 사용했던 블럭과 같은 구조\n",
    "- VGG : 깊게 쌓기에 실패 했다.\n",
    "- ResNet 은 깊게 쌓기를 성공 : 중간중간 둥근 화살표\n",
    "- conv 2번 한것을 더했다 (tf.keras.layers.add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 100 layer 이상의 깊은 망\n",
    "- skip connection\n",
    "- residual learning building block\n",
    "- pre-activation 구조\n",
    "- 깊은 망 학습의 표준 모델이 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet - residual block\n",
    "\n",
    "- 깊은 망을 쌓을때 도움이 되는 개념\n",
    "\n",
    "<img src=\"./img/c25.png\" width=80% height=80%>\n",
    "\n",
    "- residual block 개념을 conv 에만 쓰는게 아니라, 조건이 된다면 dense 에서도 써도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개짜리 블럭\n",
    "def residual_block_2(n_filter, X):\n",
    "    H = tf.keras.layers.Conv2D(n_filter, kernel_size=3, padding=\"same\")(X)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H) # 논문에 relu 대신 swish 사용\n",
    "    H = tf.keras.layers.Conv2D(n_filter, kernel_size=3, padding=\"same\")(H)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Add()([X, H]) # add 를 하고 난 후 relu 하는게 핵심\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    return H\n",
    "\n",
    "# 3개 짜리 블럭\n",
    "def residual_block_3(n_filter, X):\n",
    "    H = tf.keras.layers.Conv2D(n_filter // 4, kernel_size=1, padding=\"same\")(X)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    H = tf.keras.layers.Conv2D(n_filter // 4, kernel_size=3, padding=\"same\")(H)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    H = tf.keras.layers.Conv2D(n_filter, kernel_size=1, padding=\"same\")(H)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Add()([X, H]) # add 를 하고 난 후 relu 하는게 핵심\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/c26.png\" width=80% height=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet 34 만들어보기\n",
    "\n",
    "X = tf.keras.Input(shape=[32, 32, 3])\n",
    "H = tf.keras.layers.Conv2D(64, kernel_size=7, padding=\"same\")(X)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "H = tf.keras.layers.MaxPool2D(pool_size=3)(H)\n",
    "\n",
    "# 64 * 3\n",
    "for i in range(3):\n",
    "    H = residual_block_2(64, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "# 64 채널 outpout, but 밑에서 128로 받아야 함. (채널 수 때문에 에러가 남)\n",
    "\n",
    "# 128 * 4\n",
    "for i in range(4):\n",
    "    H = residual_block_2(128, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "# 256 * 6\n",
    "for i in range(6):\n",
    "    H = residual_block_2(256, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "# 512 * 3\n",
    "for i in range(3):\n",
    "    H = residual_block_2(512, H)\n",
    "\n",
    "H = tf.keras.layers.GlobalAveragePooling2D()(H)\n",
    "\n",
    "H = tf.keras.layers.Flatten()(H)\n",
    "H = tf.keras.layers.Dense(1000)(H)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간 채널이 안맞기 때문에 에러가 난다. 따라서, 채널을 맞춰 줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 채널 맞춰주기\n",
    "\n",
    "# 2개짜리 블럭\n",
    "def residual_block_2(n_filter, X):\n",
    "    H = tf.keras.layers.Conv2D(n_filter, kernel_size=3, padding=\"same\")(X)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H) # 논문에 relu 대신 swish 사용\n",
    "    H = tf.keras.layers.Conv2D(n_filter, kernel_size=3, padding=\"same\")(H)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    # 간단한 해결방법 (회피)\n",
    "    if X.shape[-1] == n_filter:\n",
    "        H = tf.keras.layers.Add()([X, H]) # add 를 하고 난 후 relu 하는게 핵심\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 64)   9472        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 32, 32, 64)   256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 32, 32, 64)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 10, 10, 64)   0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 10, 10, 64)   36928       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 10, 10, 64)   256         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 10, 10, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 10, 10, 64)   36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 10, 10, 64)   256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 10, 10, 64)   0           max_pooling2d_8[0][0]            \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 10, 10, 64)   0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 10, 10, 64)   36928       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 10, 10, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 10, 10, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 10, 10, 64)   36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 10, 10, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 10, 10, 64)   0           activation_52[0][0]              \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 10, 10, 64)   0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 10, 10, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 10, 10, 64)   256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 10, 10, 64)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 10, 10, 64)   36928       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 10, 10, 64)   256         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 10, 10, 64)   0           activation_54[0][0]              \n",
      "                                                                 batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 10, 10, 64)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 5, 5, 64)     0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 5, 5, 128)    73856       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 5, 5, 128)    512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 5, 5, 128)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 5, 5, 128)    147584      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 5, 5, 128)    512         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 5, 5, 128)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 5, 5, 128)    147584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 5, 5, 128)    512         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5, 5, 128)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 5, 5, 128)    147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 5, 5, 128)    512         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 5, 5, 128)    0           activation_58[0][0]              \n",
      "                                                                 batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 5, 5, 128)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 5, 5, 128)    147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 5, 5, 128)    512         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 5, 5, 128)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 5, 5, 128)    147584      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 5, 5, 128)    512         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 5, 5, 128)    0           activation_60[0][0]              \n",
      "                                                                 batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 5, 5, 128)    0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 5, 5, 128)    147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 5, 5, 128)    512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 5, 5, 128)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 5, 5, 128)    147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 5, 5, 128)    512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 5, 5, 128)    0           activation_62[0][0]              \n",
      "                                                                 batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 5, 5, 128)    0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 2, 2, 128)    0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 2, 2, 256)    295168      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 2, 2, 256)    1024        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 2, 2, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 2, 2, 256)    590080      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 2, 2, 256)    1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 2, 2, 256)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 2, 2, 256)    590080      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 2, 2, 256)    1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 2, 2, 256)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 2, 2, 256)    590080      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 2, 2, 256)    1024        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 2, 2, 256)    0           activation_66[0][0]              \n",
      "                                                                 batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 2, 2, 256)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 2, 2, 256)    590080      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 256)    1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 2, 2, 256)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 256)    590080      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 2, 2, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 2, 2, 256)    0           activation_68[0][0]              \n",
      "                                                                 batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 2, 2, 256)    0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 2, 2, 256)    590080      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 2, 2, 256)    1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 256)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 2, 2, 256)    590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 2, 2, 256)    1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 2, 2, 256)    0           activation_70[0][0]              \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 2, 2, 256)    0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 2, 2, 256)    590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 2, 2, 256)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 256)    590080      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 256)    1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 2, 2, 256)    0           activation_72[0][0]              \n",
      "                                                                 batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 2, 2, 256)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 256)    590080      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 256)    1024        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 256)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 256)    590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 256)    1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 2, 2, 256)    0           activation_74[0][0]              \n",
      "                                                                 batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 256)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 1, 1, 256)    0           activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 1, 1, 512)    1180160     max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 1, 1, 512)    2048        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 1, 1, 512)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 512)    2359808     activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1, 1, 512)    2048        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 1, 1, 512)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 512)    2359808     activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1, 1, 512)    2048        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1, 1, 512)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 1, 1, 512)    2359808     activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1, 1, 512)    2048        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 1, 1, 512)    0           activation_78[0][0]              \n",
      "                                                                 batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1, 1, 512)    0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 1, 1, 512)    2359808     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 1, 1, 512)    2048        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1, 1, 512)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 1, 1, 512)    2359808     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 1, 1, 512)    2048        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 1, 1, 512)    0           activation_80[0][0]              \n",
      "                                                                 batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 1, 1, 512)    0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1000)         513000      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1000)         4000        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 1000)         0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           10010       activation_83[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,660,706\n",
      "Trainable params: 21,643,474\n",
      "Non-trainable params: 17,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet 34 만들어보기\n",
    "\n",
    "X = tf.keras.Input(shape=[32, 32, 3])\n",
    "H = tf.keras.layers.Conv2D(64, kernel_size=7, padding=\"same\")(X)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "H = tf.keras.layers.MaxPool2D(pool_size=3)(H)\n",
    "\n",
    "# 64 * 3\n",
    "for i in range(3):\n",
    "    H = residual_block_2(64, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "# 64 채널 outpout, but 밑에서 128로 받아야 함. (채널 수 때문에 에러가 남)\n",
    "\n",
    "# 128 * 4\n",
    "for i in range(4):\n",
    "    H = residual_block_2(128, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "# 256 * 6\n",
    "for i in range(6):\n",
    "    H = residual_block_2(256, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "# 512 * 3\n",
    "for i in range(3):\n",
    "    H = residual_block_2(512, H)\n",
    "\n",
    "H = tf.keras.layers.GlobalAveragePooling2D()(H)\n",
    "\n",
    "H = tf.keras.layers.Flatten()(H)\n",
    "H = tf.keras.layers.Dense(1000)(H)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "352/352 [==============================] - 29s 81ms/step - loss: 1.3993 - accuracy: 0.4864 - val_loss: 2.0482 - val_accuracy: 0.3190\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 40s 115ms/step - loss: 1.0543 - accuracy: 0.6228 - val_loss: 1.3105 - val_accuracy: 0.5410\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 39s 112ms/step - loss: 0.8667 - accuracy: 0.6938 - val_loss: 1.2870 - val_accuracy: 0.6258\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 38s 108ms/step - loss: 0.7325 - accuracy: 0.7453 - val_loss: 1.0994 - val_accuracy: 0.6346\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 39s 110ms/step - loss: 0.6184 - accuracy: 0.7876 - val_loss: 2.0502 - val_accuracy: 0.5026\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 32s 90ms/step - loss: 0.5292 - accuracy: 0.8192 - val_loss: 1.5396 - val_accuracy: 0.6224\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.4486 - accuracy: 0.8463 - val_loss: 1.2958 - val_accuracy: 0.6304\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 35s 100ms/step - loss: 0.3780 - accuracy: 0.8703 - val_loss: 2.0523 - val_accuracy: 0.5202\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 35s 100ms/step - loss: 0.3122 - accuracy: 0.8926 - val_loss: 1.1288 - val_accuracy: 0.6924\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 33s 94ms/step - loss: 0.2596 - accuracy: 0.9117 - val_loss: 1.7691 - val_accuracy: 0.5992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20fb400b2e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3블럭 채널 맞추기 \n",
    "\n",
    "def residual_block_3(n_filter, X):\n",
    "    H = tf.keras.layers.Conv2D(n_filter // 4, kernel_size=1, padding=\"same\")(X)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    H = tf.keras.layers.Conv2D(n_filter // 4, kernel_size=3, padding=\"same\")(H)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    H = tf.keras.layers.Conv2D(n_filter, kernel_size=1, padding=\"same\")(H)\n",
    "    H = tf.keras.layers.BatchNormalization()(H)\n",
    "\n",
    "    # 진정한 해결 방법\n",
    "    if X.shape[-1] != n_filter:\n",
    "        # 1x1 컨볼루션을 통해 채널 수를 맞춰 준 후 더한다. BN은 하면 안됨! \n",
    "        X = tf.keras.layers.Conv2D(n_filter, kernel_size=1, padding=\"same\")(X)\n",
    "    \n",
    "    H = tf.keras.layers.Add()([X, H])\n",
    "    H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 32, 32, 64)   9472        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 32, 32, 64)   256         conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 32, 32, 64)   0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 10, 10, 64)   0           activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 10, 10, 64)   4160        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 10, 10, 64)   256         conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 10, 10, 64)   0           batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 10, 10, 64)   36928       activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 10, 10, 64)   256         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 10, 10, 64)   0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 10, 10, 256)  16640       activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 10, 10, 256)  16640       max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 10, 10, 256)  1024        conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_137 (Add)                   (None, 10, 10, 256)  0           conv2d_398[0][0]                 \n",
      "                                                                 batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 10, 10, 256)  0           add_137[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 10, 10, 64)   16448       activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 10, 10, 64)   256         conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 10, 10, 64)   0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 10, 10, 64)   36928       activation_400[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 10, 10, 64)   256         conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 10, 10, 64)   0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 10, 10, 256)  16640       activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 10, 10, 256)  1024        conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_138 (Add)                   (None, 10, 10, 256)  0           activation_399[0][0]             \n",
      "                                                                 batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 10, 10, 256)  0           add_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 10, 10, 64)   16448       activation_402[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 10, 10, 64)   256         conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 10, 10, 64)   0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 10, 10, 64)   36928       activation_403[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 10, 10, 64)   256         conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 10, 10, 64)   0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 10, 10, 256)  16640       activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 10, 10, 256)  1024        conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_139 (Add)                   (None, 10, 10, 256)  0           activation_402[0][0]             \n",
      "                                                                 batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 10, 10, 256)  0           add_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 5, 5, 256)    0           activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 5, 5, 128)    32896       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 5, 5, 128)    512         conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 5, 5, 128)    0           batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 5, 5, 128)    147584      activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 5, 5, 128)    512         conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 5, 5, 128)    0           batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 5, 5, 512)    66048       activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 5, 5, 512)    131584      max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 5, 5, 512)    2048        conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_140 (Add)                   (None, 5, 5, 512)    0           conv2d_408[0][0]                 \n",
      "                                                                 batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 5, 5, 512)    0           add_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 5, 5, 128)    65664       activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 5, 5, 128)    512         conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 5, 5, 128)    0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 5, 5, 128)    147584      activation_409[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 5, 5, 128)    512         conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 5, 5, 128)    0           batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 5, 5, 512)    66048       activation_410[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 5, 5, 512)    2048        conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_141 (Add)                   (None, 5, 5, 512)    0           activation_408[0][0]             \n",
      "                                                                 batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, 5, 5, 512)    0           add_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 5, 5, 128)    65664       activation_411[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 5, 5, 128)    512         conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_412 (Activation)     (None, 5, 5, 128)    0           batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 5, 5, 128)    147584      activation_412[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 5, 5, 128)    512         conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_413 (Activation)     (None, 5, 5, 128)    0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 5, 5, 512)    66048       activation_413[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 5, 5, 512)    2048        conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_142 (Add)                   (None, 5, 5, 512)    0           activation_411[0][0]             \n",
      "                                                                 batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_414 (Activation)     (None, 5, 5, 512)    0           add_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 5, 5, 128)    65664       activation_414[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 5, 5, 128)    512         conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_415 (Activation)     (None, 5, 5, 128)    0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 5, 5, 128)    147584      activation_415[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 5, 5, 128)    512         conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, 5, 5, 128)    0           batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 5, 5, 512)    66048       activation_416[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 5, 5, 512)    2048        conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_143 (Add)                   (None, 5, 5, 512)    0           activation_414[0][0]             \n",
      "                                                                 batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, 5, 5, 512)    0           add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 5, 5, 128)    65664       activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 5, 5, 128)    512         conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, 5, 5, 128)    0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 5, 5, 128)    147584      activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 5, 5, 128)    512         conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, 5, 5, 128)    0           batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 5, 5, 512)    66048       activation_419[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 5, 5, 512)    2048        conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_144 (Add)                   (None, 5, 5, 512)    0           activation_417[0][0]             \n",
      "                                                                 batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, 5, 5, 512)    0           add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 5, 5, 128)    65664       activation_420[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 5, 5, 128)    512         conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, 5, 5, 128)    0           batch_normalization_423[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 5, 5, 128)    147584      activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, 5, 5, 128)    512         conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, 5, 5, 128)    0           batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 5, 5, 512)    66048       activation_422[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, 5, 5, 512)    2048        conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_145 (Add)                   (None, 5, 5, 512)    0           activation_420[0][0]             \n",
      "                                                                 batch_normalization_425[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, 5, 5, 512)    0           add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 5, 5, 128)    65664       activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, 5, 5, 128)    512         conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 5, 5, 128)    0           batch_normalization_426[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, 5, 5, 128)    147584      activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, 5, 5, 128)    512         conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 5, 5, 128)    0           batch_normalization_427[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, 5, 5, 512)    66048       activation_425[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, 5, 5, 512)    2048        conv2d_426[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_146 (Add)                   (None, 5, 5, 512)    0           activation_423[0][0]             \n",
      "                                                                 batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 5, 5, 512)    0           add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, 5, 5, 128)    65664       activation_426[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, 5, 5, 128)    512         conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 5, 5, 128)    0           batch_normalization_429[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, 5, 5, 128)    147584      activation_427[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, 5, 5, 128)    512         conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 5, 5, 128)    0           batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, 5, 5, 512)    66048       activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, 5, 5, 512)    2048        conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_147 (Add)                   (None, 5, 5, 512)    0           activation_426[0][0]             \n",
      "                                                                 batch_normalization_431[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 5, 5, 512)    0           add_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 2, 2, 512)    0           activation_429[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, 2, 2, 256)    131328      max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 2, 2, 256)    1024        conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 2, 2, 256)    0           batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, 2, 2, 256)    590080      activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, 2, 2, 256)    1024        conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 2, 2, 256)    0           batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, 2, 2, 1024)   263168      activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, 2, 2, 1024)   525312      max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, 2, 2, 1024)   4096        conv2d_432[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_148 (Add)                   (None, 2, 2, 1024)   0           conv2d_433[0][0]                 \n",
      "                                                                 batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 2, 2, 1024)   0           add_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, 2, 2, 256)    262400      activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, 2, 2, 256)    1024        conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 2, 2, 256)    0           batch_normalization_435[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, 2, 2, 256)    590080      activation_433[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 2, 2, 256)    1024        conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 2, 2, 256)    0           batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 2, 2, 1024)   263168      activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 2, 2, 1024)   4096        conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_149 (Add)                   (None, 2, 2, 1024)   0           activation_432[0][0]             \n",
      "                                                                 batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 2, 2, 1024)   0           add_149[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 2, 2, 256)    262400      activation_435[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 2, 2, 256)    1024        conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 2, 2, 256)    0           batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 2, 2, 256)    590080      activation_436[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 2, 2, 256)    1024        conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 2, 2, 256)    0           batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 2, 2, 1024)   263168      activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 2, 2, 1024)   4096        conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_150 (Add)                   (None, 2, 2, 1024)   0           activation_435[0][0]             \n",
      "                                                                 batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 2, 2, 1024)   0           add_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 2, 2, 256)    262400      activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 2, 2, 256)    1024        conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 2, 2, 256)    0           batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 2, 2, 256)    590080      activation_439[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 2, 2, 256)    1024        conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 2, 2, 256)    0           batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 2, 2, 1024)   263168      activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 2, 2, 1024)   4096        conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_151 (Add)                   (None, 2, 2, 1024)   0           activation_438[0][0]             \n",
      "                                                                 batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 2, 2, 1024)   0           add_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 2, 2, 256)    262400      activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 2, 2, 256)    1024        conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 2, 2, 256)    0           batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 2, 2, 256)    590080      activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 2, 2, 256)    1024        conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 2, 2, 256)    0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 2, 2, 1024)   263168      activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 2, 2, 1024)   4096        conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_152 (Add)                   (None, 2, 2, 1024)   0           activation_441[0][0]             \n",
      "                                                                 batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 2, 2, 1024)   0           add_152[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 2, 2, 256)    262400      activation_444[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 2, 2, 256)    1024        conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 2, 2, 256)    0           batch_normalization_447[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 2, 2, 256)    590080      activation_445[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 2, 2, 256)    1024        conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 2, 2, 256)    0           batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 2, 2, 1024)   263168      activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 2, 2, 1024)   4096        conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_153 (Add)                   (None, 2, 2, 1024)   0           activation_444[0][0]             \n",
      "                                                                 batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 2, 2, 1024)   0           add_153[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 2, 2, 256)    262400      activation_447[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 2, 2, 256)    1024        conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 2, 2, 256)    0           batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 2, 2, 256)    590080      activation_448[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 2, 2, 256)    1024        conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 2, 2, 256)    0           batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 2, 2, 1024)   263168      activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, 2, 2, 1024)   4096        conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_154 (Add)                   (None, 2, 2, 1024)   0           activation_447[0][0]             \n",
      "                                                                 batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 2, 2, 1024)   0           add_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 2, 2, 256)    262400      activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, 2, 2, 256)    1024        conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 2, 2, 256)    0           batch_normalization_453[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 2, 2, 256)    590080      activation_451[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, 2, 2, 256)    1024        conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 2, 2, 256)    0           batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 2, 2, 1024)   263168      activation_452[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, 2, 2, 1024)   4096        conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_155 (Add)                   (None, 2, 2, 1024)   0           activation_450[0][0]             \n",
      "                                                                 batch_normalization_455[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 2, 2, 1024)   0           add_155[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 2, 2, 256)    262400      activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_456 (BatchN (None, 2, 2, 256)    1024        conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 2, 2, 256)    0           batch_normalization_456[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 2, 2, 256)    590080      activation_454[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_457 (BatchN (None, 2, 2, 256)    1024        conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 2, 2, 256)    0           batch_normalization_457[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 2, 2, 1024)   263168      activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_458 (BatchN (None, 2, 2, 1024)   4096        conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_156 (Add)                   (None, 2, 2, 1024)   0           activation_453[0][0]             \n",
      "                                                                 batch_normalization_458[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_456 (Activation)     (None, 2, 2, 1024)   0           add_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 2, 2, 256)    262400      activation_456[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_459 (BatchN (None, 2, 2, 256)    1024        conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, 2, 2, 256)    0           batch_normalization_459[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 2, 2, 256)    590080      activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_460 (BatchN (None, 2, 2, 256)    1024        conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, 2, 2, 256)    0           batch_normalization_460[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 2, 2, 1024)   263168      activation_458[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_461 (BatchN (None, 2, 2, 1024)   4096        conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_157 (Add)                   (None, 2, 2, 1024)   0           activation_456[0][0]             \n",
      "                                                                 batch_normalization_461[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, 2, 2, 1024)   0           add_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 2, 2, 256)    262400      activation_459[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_462 (BatchN (None, 2, 2, 256)    1024        conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, 2, 2, 256)    0           batch_normalization_462[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 2, 2, 256)    590080      activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_463 (BatchN (None, 2, 2, 256)    1024        conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, 2, 2, 256)    0           batch_normalization_463[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 2, 2, 1024)   263168      activation_461[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_464 (BatchN (None, 2, 2, 1024)   4096        conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_158 (Add)                   (None, 2, 2, 1024)   0           activation_459[0][0]             \n",
      "                                                                 batch_normalization_464[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_462 (Activation)     (None, 2, 2, 1024)   0           add_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 2, 2, 256)    262400      activation_462[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_465 (BatchN (None, 2, 2, 256)    1024        conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_463 (Activation)     (None, 2, 2, 256)    0           batch_normalization_465[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 2, 2, 256)    590080      activation_463[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_466 (BatchN (None, 2, 2, 256)    1024        conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_464 (Activation)     (None, 2, 2, 256)    0           batch_normalization_466[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 2, 2, 1024)   263168      activation_464[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_467 (BatchN (None, 2, 2, 1024)   4096        conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_159 (Add)                   (None, 2, 2, 1024)   0           activation_462[0][0]             \n",
      "                                                                 batch_normalization_467[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_465 (Activation)     (None, 2, 2, 1024)   0           add_159[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 2, 2, 256)    262400      activation_465[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_468 (BatchN (None, 2, 2, 256)    1024        conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_466 (Activation)     (None, 2, 2, 256)    0           batch_normalization_468[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 2, 2, 256)    590080      activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_469 (BatchN (None, 2, 2, 256)    1024        conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_467 (Activation)     (None, 2, 2, 256)    0           batch_normalization_469[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 2, 2, 1024)   263168      activation_467[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_470 (BatchN (None, 2, 2, 1024)   4096        conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_160 (Add)                   (None, 2, 2, 1024)   0           activation_465[0][0]             \n",
      "                                                                 batch_normalization_470[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_468 (Activation)     (None, 2, 2, 1024)   0           add_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 2, 2, 256)    262400      activation_468[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchN (None, 2, 2, 256)    1024        conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_469 (Activation)     (None, 2, 2, 256)    0           batch_normalization_471[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 2, 2, 256)    590080      activation_469[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchN (None, 2, 2, 256)    1024        conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_470 (Activation)     (None, 2, 2, 256)    0           batch_normalization_472[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 2, 2, 1024)   263168      activation_470[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchN (None, 2, 2, 1024)   4096        conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_161 (Add)                   (None, 2, 2, 1024)   0           activation_468[0][0]             \n",
      "                                                                 batch_normalization_473[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_471 (Activation)     (None, 2, 2, 1024)   0           add_161[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 2, 2, 256)    262400      activation_471[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_474 (BatchN (None, 2, 2, 256)    1024        conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_472 (Activation)     (None, 2, 2, 256)    0           batch_normalization_474[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 2, 2, 256)    590080      activation_472[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_475 (BatchN (None, 2, 2, 256)    1024        conv2d_474[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_473 (Activation)     (None, 2, 2, 256)    0           batch_normalization_475[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 2, 2, 1024)   263168      activation_473[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_476 (BatchN (None, 2, 2, 1024)   4096        conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_162 (Add)                   (None, 2, 2, 1024)   0           activation_471[0][0]             \n",
      "                                                                 batch_normalization_476[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_474 (Activation)     (None, 2, 2, 1024)   0           add_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 2, 2, 256)    262400      activation_474[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_477 (BatchN (None, 2, 2, 256)    1024        conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_475 (Activation)     (None, 2, 2, 256)    0           batch_normalization_477[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 2, 2, 256)    590080      activation_475[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_478 (BatchN (None, 2, 2, 256)    1024        conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_476 (Activation)     (None, 2, 2, 256)    0           batch_normalization_478[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 2, 2, 1024)   263168      activation_476[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_479 (BatchN (None, 2, 2, 1024)   4096        conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_163 (Add)                   (None, 2, 2, 1024)   0           activation_474[0][0]             \n",
      "                                                                 batch_normalization_479[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_477 (Activation)     (None, 2, 2, 1024)   0           add_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 2, 2, 256)    262400      activation_477[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_480 (BatchN (None, 2, 2, 256)    1024        conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_478 (Activation)     (None, 2, 2, 256)    0           batch_normalization_480[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 2, 2, 256)    590080      activation_478[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchN (None, 2, 2, 256)    1024        conv2d_480[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_479 (Activation)     (None, 2, 2, 256)    0           batch_normalization_481[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 2, 2, 1024)   263168      activation_479[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_482 (BatchN (None, 2, 2, 1024)   4096        conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_164 (Add)                   (None, 2, 2, 1024)   0           activation_477[0][0]             \n",
      "                                                                 batch_normalization_482[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_480 (Activation)     (None, 2, 2, 1024)   0           add_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 2, 2, 256)    262400      activation_480[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_483 (BatchN (None, 2, 2, 256)    1024        conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_481 (Activation)     (None, 2, 2, 256)    0           batch_normalization_483[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 2, 2, 256)    590080      activation_481[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_484 (BatchN (None, 2, 2, 256)    1024        conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_482 (Activation)     (None, 2, 2, 256)    0           batch_normalization_484[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 2, 2, 1024)   263168      activation_482[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_485 (BatchN (None, 2, 2, 1024)   4096        conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_165 (Add)                   (None, 2, 2, 1024)   0           activation_480[0][0]             \n",
      "                                                                 batch_normalization_485[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_483 (Activation)     (None, 2, 2, 1024)   0           add_165[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 2, 2, 256)    262400      activation_483[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_486 (BatchN (None, 2, 2, 256)    1024        conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_484 (Activation)     (None, 2, 2, 256)    0           batch_normalization_486[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 2, 2, 256)    590080      activation_484[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_487 (BatchN (None, 2, 2, 256)    1024        conv2d_486[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_485 (Activation)     (None, 2, 2, 256)    0           batch_normalization_487[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 2, 2, 1024)   263168      activation_485[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchN (None, 2, 2, 1024)   4096        conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_166 (Add)                   (None, 2, 2, 1024)   0           activation_483[0][0]             \n",
      "                                                                 batch_normalization_488[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_486 (Activation)     (None, 2, 2, 1024)   0           add_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 2, 2, 256)    262400      activation_486[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchN (None, 2, 2, 256)    1024        conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_487 (Activation)     (None, 2, 2, 256)    0           batch_normalization_489[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 2, 2, 256)    590080      activation_487[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchN (None, 2, 2, 256)    1024        conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_488 (Activation)     (None, 2, 2, 256)    0           batch_normalization_490[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 2, 2, 1024)   263168      activation_488[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchN (None, 2, 2, 1024)   4096        conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_167 (Add)                   (None, 2, 2, 1024)   0           activation_486[0][0]             \n",
      "                                                                 batch_normalization_491[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_489 (Activation)     (None, 2, 2, 1024)   0           add_167[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 2, 2, 256)    262400      activation_489[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchN (None, 2, 2, 256)    1024        conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_490 (Activation)     (None, 2, 2, 256)    0           batch_normalization_492[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 2, 2, 256)    590080      activation_490[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_493 (BatchN (None, 2, 2, 256)    1024        conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_491 (Activation)     (None, 2, 2, 256)    0           batch_normalization_493[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 2, 2, 1024)   263168      activation_491[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_494 (BatchN (None, 2, 2, 1024)   4096        conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_168 (Add)                   (None, 2, 2, 1024)   0           activation_489[0][0]             \n",
      "                                                                 batch_normalization_494[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_492 (Activation)     (None, 2, 2, 1024)   0           add_168[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 2, 2, 256)    262400      activation_492[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_495 (BatchN (None, 2, 2, 256)    1024        conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_493 (Activation)     (None, 2, 2, 256)    0           batch_normalization_495[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 2, 2, 256)    590080      activation_493[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_496 (BatchN (None, 2, 2, 256)    1024        conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_494 (Activation)     (None, 2, 2, 256)    0           batch_normalization_496[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 2, 2, 1024)   263168      activation_494[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchN (None, 2, 2, 1024)   4096        conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_169 (Add)                   (None, 2, 2, 1024)   0           activation_492[0][0]             \n",
      "                                                                 batch_normalization_497[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_495 (Activation)     (None, 2, 2, 1024)   0           add_169[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 2, 2, 256)    262400      activation_495[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchN (None, 2, 2, 256)    1024        conv2d_497[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_496 (Activation)     (None, 2, 2, 256)    0           batch_normalization_498[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 2, 2, 256)    590080      activation_496[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_499 (BatchN (None, 2, 2, 256)    1024        conv2d_498[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_497 (Activation)     (None, 2, 2, 256)    0           batch_normalization_499[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 2, 2, 1024)   263168      activation_497[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_500 (BatchN (None, 2, 2, 1024)   4096        conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_170 (Add)                   (None, 2, 2, 1024)   0           activation_495[0][0]             \n",
      "                                                                 batch_normalization_500[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_498 (Activation)     (None, 2, 2, 1024)   0           add_170[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 2, 2, 256)    262400      activation_498[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_501 (BatchN (None, 2, 2, 256)    1024        conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_499 (Activation)     (None, 2, 2, 256)    0           batch_normalization_501[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 2, 2, 256)    590080      activation_499[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_502 (BatchN (None, 2, 2, 256)    1024        conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_500 (Activation)     (None, 2, 2, 256)    0           batch_normalization_502[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 2, 2, 1024)   263168      activation_500[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_503 (BatchN (None, 2, 2, 1024)   4096        conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_171 (Add)                   (None, 2, 2, 1024)   0           activation_498[0][0]             \n",
      "                                                                 batch_normalization_503[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_501 (Activation)     (None, 2, 2, 1024)   0           add_171[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 2, 2, 256)    262400      activation_501[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_504 (BatchN (None, 2, 2, 256)    1024        conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_502 (Activation)     (None, 2, 2, 256)    0           batch_normalization_504[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 2, 2, 256)    590080      activation_502[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_505 (BatchN (None, 2, 2, 256)    1024        conv2d_504[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_503 (Activation)     (None, 2, 2, 256)    0           batch_normalization_505[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 2, 2, 1024)   263168      activation_503[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_506 (BatchN (None, 2, 2, 1024)   4096        conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_172 (Add)                   (None, 2, 2, 1024)   0           activation_501[0][0]             \n",
      "                                                                 batch_normalization_506[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_504 (Activation)     (None, 2, 2, 1024)   0           add_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 2, 2, 256)    262400      activation_504[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_507 (BatchN (None, 2, 2, 256)    1024        conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_505 (Activation)     (None, 2, 2, 256)    0           batch_normalization_507[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 2, 2, 256)    590080      activation_505[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_508 (BatchN (None, 2, 2, 256)    1024        conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_506 (Activation)     (None, 2, 2, 256)    0           batch_normalization_508[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 2, 2, 1024)   263168      activation_506[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_509 (BatchN (None, 2, 2, 1024)   4096        conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_173 (Add)                   (None, 2, 2, 1024)   0           activation_504[0][0]             \n",
      "                                                                 batch_normalization_509[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_507 (Activation)     (None, 2, 2, 1024)   0           add_173[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 2, 2, 256)    262400      activation_507[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_510 (BatchN (None, 2, 2, 256)    1024        conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_508 (Activation)     (None, 2, 2, 256)    0           batch_normalization_510[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 2, 2, 256)    590080      activation_508[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_511 (BatchN (None, 2, 2, 256)    1024        conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_509 (Activation)     (None, 2, 2, 256)    0           batch_normalization_511[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 2, 2, 1024)   263168      activation_509[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_512 (BatchN (None, 2, 2, 1024)   4096        conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_174 (Add)                   (None, 2, 2, 1024)   0           activation_507[0][0]             \n",
      "                                                                 batch_normalization_512[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_510 (Activation)     (None, 2, 2, 1024)   0           add_174[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 2, 2, 256)    262400      activation_510[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_513 (BatchN (None, 2, 2, 256)    1024        conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_511 (Activation)     (None, 2, 2, 256)    0           batch_normalization_513[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 2, 2, 256)    590080      activation_511[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_514 (BatchN (None, 2, 2, 256)    1024        conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_512 (Activation)     (None, 2, 2, 256)    0           batch_normalization_514[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 2, 2, 1024)   263168      activation_512[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_515 (BatchN (None, 2, 2, 1024)   4096        conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_175 (Add)                   (None, 2, 2, 1024)   0           activation_510[0][0]             \n",
      "                                                                 batch_normalization_515[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_513 (Activation)     (None, 2, 2, 1024)   0           add_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 2, 2, 256)    262400      activation_513[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_516 (BatchN (None, 2, 2, 256)    1024        conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_514 (Activation)     (None, 2, 2, 256)    0           batch_normalization_516[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 2, 2, 256)    590080      activation_514[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_517 (BatchN (None, 2, 2, 256)    1024        conv2d_516[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_515 (Activation)     (None, 2, 2, 256)    0           batch_normalization_517[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 2, 2, 1024)   263168      activation_515[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_518 (BatchN (None, 2, 2, 1024)   4096        conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_176 (Add)                   (None, 2, 2, 1024)   0           activation_513[0][0]             \n",
      "                                                                 batch_normalization_518[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_516 (Activation)     (None, 2, 2, 1024)   0           add_176[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 2, 2, 256)    262400      activation_516[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_519 (BatchN (None, 2, 2, 256)    1024        conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_517 (Activation)     (None, 2, 2, 256)    0           batch_normalization_519[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 2, 2, 256)    590080      activation_517[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_520 (BatchN (None, 2, 2, 256)    1024        conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_518 (Activation)     (None, 2, 2, 256)    0           batch_normalization_520[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 2, 2, 1024)   263168      activation_518[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_521 (BatchN (None, 2, 2, 1024)   4096        conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_177 (Add)                   (None, 2, 2, 1024)   0           activation_516[0][0]             \n",
      "                                                                 batch_normalization_521[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_519 (Activation)     (None, 2, 2, 1024)   0           add_177[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 2, 2, 256)    262400      activation_519[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_522 (BatchN (None, 2, 2, 256)    1024        conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_520 (Activation)     (None, 2, 2, 256)    0           batch_normalization_522[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 2, 2, 256)    590080      activation_520[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_523 (BatchN (None, 2, 2, 256)    1024        conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_521 (Activation)     (None, 2, 2, 256)    0           batch_normalization_523[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 2, 2, 1024)   263168      activation_521[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_524 (BatchN (None, 2, 2, 1024)   4096        conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_178 (Add)                   (None, 2, 2, 1024)   0           activation_519[0][0]             \n",
      "                                                                 batch_normalization_524[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_522 (Activation)     (None, 2, 2, 1024)   0           add_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 2, 2, 256)    262400      activation_522[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_525 (BatchN (None, 2, 2, 256)    1024        conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_523 (Activation)     (None, 2, 2, 256)    0           batch_normalization_525[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 2, 2, 256)    590080      activation_523[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_526 (BatchN (None, 2, 2, 256)    1024        conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_524 (Activation)     (None, 2, 2, 256)    0           batch_normalization_526[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 2, 2, 1024)   263168      activation_524[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_527 (BatchN (None, 2, 2, 1024)   4096        conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_179 (Add)                   (None, 2, 2, 1024)   0           activation_522[0][0]             \n",
      "                                                                 batch_normalization_527[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_525 (Activation)     (None, 2, 2, 1024)   0           add_179[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 2, 2, 256)    262400      activation_525[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_528 (BatchN (None, 2, 2, 256)    1024        conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_526 (Activation)     (None, 2, 2, 256)    0           batch_normalization_528[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 2, 2, 256)    590080      activation_526[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_529 (BatchN (None, 2, 2, 256)    1024        conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_527 (Activation)     (None, 2, 2, 256)    0           batch_normalization_529[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 2, 2, 1024)   263168      activation_527[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_530 (BatchN (None, 2, 2, 1024)   4096        conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_180 (Add)                   (None, 2, 2, 1024)   0           activation_525[0][0]             \n",
      "                                                                 batch_normalization_530[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_528 (Activation)     (None, 2, 2, 1024)   0           add_180[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 2, 2, 256)    262400      activation_528[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_531 (BatchN (None, 2, 2, 256)    1024        conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_529 (Activation)     (None, 2, 2, 256)    0           batch_normalization_531[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 2, 2, 256)    590080      activation_529[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_532 (BatchN (None, 2, 2, 256)    1024        conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_530 (Activation)     (None, 2, 2, 256)    0           batch_normalization_532[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 2, 2, 1024)   263168      activation_530[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_533 (BatchN (None, 2, 2, 1024)   4096        conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_181 (Add)                   (None, 2, 2, 1024)   0           activation_528[0][0]             \n",
      "                                                                 batch_normalization_533[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_531 (Activation)     (None, 2, 2, 1024)   0           add_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 2, 2, 256)    262400      activation_531[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_534 (BatchN (None, 2, 2, 256)    1024        conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_532 (Activation)     (None, 2, 2, 256)    0           batch_normalization_534[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 2, 2, 256)    590080      activation_532[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_535 (BatchN (None, 2, 2, 256)    1024        conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_533 (Activation)     (None, 2, 2, 256)    0           batch_normalization_535[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 2, 2, 1024)   263168      activation_533[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_536 (BatchN (None, 2, 2, 1024)   4096        conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_182 (Add)                   (None, 2, 2, 1024)   0           activation_531[0][0]             \n",
      "                                                                 batch_normalization_536[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_534 (Activation)     (None, 2, 2, 1024)   0           add_182[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 2, 2, 256)    262400      activation_534[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_537 (BatchN (None, 2, 2, 256)    1024        conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_535 (Activation)     (None, 2, 2, 256)    0           batch_normalization_537[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 2, 2, 256)    590080      activation_535[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_538 (BatchN (None, 2, 2, 256)    1024        conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_536 (Activation)     (None, 2, 2, 256)    0           batch_normalization_538[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 2, 2, 1024)   263168      activation_536[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_539 (BatchN (None, 2, 2, 1024)   4096        conv2d_538[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_183 (Add)                   (None, 2, 2, 1024)   0           activation_534[0][0]             \n",
      "                                                                 batch_normalization_539[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_537 (Activation)     (None, 2, 2, 1024)   0           add_183[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 1, 1, 1024)   0           activation_537[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 1, 1, 512)    524800      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_540 (BatchN (None, 1, 1, 512)    2048        conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_538 (Activation)     (None, 1, 1, 512)    0           batch_normalization_540[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 1, 1, 512)    2359808     activation_538[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_541 (BatchN (None, 1, 1, 512)    2048        conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_539 (Activation)     (None, 1, 1, 512)    0           batch_normalization_541[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 1, 1, 2048)   1050624     activation_539[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 1, 1, 2048)   2099200     max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_542 (BatchN (None, 1, 1, 2048)   8192        conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_184 (Add)                   (None, 1, 1, 2048)   0           conv2d_542[0][0]                 \n",
      "                                                                 batch_normalization_542[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_540 (Activation)     (None, 1, 1, 2048)   0           add_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 1, 1, 512)    1049088     activation_540[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_543 (BatchN (None, 1, 1, 512)    2048        conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_541 (Activation)     (None, 1, 1, 512)    0           batch_normalization_543[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 1, 1, 512)    2359808     activation_541[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_544 (BatchN (None, 1, 1, 512)    2048        conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_542 (Activation)     (None, 1, 1, 512)    0           batch_normalization_544[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 1, 1, 2048)   1050624     activation_542[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_545 (BatchN (None, 1, 1, 2048)   8192        conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_185 (Add)                   (None, 1, 1, 2048)   0           activation_540[0][0]             \n",
      "                                                                 batch_normalization_545[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_543 (Activation)     (None, 1, 1, 2048)   0           add_185[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 1, 1, 512)    1049088     activation_543[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_546 (BatchN (None, 1, 1, 512)    2048        conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_544 (Activation)     (None, 1, 1, 512)    0           batch_normalization_546[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 1, 1, 512)    2359808     activation_544[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_547 (BatchN (None, 1, 1, 512)    2048        conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_545 (Activation)     (None, 1, 1, 512)    0           batch_normalization_547[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 1, 1, 2048)   1050624     activation_545[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_548 (BatchN (None, 1, 1, 2048)   8192        conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_186 (Add)                   (None, 1, 1, 2048)   0           activation_543[0][0]             \n",
      "                                                                 batch_normalization_548[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_546 (Activation)     (None, 1, 1, 2048)   0           add_186[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           activation_546[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1000)         2049000     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_549 (BatchN (None, 1000)         4000        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_547 (Activation)     (None, 1000)         0           batch_normalization_549[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           10010       activation_547[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 60,418,594\n",
      "Trainable params: 60,272,850\n",
      "Non-trainable params: 145,744\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet 152\n",
    "\n",
    "X = tf.keras.Input(shape=[32, 32, 3])\n",
    "H = tf.keras.layers.Conv2D(64, kernel_size=7, padding=\"same\")(X)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "H = tf.keras.layers.MaxPool2D(pool_size=3)(H)\n",
    "\n",
    "# residual_block_3 256 * 3\n",
    "for i in range(3):\n",
    "    H = residual_block_3(256, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "# residual_block_3 512 * 8\n",
    "for i in range(8):\n",
    "    H = residual_block_3(512, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "# residual_block_3 1024 * 36\n",
    "for i in range(36):\n",
    "    H = residual_block_3(1024, H)\n",
    "H = tf.keras.layers.MaxPool2D()(H)\n",
    "\n",
    "# residual_block_3 2048 * 3\n",
    "for i in range(3):\n",
    "    H = residual_block_3(2048, H)\n",
    "\n",
    "H = tf.keras.layers.GlobalAveragePooling2D()(H)\n",
    "\n",
    "H = tf.keras.layers.Flatten()(H)\n",
    "H = tf.keras.layers.Dense(1000)(H)\n",
    "H = tf.keras.layers.BatchNormalization()(H)\n",
    "H = tf.keras.layers.Activation(\"swish\")(H)\n",
    "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
    "\n",
    "model = tf.keras.Model(X, Y)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "352/352 [==============================] - 255s 576ms/step - loss: 1.9153 - accuracy: 0.3008 - val_loss: 580.6890 - val_accuracy: 0.2940\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 179s 508ms/step - loss: 1.4530 - accuracy: 0.4874 - val_loss: 2.1100 - val_accuracy: 0.3968\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 143s 407ms/step - loss: 1.2282 - accuracy: 0.5747 - val_loss: 2.1940 - val_accuracy: 0.3596\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 137s 390ms/step - loss: 0.9574 - accuracy: 0.6641 - val_loss: 1.2094 - val_accuracy: 0.5860\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 157s 448ms/step - loss: 0.7773 - accuracy: 0.7310 - val_loss: 0.9652 - val_accuracy: 0.6762\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 147s 418ms/step - loss: 0.6381 - accuracy: 0.7763 - val_loss: 1.4069 - val_accuracy: 0.5810\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 163s 464ms/step - loss: 0.5323 - accuracy: 0.8156 - val_loss: 0.8901 - val_accuracy: 0.7006\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 125s 356ms/step - loss: 0.4346 - accuracy: 0.8495 - val_loss: 10.1999 - val_accuracy: 0.5526\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 101s 287ms/step - loss: 0.3397 - accuracy: 0.8812 - val_loss: 0.9893 - val_accuracy: 0.6928\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 101s 287ms/step - loss: 0.2683 - accuracy: 0.9048 - val_loss: 12.2089 - val_accuracy: 0.2830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20fb0c40d60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn 4 2:17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"./img/c26.png\" width=80% height=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40b396f7bb4524eebe16d5148ef674cb630ecbb9edf31b1d2c1678c5ede47175"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('webai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
