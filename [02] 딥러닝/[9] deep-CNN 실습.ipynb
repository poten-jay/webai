{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 실습 \n",
    "\n",
    "220406 / [CNN 실습]\n",
    "\n",
    "https://coherent-hortensia-d93.notion.site/a3cb8f1b17c84c68a9122fd15faa9e61\n",
    "\n",
    "https://colab.research.google.com/drive/1H-pO_4t91djwJ_wQ90E138N954PIGw9f?usp=sharing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 학습\n",
    "\n",
    "### 비용함수 (Cost Function)\n",
    "\n",
    "- 가설로부터 얻은 예측 값과 실제 값 사이의 차를 비용(Cost), 오차(Error) 또는 손실(Loss) 이라 한다.\n",
    "- 즉, 가설이 얼마나 잘못되었는지 평가하는 척도\n",
    "- 비용을 계산하는 함수를 비용 함수(Cost Function)이라 함\n",
    "\n",
    "---\n",
    "\n",
    "### MSE (Mean Squared Error)\n",
    "- 예측 값과 실제 값 사이의 평균 제곱 오차\n",
    "- 회귀 문제의 비용 함수로 사용\n",
    "\n",
    "### Binary Cross-Entroyp\n",
    "- 예측 레이블과 실제 레이블 사이의 교차 엔트로피 손실\n",
    "- 레이블이 2개만 존재할 때(이진 분류) 사용\n",
    "\n",
    "### Categorical Cross-Entropy\n",
    "- 다중 분류 손실함수로 one-hot-encoding 된  입력 값을 받아 사용\n",
    "\n",
    "### Sparse_Categorical_Cross-Entroyp\n",
    "- 다중 분류 손실함수로 정수형 자료로 된 입력 값을 받아 사용\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵티마이저(Optimizer)\n",
    "- 관계를 가장 잘 모델링하는 가중치 w 와 절편 b를 찾는 것이 목표\n",
    "- 가중치 업데이트 시 필요한 하이퍼파라미터\n",
    "- 1회 훈련(1 에포크) 후 어떤 방식으로 가중치를 조절할 것인가에 관한 알고리즘\n",
    "\n",
    "<img src=\"./img/d4.png\" width=80% height=80%>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 활성화 함수(Activation Function)\n",
    "- 입력층으로부터 입력받은 데이터의 활성 또는 비활성하는데 사용되는 함수\n",
    "- 입력값에 따른 출력값의 형태를 결정하는 함수\n",
    "- y = wx + b : 1차 함수\n",
    "- 딥러닝에서 활성화 함수는 반드시 비선형 함수여야 함\n",
    "- 선형 함수를 사용할 경우, 단층으로 구성한 것과 똑같은 결과가 나오기 때문임\n",
    "\n",
    "<img src=\"./img/d5.png\" width=80% height=80%>\n",
    "\n",
    "### Sigmoid\n",
    "- 입력 값을 0과 1 사이의 값으로 변환하여 다음 레이어로 전달\n",
    "- 이진 분류화에 주로 사용\n",
    "\n",
    "### ReLu\n",
    "- 0 이하의 값은 다음 레이어에 전달하지 않음\n",
    "- 0 이상의 값은 원래 값 그대로를 다음 레이어로 전달\n",
    "- 회귀 문제와 CNN 학습 시 주로 사용\n",
    "\n",
    "### Softmax (보통 모델 마지막에 사용함)\n",
    "- n 차원의 입력을 받아, 각 클래스에 속할 확률을 출력\n",
    "- 입력받은 값을 0~1 사이의 값으로 출력하며, 총 합은 항상 1이어서 확률 비교 시 유용함\n",
    "- 다중 클래스 분류에 주로 사용\n",
    "\n",
    "### Swish\n",
    "- Swish는 Relu를 대체하기 의해 구글이 고안한 함수\n",
    "- Sigmoid 함수에 x를 곱한 아주 간단한 형태\n",
    "- 깊은 레이어를 학습시킬 때 Relu보다 뛰어난 성능을 보여 줌\n",
    "- CNN 학습 시 주로 사용\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=\"./img/d4.png\" width=80% height=80%>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
